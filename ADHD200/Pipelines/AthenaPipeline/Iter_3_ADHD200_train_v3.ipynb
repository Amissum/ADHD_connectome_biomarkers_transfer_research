{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADHD200 — Обучение (Multiclass) на подготовленных таймсериях - Iter 3\n",
    "\n",
    "Этот ноутбук реализует три ступени:\n",
    "1) **Базлайны без нейросетей**:\n",
    "   - **Статический FC** (корреляции ROI×ROI) → Logistic Regression (+PCA по желанию);\n",
    "   - **Динамический FC + HMM** (или KMeans), признаки: доли состояний, переключаемость, длительность.\n",
    "   - **Переносимость**: Leave-One-Site-Out для статического FC.\n",
    "2) **Нейросети**: LSTM/GRU/TCN+BiGRU+Self-Attn с ковариатами (возраст/пол), веса классов, метрики `acc/auc/f1`.\n",
    "3) **Строгая валидация**: групповой сплит по участнику/сайту для предотвращения утечек.\n",
    "\n",
    "В данном ноутбуке используется подготовленный набор данных из ноутбука [ADHD200_prep.ipynb](ADHD200_prep.ipynb). Для обучения нейросети используются файлы `.npy` с таймсериями.\n",
    "Обучение ведётся только на данных подростков из соответствующего отфильтрованного манифеста `manifest.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f388695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: hmmlearn in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.7.2)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlwt in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openpyxl in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install hmmlearn\n",
    "%pip install xlwt\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dce36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import enum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import xlwt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Увеличим ширину печати для pandas\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Отключим предупреждения для чистоты логирования\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f98cd4",
   "metadata": {},
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a2fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Константы загружены:\n",
      "Дети: 0-11.99 лет\n",
      "Подростки: 12-15.99 лет\n",
      "Молодые взрослые: 16-21.99 лет\n",
      "Имена когорт по возрасту: ['children', 'teen', 'adult']\n",
      "Ключи когорт по возрасту: {'children': 0, 'teen': 1, 'adult': 2}\n",
      "Ключи диагнозов: {0: 'Typically Developing Children', 1: 'ADHD-Combined', 2: 'ADHD-Hyperactive/Impulsive', 3: 'ADHD-Inattentive'}\n",
      "Коды сайтов (обратная карта): {'Peking_1': 1, 'Peking_2': 1, 'Peking_3': 1, 'Brown': 2, 'KKI': 3, 'NeuroIMAGE': 4, 'NYU': 5, 'OHSU': 6, 'Pittsburgh': 7, 'WashU': 8}\n",
      "Путь к Athena Source: /Users/alexey.stafeev/MyDocuments/Study/МФТИ/НИР/Materials/ADHD200/ADHD200_CC400_TCs_filtfix\n",
      "Random seed: 42\n",
      "T_FIX: 200\n",
      "WINDOW_SIZE: 30\n",
      "WINDOW_STEP: 5\n",
      "FC_METRIC: correlation\n"
     ]
    }
   ],
   "source": [
    "# Загрузка констант из YAML файла\n",
    "with open('../../research_constants.yaml', 'r') as file:\n",
    "    constants = yaml.safe_load(file)\n",
    "\n",
    "CHILDREN_MINIMAL_AGE = constants['AGE_COHORTS']['CHILDREN_MINIMAL_AGE']\n",
    "CHILDREN_MAXIMAL_AGE = constants['AGE_COHORTS']['CHILDREN_MAXIMAL_AGE']\n",
    "TEEN_MINIMAL_AGE = constants['AGE_COHORTS']['TEEN_MINIMAL_AGE']\n",
    "TEEN_MAXIMAL_AGE = constants['AGE_COHORTS']['TEEN_MAXIMAL_AGE']\n",
    "ADULT_MINIMAL_AGE = constants['AGE_COHORTS']['ADULT_MINIMAL_AGE']\n",
    "ADULT_MAXIMAL_AGE = constants['AGE_COHORTS']['ADULT_MAXIMAL_AGE']\n",
    "\n",
    "AGE_COHORT_NAMES = constants['AGE_COHORT_NAMES']\n",
    "AGE_COHORTS_KEYS = constants['AGE_COHORTS_KEYS']\n",
    "\n",
    "DIAGNOSIS_KEYS = constants['DIAGNOSIS_KEYS']\n",
    "\n",
    "SITE_CODES_REVERSED_MAP = constants['SITE_CODES_REVERSED_MAP']\n",
    "\n",
    "ATHENA_SOURCE = constants['DATA_SOURCES']['ATHENA_SOURCE_ROOT']\n",
    "RANDOM_SEED = constants['RANDOM_SEED']\n",
    "\n",
    "T_FIX = constants['TIME_SERIES']['T_FIX']\n",
    "WINDOW_SIZE = constants['TIME_SERIES']['WINDOW_SIZE']\n",
    "WINDOW_STEP = constants['TIME_SERIES']['WINDOW_STEP']\n",
    "FC_METRIC = constants['TIME_SERIES']['FC_METRIC']\n",
    "\n",
    "print(\"Константы загружены:\")\n",
    "print(f\"Дети: {CHILDREN_MINIMAL_AGE}-{CHILDREN_MAXIMAL_AGE} лет\")\n",
    "print(f\"Подростки: {TEEN_MINIMAL_AGE}-{TEEN_MAXIMAL_AGE} лет\")\n",
    "print(f\"Молодые взрослые: {ADULT_MINIMAL_AGE}-{ADULT_MAXIMAL_AGE} лет\")\n",
    "print(f\"Имена когорт по возрасту: {AGE_COHORT_NAMES}\")\n",
    "print(f\"Ключи когорт по возрасту: {AGE_COHORTS_KEYS}\")\n",
    "print(f\"Ключи диагнозов: {DIAGNOSIS_KEYS}\")\n",
    "print(f\"Коды сайтов (обратная карта): {SITE_CODES_REVERSED_MAP}\")\n",
    "print(f\"Путь к Athena Source: {ATHENA_SOURCE}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"T_FIX: {T_FIX}\")\n",
    "print(f\"WINDOW_SIZE: {WINDOW_SIZE}\")\n",
    "print(f\"WINDOW_STEP: {WINDOW_STEP}\")\n",
    "print(f\"FC_METRIC: {FC_METRIC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директория для экспериментов уже существует: ./Experiments\n",
      "Директория для чекпоинтов уже существует: Experiments/1_st_experiment_checkpoints\n",
      "Обучение моделей будет произведено на cpu\n",
      "EarlyStopping: metric=EarlyStopMetric.VAL_LOSS, patience=20\n",
      "Sanitize=True, GradClip=5.0, ReinitOnNaN=True, StagnationReset=3\n",
      "Salvage: Impute=ImputeStrategy.ROI_MEAN, SampleMaxNanFrac=0.98, RowMinFiniteFrac=0.3, ROI_drop<0.2, Interp=True\n"
     ]
    }
   ],
   "source": [
    "class ModelType(enum.Enum):\n",
    "    LSTM = 'LSTM'\n",
    "    GRU = 'GRU'\n",
    "    TCN = 'TCN'\n",
    "    MLP = 'MLP'\n",
    "\n",
    "class DataMode(enum.Enum):\n",
    "    SEQ_NPY = 'SEQ_NPY'\n",
    "    SEQ_TSV = 'SEQ_TSV'\n",
    "    DFC = 'DFC'\n",
    "\n",
    "class ImputeStrategy(enum.Enum):\n",
    "    ROI_MEAN = 'roi_mean'\n",
    "    GLOBAL_ZERO = 'global_zero'\n",
    "\n",
    "class BalanceStrategy(enum.Enum):\n",
    "    SAMPLER = 'sampler'\n",
    "    OVERSAMPLE = 'oversample'\n",
    "    LOSS_WEIGHT = 'loss_weight'\n",
    "\n",
    "class EarlyStopMetric(enum.Enum):\n",
    "    VAL_LOSS = 'val_loss'\n",
    "    VAL_ACCURACY = 'val_accuracy'\n",
    "    VAL_F1 = 'val_f1'\n",
    "\n",
    "class ClassWeightMode(enum.Enum):\n",
    "    INV_FREQ = 'inv_freq'\n",
    "    INV_SQRT_FREQ = 'inv_sqrt_freq'\n",
    "\n",
    "DATA_ROOT = './Athena_prepared_three_age_cohorts' # корневая директория с подготовленными данными (iter_3)\n",
    "MANIFEST_CSV = f'{DATA_ROOT}/manifest_windows_all_cohorts.csv'\n",
    "\n",
    "PHENO_CSV = \"../../SortedRawDataBIDS/participants_all_cohorts_pheno.tsv\"    # participant_id + метка (0..N_CLASSES-1) + Age + sex + site\n",
    "\n",
    "DFC_CSV = f'{DATA_ROOT}/aggregate_manifest_all_cohorts.csv'  # только если DATA_MODE=='DFC'\n",
    "\n",
    "EXPERIMENT_ROOT = f'./Experiments'\n",
    "if not os.path.exists(EXPERIMENT_ROOT):\n",
    "    os.makedirs(EXPERIMENT_ROOT)\n",
    "    print(f\"Создана директория для экспериментов: {EXPERIMENT_ROOT}\")\n",
    "else:\n",
    "    print(f\"Директория для экспериментов уже существует: {EXPERIMENT_ROOT}\")\n",
    "\n",
    "EXPERIMENT_NAME = '1_st_experiment'\n",
    "CHECKPOINT_DIR = str(Path(EXPERIMENT_ROOT)/f'{EXPERIMENT_NAME}_checkpoints')\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "    print(f\"Создана директория для чекпоинтов: {CHECKPOINT_DIR}\")\n",
    "else:\n",
    "    print(f\"Директория для чекпоинтов уже существует: {CHECKPOINT_DIR}\")\n",
    "\n",
    "REUSE_MODELS = False\n",
    "N_CLASSES = len(DIAGNOSIS_KEYS)    # число классов для классификации (0 - TD, 1 - ADHD-C, 2 - ADHD-HI, 3 - ADHD-I)\n",
    "EPOCHS = 50\n",
    "BATCH_TRAIN = 32\n",
    "BATCH_VAL = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# === Early Stopping ===\n",
    "EARLY_STOP_PATIENCE = 20\n",
    "EARLY_STOP_METRIC = EarlyStopMetric.VAL_LOSS    # 'val_loss' | 'val_accuracy' | 'val_f1'\n",
    "MIN_DELTA_IMPROVE = 1e-4\n",
    "\n",
    "# === Санитизация и стабильность ===\n",
    "SANITIZE_INPUTS = True\n",
    "ADD_EPS_NOISE_IF_ALL_ZERO = True\n",
    "MAX_GRAD_NORM = 5.0\n",
    "REINIT_ON_NAN = True\n",
    "STAGNATION_RESET_EPOCHS = 3\n",
    "HEAD_REINIT = True\n",
    "\n",
    "# === NaN / Imputation handling (salvage) ===\n",
    "IMPUTE_STRATEGY = ImputeStrategy.ROI_MEAN     # 'roi_mean' | 'global_zero'\n",
    "SAMPLE_MAX_NAN_FRAC = 0.98                    # итоговый порог после salvage\n",
    "ROW_MIN_FINITE_FRAC = 0.3                     # строка валидна если >=30% конечных значений (иначе удаляется)\n",
    "DROP_HIGH_NAN = True                          # удалять примеры только если nan_frac==1.0 (полностью испорчены)\n",
    "LOG_NAN_STATS = True                          # логировать статистику по NaN до и после salvage\n",
    "ROI_DROP_THRESHOLD = 0.2                      # удалить ROI (столбец), если доля конечных значений <20% в примере\n",
    "INTERPOLATE_NAN = True                        # линейная интерполяция по времени до mean-импутации\n",
    "\n",
    "# === Балансировка классов ===\n",
    "ENABLE_AUTOBALANCE = True\n",
    "BALANCE_STRATEGY = BalanceStrategy.SAMPLER    # 'sampler' | 'oversample' | 'loss_weight'        \n",
    "CLASS_WEIGHT_MODE = ClassWeightMode.INV_FREQ  # 'inv_freq' | 'inv_sqrt_freq'\n",
    "MAX_CLASS_WEIGHT_RATIO = 10.0                 # ограничение максимального веса класса\n",
    "\n",
    "LABEL_COLUMN_CANDIDATES = ['label','Label','DX','dx','Diagnosis','diagnosis']\n",
    "BINARY_MAP = {0:0, 1:1, 2:2, 3:3, 'ADHD-Combined':1, 'ADHD-Hyperactive/Impulsive':2, 'ADHD-Inattentive':3, 'TD':0, 'HC':0, 'Control':0}\n",
    "MULTICLASS = True\n",
    "\n",
    "USE_COVARIATES = False\n",
    "COV_CONT = ['age']\n",
    "COV_CATEGORIAL = ['sex','site']\n",
    "\n",
    "RUN_BASELINES = True\n",
    "FC_PCA_COMPONENTS = 200\n",
    "HMM_N_STATES = 5\n",
    "WIN_DYN = 30\n",
    "STEP_DYN = 5\n",
    "DO_LOSO = True\n",
    "VAL_SIZE = 0.2                        # доля валидационного сета при GroupShuffleSplit - 20%\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Обучение моделей будет произведено на {DEVICE}\")\n",
    "print(f\"EarlyStopping: metric={EARLY_STOP_METRIC}, patience={EARLY_STOP_PATIENCE}\")\n",
    "print(f\"Sanitize={SANITIZE_INPUTS}, GradClip={MAX_GRAD_NORM}, ReinitOnNaN={REINIT_ON_NAN}, StagnationReset={STAGNATION_RESET_EPOCHS}\")\n",
    "print(f\"Salvage: Impute={IMPUTE_STRATEGY}, SampleMaxNanFrac={SAMPLE_MAX_NAN_FRAC}, RowMinFiniteFrac={ROW_MIN_FINITE_FRAC}, ROI_drop<{ROI_DROP_THRESHOLD}, Interp={INTERPOLATE_NAN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Загрузка манифеста и фенотипов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1954, 15), (931, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man = pd.read_csv(MANIFEST_CSV)\n",
    "ph  = pd.read_csv(PHENO_CSV, delimiter='\\t') # для .tsv\n",
    "\n",
    "if 'participant_id' not in ph.columns:\n",
    "    for c in ph.columns:\n",
    "        if c.lower() in ('participant_id','subject','sub','id'):\n",
    "            ph = ph.rename(columns={c:'participant_id'})\n",
    "            break\n",
    "\n",
    "label_col = next((c for c in LABEL_COLUMN_CANDIDATES if c in ph.columns), None)\n",
    "assert label_col is not None, f'Нет метки среди: {LABEL_COLUMN_CANDIDATES}'\n",
    "\n",
    "ph = ph[['participant_id', label_col] + [c for c in COV_CONT+COV_CATEGORIAL if c in ph.columns]].copy()\n",
    "ph.rename(columns={label_col:'label'}, inplace=True)\n",
    "if not MULTICLASS:\n",
    "    ph['label'] = ph['label'].map(BINARY_MAP)\n",
    "\n",
    "man.shape, ph.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3e8fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "npy_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tsv_path",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atlas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nan_ratio_run",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age_cohort",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5fde2dbb-8d5b-4a63-99b4-f8fbd25e021a",
       "rows": [
        [
         "0",
         "sub-1043241",
         "1043241",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children"
        ],
        [
         "1",
         "sub-1266183",
         "1266183",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children"
        ],
        [
         "2",
         "sub-1535233",
         "1535233",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children"
        ],
        [
         "3",
         "sub-1541812",
         "1541812",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children"
        ],
        [
         "4",
         "sub-1577042",
         "1577042",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>tsv_path</th>\n",
       "      <th>atlas</th>\n",
       "      <th>TR</th>\n",
       "      <th>nan_ratio_run</th>\n",
       "      <th>age_cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-1043241</td>\n",
       "      <td>1043241</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-1266183</td>\n",
       "      <td>1266183</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-1535233</td>\n",
       "      <td>1535233</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-1541812</td>\n",
       "      <td>1541812</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-1577042</td>\n",
       "      <td>1577042</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  pid_raw site  site_original      run_id  win_index  segment_start  segment_end                                           npy_path                                          mask_path  tsv_path  atlas  TR  nan_ratio_run age_cohort\n",
       "0    sub-1043241  1043241  KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children\n",
       "1    sub-1266183  1266183  KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children\n",
       "2    sub-1535233  1535233  KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children\n",
       "3    sub-1541812  1541812  KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children\n",
       "4    sub-1577042  1577042  KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1954 entries, 0 to 1953\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   participant_id  1954 non-null   object \n",
      " 1   pid_raw         1954 non-null   int64  \n",
      " 2   site            1954 non-null   object \n",
      " 3   site_original   1954 non-null   int64  \n",
      " 4   run_id          1954 non-null   object \n",
      " 5   win_index       1954 non-null   int64  \n",
      " 6   segment_start   1954 non-null   int64  \n",
      " 7   segment_end     1954 non-null   int64  \n",
      " 8   npy_path        1954 non-null   object \n",
      " 9   mask_path       1954 non-null   object \n",
      " 10  tsv_path        0 non-null      float64\n",
      " 11  atlas           1954 non-null   object \n",
      " 12  TR              0 non-null      float64\n",
      " 13  nan_ratio_run   1954 non-null   float64\n",
      " 14  age_cohort      1954 non-null   object \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 229.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(man.head())\n",
    "display(man.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c6e2fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4efe6dd6-752d-4be8-938a-71cbdb338dcc",
       "rows": [
        [
         "0",
         "sub-2371032",
         "0",
         "10.73",
         "KKI"
        ],
        [
         "1",
         "sub-3434578",
         "0",
         "8.12",
         "KKI"
        ],
        [
         "2",
         "sub-8628223",
         "0",
         "10.81",
         "KKI"
        ],
        [
         "3",
         "sub-2930625",
         "0",
         "9.97",
         "KKI"
        ],
        [
         "4",
         "sub-3154996",
         "3",
         "11.65",
         "KKI"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-2371032</td>\n",
       "      <td>0</td>\n",
       "      <td>10.73</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-3434578</td>\n",
       "      <td>0</td>\n",
       "      <td>8.12</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-8628223</td>\n",
       "      <td>0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-2930625</td>\n",
       "      <td>0</td>\n",
       "      <td>9.97</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-3154996</td>\n",
       "      <td>3</td>\n",
       "      <td>11.65</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  label    age site\n",
       "0    sub-2371032      0  10.73  KKI\n",
       "1    sub-3434578      0   8.12  KKI\n",
       "2    sub-8628223      0  10.81  KKI\n",
       "3    sub-2930625      0   9.97  KKI\n",
       "4    sub-3154996      3  11.65  KKI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931 entries, 0 to 930\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   participant_id  931 non-null    object \n",
      " 1   label           931 non-null    int64  \n",
      " 2   age             931 non-null    float64\n",
      " 3   site            931 non-null    object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 29.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ph.head())\n",
    "display(ph.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Таблица примеров под режим\n",
    "\n",
    "Эта функция строит DataFrame с примерами для заданного режима работы модели (например, `SEQ_NPY` для таймсерий в формате `.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03243f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_for_mode(manifest, phenotypes, mode: DataMode) -> pd.DataFrame:\n",
    "    df = manifest.copy()\n",
    "    print(f\"Исходная таблица манифеста: {df.shape[0]} примеров\")\n",
    "    if mode==DataMode.SEQ_NPY:\n",
    "        df = df[df['npy_path'].notna()]\n",
    "        df['data_path'] = df['npy_path']\n",
    "    elif mode==DataMode.SEQ_TSV:\n",
    "        if 'tsv_path' not in df.columns:\n",
    "            raise ValueError(\"Нет 'tsv_path' в манифесте\")\n",
    "        df = df[df['tsv_path'].notna()]\n",
    "        df['data_path'] = df['tsv_path']\n",
    "    elif mode==DataMode.DFC:\n",
    "        dfc = pd.read_csv(DFC_CSV)\n",
    "        agg = (manifest.groupby('participant_id').agg({'site':'first','atlas':'first','TR':'median'}).reset_index())\n",
    "        df = dfc.merge(agg, on='participant_id', how='left')\n",
    "    else:\n",
    "        raise ValueError('Unknown mode')\n",
    "    print(f\"Построена таблица для режима {mode}: {df.shape[0]} примеров\")\n",
    "    df = df.merge(phenotypes, on='participant_id', how='inner')\n",
    "    df = df[df['label'].notna()].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная таблица манифеста: 1954 примеров\n",
      "Построена таблица для режима DataMode.SEQ_NPY: 1954 примеров\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "npy_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tsv_path",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atlas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nan_ratio_run",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age_cohort",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site_y",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b8a34185-1808-4743-82d6-df1a61769857",
       "rows": [
        [
         "0",
         "sub-1043241",
         "1043241",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy",
         "0",
         "9.12",
         "KKI"
        ],
        [
         "1",
         "sub-1266183",
         "1266183",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy",
         "0",
         "9.67",
         "KKI"
        ],
        [
         "2",
         "sub-1535233",
         "1535233",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy",
         "0",
         "9.64",
         "KKI"
        ],
        [
         "3",
         "sub-1541812",
         "1541812",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy",
         "1",
         "8.45",
         "KKI"
        ],
        [
         "4",
         "sub-1577042",
         "1577042",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy",
         "1",
         "9.06",
         "KKI"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site_x</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>tsv_path</th>\n",
       "      <th>atlas</th>\n",
       "      <th>TR</th>\n",
       "      <th>nan_ratio_run</th>\n",
       "      <th>age_cohort</th>\n",
       "      <th>data_path</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>site_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-1043241</td>\n",
       "      <td>1043241</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-1266183</td>\n",
       "      <td>1266183</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-1535233</td>\n",
       "      <td>1535233</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-1541812</td>\n",
       "      <td>1541812</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-1577042</td>\n",
       "      <td>1577042</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.06</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  pid_raw site_x  site_original      run_id  win_index  segment_start  segment_end                                           npy_path                                          mask_path  tsv_path  atlas  TR  nan_ratio_run age_cohort                                          data_path  label   age site_y\n",
       "0    sub-1043241  1043241    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.12    KKI\n",
       "1    sub-1266183  1266183    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.67    KKI\n",
       "2    sub-1535233  1535233    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.64    KKI\n",
       "3    sub-1541812  1541812    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      1  8.45    KKI\n",
       "4    sub-1577042  1577042    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      1  9.06    KKI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1953 entries, 0 to 1952\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   participant_id  1953 non-null   object \n",
      " 1   pid_raw         1953 non-null   int64  \n",
      " 2   site_x          1953 non-null   object \n",
      " 3   site_original   1953 non-null   int64  \n",
      " 4   run_id          1953 non-null   object \n",
      " 5   win_index       1953 non-null   int64  \n",
      " 6   segment_start   1953 non-null   int64  \n",
      " 7   segment_end     1953 non-null   int64  \n",
      " 8   npy_path        1953 non-null   object \n",
      " 9   mask_path       1953 non-null   object \n",
      " 10  tsv_path        0 non-null      float64\n",
      " 11  atlas           1953 non-null   object \n",
      " 12  TR              0 non-null      float64\n",
      " 13  nan_ratio_run   1953 non-null   float64\n",
      " 14  age_cohort      1953 non-null   object \n",
      " 15  data_path       1953 non-null   object \n",
      " 16  label           1953 non-null   int64  \n",
      " 17  age             1953 non-null   float64\n",
      " 18  site_y          1953 non-null   object \n",
      "dtypes: float64(4), int64(6), object(9)\n",
      "memory usage: 290.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = build_table_for_mode(man, ph, DataMode.SEQ_NPY)\n",
    "display(data_df.head())\n",
    "display(data_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d207599",
   "metadata": {},
   "source": [
    "Если DFC_CSV указан, то добавляются признаки динамического FC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2ed89aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная таблица манифеста: 1954 примеров\n",
      "Построена таблица для режима DataMode.DFC: 1954 примеров\n",
      "Загружены признаки динамического FC из ./Athena_prepared_three_age_cohorts/aggregate_manifest_all_cohorts.csv:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fc_dim",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "atlas_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age_cohort",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_y",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "atlas_y",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fe7d13a7-aec5-4b24-9be1-5a4778756fa9",
       "rows": [
        [
         "0",
         "sub-1043241",
         "1043241",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "62128",
         "CC400",
         null,
         "children",
         "KKI",
         "CC400",
         null,
         "0",
         "9.12",
         "KKI"
        ],
        [
         "1",
         "sub-1266183",
         "1266183",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "1",
         "62128",
         "CC400",
         null,
         "children",
         "KKI",
         "CC400",
         null,
         "0",
         "9.67",
         "KKI"
        ],
        [
         "2",
         "sub-1535233",
         "1535233",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "62128",
         "CC400",
         null,
         "children",
         "KKI",
         "CC400",
         null,
         "0",
         "9.64",
         "KKI"
        ],
        [
         "3",
         "sub-1541812",
         "1541812",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "62128",
         "CC400",
         null,
         "children",
         "KKI",
         "CC400",
         null,
         "1",
         "8.45",
         "KKI"
        ],
        [
         "4",
         "sub-1577042",
         "1577042",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "1",
         "62128",
         "CC400",
         null,
         "children",
         "KKI",
         "CC400",
         null,
         "1",
         "9.06",
         "KKI"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site_x</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>state_label</th>\n",
       "      <th>fc_dim</th>\n",
       "      <th>atlas_x</th>\n",
       "      <th>TR_x</th>\n",
       "      <th>age_cohort</th>\n",
       "      <th>site_y</th>\n",
       "      <th>atlas_y</th>\n",
       "      <th>TR_y</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-1043241</td>\n",
       "      <td>1043241</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62128</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>KKI</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-1266183</td>\n",
       "      <td>1266183</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62128</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>KKI</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-1535233</td>\n",
       "      <td>1535233</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62128</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>KKI</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-1541812</td>\n",
       "      <td>1541812</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62128</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>KKI</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-1577042</td>\n",
       "      <td>1577042</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62128</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "      <td>KKI</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9.06</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  pid_raw site_x  site_original      run_id  win_index  state_label  fc_dim atlas_x  TR_x age_cohort site_y atlas_y  TR_y  label   age site\n",
       "0    sub-1043241  1043241    KKI              3  ses1_rest1          0            0   62128   CC400   NaN   children    KKI   CC400   NaN      0  9.12  KKI\n",
       "1    sub-1266183  1266183    KKI              3  ses1_rest1          0            1   62128   CC400   NaN   children    KKI   CC400   NaN      0  9.67  KKI\n",
       "2    sub-1535233  1535233    KKI              3  ses1_rest1          0            0   62128   CC400   NaN   children    KKI   CC400   NaN      0  9.64  KKI\n",
       "3    sub-1541812  1541812    KKI              3  ses1_rest1          0            0   62128   CC400   NaN   children    KKI   CC400   NaN      1  8.45  KKI\n",
       "4    sub-1577042  1577042    KKI              3  ses1_rest1          0            1   62128   CC400   NaN   children    KKI   CC400   NaN      1  9.06  KKI"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1953 entries, 0 to 1952\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   participant_id  1953 non-null   object \n",
      " 1   pid_raw         1953 non-null   int64  \n",
      " 2   site_x          1953 non-null   object \n",
      " 3   site_original   1953 non-null   int64  \n",
      " 4   run_id          1953 non-null   object \n",
      " 5   win_index       1953 non-null   int64  \n",
      " 6   state_label     1953 non-null   int64  \n",
      " 7   fc_dim          1953 non-null   int64  \n",
      " 8   atlas_x         1953 non-null   object \n",
      " 9   TR_x            0 non-null      float64\n",
      " 10  age_cohort      1953 non-null   object \n",
      " 11  site_y          1953 non-null   object \n",
      " 12  atlas_y         1953 non-null   object \n",
      " 13  TR_y            0 non-null      float64\n",
      " 14  label           1953 non-null   int64  \n",
      " 15  age             1953 non-null   float64\n",
      " 16  site            1953 non-null   object \n",
      "dtypes: float64(3), int64(6), object(8)\n",
      "memory usage: 259.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df_dfc = None\n",
    "if DFC_CSV is not None:\n",
    "    data_df_dfc = build_table_for_mode(man, ph, DataMode.DFC)\n",
    "    print(f\"Загружены признаки динамического FC из {DFC_CSV}:\")\n",
    "    display(data_df_dfc.head())\n",
    "    display(data_df_dfc.info())\n",
    "else:\n",
    "    data_df_dfc = None\n",
    "    print(\"DFC_CSV не указан, признаки динамического FC не загружены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "da55985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvage_and_filter_pass(\n",
    "    data_df: pd.DataFrame,\n",
    "    data_mode: DataMode,\n",
    "    roi_drop_threshold: float,\n",
    "    log_nan_stats: bool = True,\n",
    "    drop_high_nan: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Выполняет 'salvage & filtering' проход:\n",
    "    - считает долю NaN до / после выбрасывания плохих ROI по каждому сэмплу,\n",
    "    - записывает колонки 'nan_frac_raw' и 'roi_drop_cnt',\n",
    "    - при необходимости выбрасывает полностью испорченные сэмплы (nan_frac_raw == 1.0).\n",
    "\n",
    "    Возвращает новый DataFrame (с reset_index, если были дропы).\n",
    "    \"\"\"\n",
    "    if data_mode not in (DataMode.SEQ_NPY, DataMode.SEQ_TSV):\n",
    "        print(\"[Salvage] Skipped (DFC mode)\")\n",
    "        return data_df\n",
    "\n",
    "    nan_fracs = []\n",
    "    roi_drop_counts = []\n",
    "    sample_paths = data_df[\"data_path\"].tolist()\n",
    "\n",
    "    for p in sample_paths:\n",
    "        try:\n",
    "            if data_mode == DataMode.SEQ_NPY:\n",
    "                arr = np.load(p)\n",
    "            else:\n",
    "                arr = pd.read_csv(\n",
    "                    p, sep=\"\\t\", header=None, compression=\"gzip\"\n",
    "                ).values\n",
    "\n",
    "            fin = np.isfinite(arr)\n",
    "            nan_frac = 1.0 - fin.mean()\n",
    "\n",
    "            # ROI salvage: дропаем столбцы (ROI) с низкой долей финитных значений\n",
    "            col_finite_ratio = fin.mean(axis=0)\n",
    "            bad_cols = np.where(col_finite_ratio < roi_drop_threshold)[0]\n",
    "            roi_drop_counts.append(len(bad_cols))\n",
    "\n",
    "            if len(bad_cols) > 0 and len(bad_cols) < arr.shape[1]:\n",
    "                arr = np.delete(arr, bad_cols, axis=1)\n",
    "\n",
    "            # пересчёт nan_frac после удаления колонок\n",
    "            fin2 = np.isfinite(arr)\n",
    "            nan_frac = 1.0 - fin2.mean()\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"Ошибка при загрузке сэмпла {p}, помечаем как полностью NaN\")\n",
    "            nan_frac = 1.0\n",
    "            roi_drop_counts.append(np.nan)\n",
    "\n",
    "        nan_fracs.append(nan_frac)\n",
    "\n",
    "    data_df = data_df.copy()\n",
    "    data_df[\"nan_frac_raw\"] = nan_fracs\n",
    "    data_df[\"roi_drop_cnt\"] = roi_drop_counts\n",
    "\n",
    "    if log_nan_stats:\n",
    "        print(\"[Salvage] Raw nan_frac describe:\")\n",
    "        print(data_df[\"nan_frac_raw\"].describe())\n",
    "        print(\"[Salvage] ROI drop count describe:\")\n",
    "        print(data_df[\"roi_drop_cnt\"].describe())\n",
    "\n",
    "    # Дропаем только полностью испорченные сэмплы\n",
    "    if drop_high_nan:\n",
    "        before = len(data_df)\n",
    "        data_df = data_df[data_df[\"nan_frac_raw\"] < 1.0].reset_index(drop=True)\n",
    "        print(f\"[Salvage] Dropped {before - len(data_df)} fully NaN samples\")\n",
    "\n",
    "    # Гистограмма\n",
    "    if log_nan_stats:\n",
    "        hist_vals = data_df[\"nan_frac_raw\"].values\n",
    "        bins = np.linspace(0, 1, 11)\n",
    "        hist, _ = np.histogram(hist_vals, bins=bins)\n",
    "        print(\"[Salvage] nan_frac histogram (bins 0..1 step 0.1):\", hist)\n",
    "        \n",
    "    return data_df\n",
    "\n",
    "\n",
    "def nan_filter_before_splits(\n",
    "    data_df: pd.DataFrame,\n",
    "    data_mode: DataMode,\n",
    "    sample_max_nan_frac: float,\n",
    "    log_nan_stats: bool = True,\n",
    "    drop_high_nan: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считает долю NaN по каждому сэмплу и фильтрует по порогу sample_max_nan_frac.\n",
    "    Записывает колонку 'nan_frac' и возвращает новый DataFrame.\n",
    "    \"\"\"\n",
    "    nan_fracs = []\n",
    "    \n",
    "    if data_mode not in (DataMode.SEQ_NPY, DataMode.SEQ_TSV):\n",
    "        print(\"[NaN] Skipped filtering (DFC mode)\")\n",
    "        data_df[\"nan_frac\"] = np.zeros(len(data_df))\n",
    "        return data_df\n",
    "\n",
    "    for p in data_df[\"data_path\"]:\n",
    "        try:\n",
    "            if data_mode == DataMode.SEQ_NPY:\n",
    "                arr = np.load(p)\n",
    "            else:\n",
    "                arr = pd.read_csv(\n",
    "                    p, sep=\"\\t\", header=None, compression=\"gzip\"\n",
    "                ).values\n",
    "            total = arr.size\n",
    "            nan_count = np.isnan(arr).sum()\n",
    "            nan_frac = nan_count / total if total > 0 else 0.0\n",
    "        except Exception:\n",
    "            nan_frac = 1.0\n",
    "\n",
    "        nan_fracs.append(nan_frac)\n",
    "\n",
    "    data_df = data_df.copy()\n",
    "    data_df[\"nan_frac\"] = nan_fracs\n",
    "\n",
    "    if log_nan_stats:\n",
    "        print(\"[NaN] Summary before filtering:\")\n",
    "        print(data_df[\"nan_frac\"].describe())\n",
    "        print(\n",
    "            \"[NaN] Count > SAMPLE_MAX_NAN_FRAC:\",\n",
    "            (data_df[\"nan_frac\"] > sample_max_nan_frac).sum(),\n",
    "        )\n",
    "\n",
    "    if drop_high_nan:\n",
    "        kept_df = data_df[data_df[\"nan_frac\"] <= sample_max_nan_frac].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        dropped = len(data_df) - len(kept_df)\n",
    "        print(\n",
    "            f\"[NaN] Dropped {dropped} / {len(data_df)} samples \"\n",
    "            f\"(>{sample_max_nan_frac*100:.1f}% NaN)\"\n",
    "        )\n",
    "        data_df = kept_df\n",
    "\n",
    "    return data_df\n",
    "\n",
    "def add_n_roi_column(data_df: pd.DataFrame, mode: DataMode) -> pd.DataFrame:\n",
    "    n_roi_list = []\n",
    "    for p in data_df[\"data_path\"]:\n",
    "        try:\n",
    "            if mode == DataMode.SEQ_NPY:\n",
    "                arr = np.load(p)\n",
    "            elif mode == DataMode.SEQ_TSV:\n",
    "                arr = pd.read_csv(p, sep=\"\\t\", header=None, compression=\"gzip\").values\n",
    "            else:\n",
    "                arr = None\n",
    "            n_roi_list.append(arr.shape[1] if arr is not None else 0)\n",
    "        except Exception:\n",
    "            n_roi_list.append(0)\n",
    "    df = data_df.copy()\n",
    "    df[\"n_roi\"] = n_roi_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463d81c",
   "metadata": {},
   "source": [
    "### Проверка доли NaN в данных (для таймсерий SEQ_NPY/SEQ_TSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0c1cb8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Формы сырых сэмплов ДО salvage ===\n",
      "n_roi\n",
      "353    1921\n",
      "1        32\n",
      "Name: count, dtype: int64\n",
      "[ROI size] target_n_roi: 353\n",
      "[ROI size] Плохих сэмплов (неправильный n_roi): 32\n",
      "    participant_id                                          data_path  n_roi\n",
      "91     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "92     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "93     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "94     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "103    sub-0010027  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "[ROI size] Размер после фильтрации по размеру ROI: (1921, 20)\n",
      "n_roi\n",
      "353    1921\n",
      "1        32\n",
      "Name: count, dtype: int64\n",
      "[ROI size] target_n_roi: 353\n",
      "[ROI size] Плохих сэмплов (неправильный n_roi): 32\n",
      "    participant_id                                          data_path  n_roi\n",
      "91     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "92     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "93     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "94     sub-0010016  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "103    sub-0010027  Athena_prepared_three_age_cohorts/cohort_child...      1\n",
      "[ROI size] Размер после фильтрации по размеру ROI: (1921, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Формы сырых сэмплов ДО salvage ===\")\n",
    "data_df = add_n_roi_column(data_df, mode=DataMode.SEQ_NPY)\n",
    "print(data_df[\"n_roi\"].value_counts().head())\n",
    "\n",
    "target_n_roi = data_df[\"n_roi\"].mode().iloc[0]\n",
    "print(\"[ROI size] target_n_roi:\", target_n_roi)\n",
    "\n",
    "bad_mask = data_df[\"n_roi\"] != target_n_roi\n",
    "print(\"[ROI size] Плохих сэмплов (неправильный n_roi):\", bad_mask.sum())\n",
    "if bad_mask.sum() > 0:\n",
    "    print(data_df.loc[bad_mask, [\"participant_id\", \"data_path\", \"n_roi\"]].head())\n",
    "\n",
    "# Отфильтруем файлы с \"битой\" маской, если они есть\n",
    "data_df = data_df[~bad_mask].reset_index(drop=True)\n",
    "print(\"[ROI size] Размер после фильтрации по размеру ROI:\", data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c088bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Salvage & Filtering pass ===\n",
      "[Salvage] Raw nan_frac describe:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: nan_frac_raw, dtype: float64\n",
      "[Salvage] ROI drop count describe:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: roi_drop_cnt, dtype: float64\n",
      "[Salvage] Dropped 0 fully NaN samples\n",
      "[Salvage] nan_frac histogram (bins 0..1 step 0.1): [1921    0    0    0    0    0    0    0    0    0]\n",
      "Размер после salvage: (1921, 22)\n",
      "[Salvage] Raw nan_frac describe:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: nan_frac_raw, dtype: float64\n",
      "[Salvage] ROI drop count describe:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: roi_drop_cnt, dtype: float64\n",
      "[Salvage] Dropped 0 fully NaN samples\n",
      "[Salvage] nan_frac histogram (bins 0..1 step 0.1): [1921    0    0    0    0    0    0    0    0    0]\n",
      "Размер после salvage: (1921, 22)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "npy_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tsv_path",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atlas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nan_ratio_run",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age_cohort",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "data_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "site_y",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_roi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nan_frac_raw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roi_drop_cnt",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d5a66916-603e-4977-84ee-b5c5b74f7e22",
       "rows": [
        [
         "0",
         "sub-1043241",
         "1043241",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy",
         "0",
         "9.12",
         "KKI",
         "353",
         "0.0",
         "0"
        ],
        [
         "1",
         "sub-1266183",
         "1266183",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy",
         "0",
         "9.67",
         "KKI",
         "353",
         "0.0",
         "0"
        ],
        [
         "2",
         "sub-1535233",
         "1535233",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy",
         "0",
         "9.64",
         "KKI",
         "353",
         "0.0",
         "0"
        ],
        [
         "3",
         "sub-1541812",
         "1541812",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy",
         "1",
         "8.45",
         "KKI",
         "353",
         "0.0",
         "0"
        ],
        [
         "4",
         "sub-1577042",
         "1577042",
         "KKI",
         "3",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "children",
         "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy",
         "1",
         "9.06",
         "KKI",
         "353",
         "0.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site_x</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>tsv_path</th>\n",
       "      <th>atlas</th>\n",
       "      <th>TR</th>\n",
       "      <th>nan_ratio_run</th>\n",
       "      <th>age_cohort</th>\n",
       "      <th>data_path</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>site_y</th>\n",
       "      <th>n_roi</th>\n",
       "      <th>nan_frac_raw</th>\n",
       "      <th>roi_drop_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-1043241</td>\n",
       "      <td>1043241</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.12</td>\n",
       "      <td>KKI</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-1266183</td>\n",
       "      <td>1266183</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>KKI</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-1535233</td>\n",
       "      <td>1535233</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>KKI</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-1541812</td>\n",
       "      <td>1541812</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "      <td>KKI</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-1577042</td>\n",
       "      <td>1577042</td>\n",
       "      <td>KKI</td>\n",
       "      <td>3</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>children</td>\n",
       "      <td>Athena_prepared_three_age_cohorts/cohort_child...</td>\n",
       "      <td>1</td>\n",
       "      <td>9.06</td>\n",
       "      <td>KKI</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  pid_raw site_x  site_original      run_id  win_index  segment_start  segment_end                                           npy_path                                          mask_path  tsv_path  atlas  TR  nan_ratio_run age_cohort                                          data_path  label   age site_y  n_roi  nan_frac_raw  roi_drop_cnt\n",
       "0    sub-1043241  1043241    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.12    KKI    353           0.0             0\n",
       "1    sub-1266183  1266183    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.67    KKI    353           0.0             0\n",
       "2    sub-1535233  1535233    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      0  9.64    KKI    353           0.0             0\n",
       "3    sub-1541812  1541812    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      1  8.45    KKI    353           0.0             0\n",
       "4    sub-1577042  1577042    KKI              3  ses1_rest1          0              0          200  Athena_prepared_three_age_cohorts/cohort_child...  Athena_prepared_three_age_cohorts/cohort_child...       NaN  CC400 NaN            0.0   children  Athena_prepared_three_age_cohorts/cohort_child...      1  9.06    KKI    353           0.0             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NaN filtering before splits ===\n",
      "[NaN] Summary before filtering:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: nan_frac, dtype: float64\n",
      "[NaN] Count > SAMPLE_MAX_NAN_FRAC: 0\n",
      "[NaN] Dropped 0 / 1921 samples (>98.0% NaN)\n",
      "Размер после NaN фильтрации: (1921, 23)\n",
      "Top nan_frac head:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: nan_frac, dtype: float64\n",
      "[NaN] Summary before filtering:\n",
      "count    1921.0\n",
      "mean        0.0\n",
      "std         0.0\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         0.0\n",
      "Name: nan_frac, dtype: float64\n",
      "[NaN] Count > SAMPLE_MAX_NAN_FRAC: 0\n",
      "[NaN] Dropped 0 / 1921 samples (>98.0% NaN)\n",
      "Размер после NaN фильтрации: (1921, 23)\n",
      "Top nan_frac head:\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: nan_frac, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# === Salvage & Filtering pass ===\n",
    "print(\"=== Salvage & Filtering pass ===\")\n",
    "data_df = salvage_and_filter_pass(\n",
    "    data_df,\n",
    "    data_mode=DataMode.SEQ_NPY,\n",
    "    roi_drop_threshold=ROI_DROP_THRESHOLD,\n",
    "    log_nan_stats=LOG_NAN_STATS,\n",
    "    drop_high_nan=DROP_HIGH_NAN,\n",
    ")\n",
    "\n",
    "print(\"Размер после salvage:\", data_df.shape)\n",
    "display(data_df.head())\n",
    "\n",
    "# === Фильтрация примеров по доле NaN до сплитов ===\n",
    "print(\"\\n=== NaN filtering before splits ===\")\n",
    "data_df = nan_filter_before_splits(\n",
    "    data_df,\n",
    "    data_mode=DataMode.SEQ_NPY,\n",
    "    sample_max_nan_frac=SAMPLE_MAX_NAN_FRAC,\n",
    "    log_nan_stats=LOG_NAN_STATS,\n",
    "    drop_high_nan=DROP_HIGH_NAN,\n",
    ")\n",
    "\n",
    "print(\"Размер после NaN фильтрации:\", data_df.shape)\n",
    "print(\"Top nan_frac head:\")\n",
    "print(data_df[\"nan_frac\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e2ed285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Анализ форм сэмплов ===\n",
      "Уникальные формы сэмплов (T, ROI) и их количество:\n",
      "[200   1] => 32\n",
      "[200 353] => 1921\n",
      "Уникальные формы сэмплов (T, ROI) и их количество:\n",
      "[200   1] => 32\n",
      "[200 353] => 1921\n"
     ]
    }
   ],
   "source": [
    "# === Анализ форм сэмплов ===\n",
    "print(\"\\n=== Анализ форм сэмплов ===\")\n",
    "\n",
    "def get_sample_shape(path: str, mode: DataMode) -> tuple:\n",
    "    if mode == DataMode.SEQ_NPY:\n",
    "        arr = np.load(path)\n",
    "    else:\n",
    "        arr = pd.read_csv(path, sep='\\t', header=None, compression='gzip').values\n",
    "    return arr.shape\n",
    "\n",
    "shapes = []\n",
    "for p in data_df['data_path']:\n",
    "    arr_shape = get_sample_shape(p, DataMode.SEQ_NPY)\n",
    "    shapes.append(arr_shape)\n",
    "\n",
    "unique_shapes, counts = np.unique(np.array(shapes), axis=0, return_counts=True)\n",
    "print(\"Уникальные формы сэмплов (T, ROI) и их количество:\")\n",
    "for s, c in zip(unique_shapes, counts):\n",
    "    print(s, \"=>\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8aa0d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: label\n",
      "0    0.605934\n",
      "1    0.207704\n",
      "3    0.169183\n",
      "2    0.017179\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверка, что лейблы не испорчены одним классом после фильтров:\n",
    "print(\"Label distribution:\", data_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6869323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка загрузки первых 10 сэмплов (SEQ_NPY):\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1043241/sub-1043241_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.8582435\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1266183/sub-1266183_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1535233/sub-1535233_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.8582435\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1541812/sub-1541812_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1577042/sub-1577042_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1638334/sub-1638334_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1652369/sub-1652369_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1686265/sub-1686265_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1692275/sub-1692275_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n",
      "Athena_prepared_three_age_cohorts/cohort_children_participants/sub-1735881/sub-1735881_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.7734105\n"
     ]
    }
   ],
   "source": [
    "print('Проверка загрузки первых 10 сэмплов (SEQ_NPY):')\n",
    "test_paths = data_df['data_path'].head(10).tolist()\n",
    "for p in test_paths:\n",
    "    x = np.load(p)\n",
    "    print(p, 'nan%', np.isnan(x).mean()*100, 'std_mean', x.std(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Сплиты без утечки и ковариаты\n",
    "\n",
    "Эта функция создаёт сплиты по участникам/сайтам, чтобы избежать утечек между обучением и валидацией. Также она извлекает ковариаты (возраст, пол) для использования в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для текущего разбиения: длина 5\n",
      "Ковариаты не используются.\n"
     ]
    }
   ],
   "source": [
    "groups = data_df['participant_id'].astype(str).values\n",
    "y = data_df['label'].values\n",
    "if len(np.unique(y)) > 1:\n",
    "    splitter = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "else:\n",
    "    splitter = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=SEED)\n",
    "folds = list(splitter.split(X=np.zeros_like(y), y=y, groups=groups))\n",
    "\n",
    "cov_cols_cont = [c for c in COV_CONT if c in data_df.columns]\n",
    "cov_cols_cat  = [c for c in COV_CATEGORIAL  if c in data_df.columns]\n",
    "if USE_COVARIATES and (cov_cols_cont or cov_cols_cat):\n",
    "    pre = ColumnTransformer([\n",
    "        ('cont', StandardScaler(), cov_cols_cont),\n",
    "        ('cat',  OneHotEncoder(handle_unknown='ignore'), cov_cols_cat)\n",
    "    ])\n",
    "else:\n",
    "    pre = None\n",
    "\n",
    "# Выведем информацию о разбиении и ковариатах\n",
    "print(f\"Для текущего разбиения: длина {len(folds)}\")\n",
    "if USE_COVARIATES:\n",
    "    print(f\"Числовые ковариаты - {cov_cols_cont}, категориальные ковариаты - {cov_cols_cat}\")\n",
    "else:\n",
    "    print(\"Ковариаты не используются.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Датасеты и DataLoader’ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame,\n",
    "                 mode: DataMode,\n",
    "                 impute_strategy: ImputeStrategy = IMPUTE_STRATEGY,\n",
    "                 add_eps_noise_if_all_zero: bool = ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                 cov_pre=None,\n",
    "                 roi_keep_idx=None):\n",
    "        assert mode in (DataMode.SEQ_NPY, DataMode.SEQ_TSV), 'TimeSeriesDataset поддерживает только SEQ_NPY и SEQ_TSV режимы'\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.impute_strategy = impute_strategy\n",
    "        self.add_eps_noise_if_all_zero = add_eps_noise_if_all_zero\n",
    "        self.cov_pre = cov_pre\n",
    "        self.roi_keep_idx = roi_keep_idx\n",
    "        if cov_pre is not None:\n",
    "            cov_input = self.df[[c for c in (cov_cols_cont+cov_cols_cat) if c in self.df.columns]].copy()\n",
    "            self.cov = cov_pre.transform(cov_input)\n",
    "            self.cov = np.asarray(self.cov, dtype=np.float32)\n",
    "        else:\n",
    "            self.cov = None\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        if self.mode==DataMode.SEQ_NPY:\n",
    "            x = np.load(r['data_path']).astype('float32')\n",
    "        else:\n",
    "            x = pd.read_csv(r['data_path'], sep='\\t', header=None, compression='gzip').values.astype('float32')\n",
    "        \n",
    "        if self.roi_keep_idx is not None:\n",
    "            x = x[:, self.roi_keep_idx]\n",
    "\n",
    "        # NaN stats per sample for debug (not persisted each call to avoid slowdown)\n",
    "        finite_mask = np.isfinite(x)\n",
    "        # Build time mask: row valid if fraction finite >= ROW_MIN_FINITE_FRAC\n",
    "        row_valid = (finite_mask.sum(axis=1) / (finite_mask.shape[1] if finite_mask.shape[1] > 0 else 1)) >= ROW_MIN_FINITE_FRAC\n",
    "        # Impute NaNs\n",
    "        if self.impute_strategy == ImputeStrategy.ROI_MEAN:  # per-ROI mean imputation\n",
    "            roi_means = np.where(np.isfinite(x[row_valid]).sum(axis=0)>0, np.nanmean(x[row_valid], axis=0), 0.0)\n",
    "            # Replace NaNs with corresponding roi mean\n",
    "            nan_positions = ~finite_mask\n",
    "            if x.shape[1] > 0:\n",
    "                x[nan_positions] = np.take(roi_means, np.where(nan_positions)[1])\n",
    "        else:  # global_zero\n",
    "            x[~finite_mask] = 0.0\n",
    "        if self.add_eps_noise_if_all_zero and not np.any(x):\n",
    "            x += (np.random.randn(*x.shape).astype('float32')) * 1e-3\n",
    "        # Final sanitize\n",
    "        x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        m = row_valid.astype('float32')  # mask of valid timepoints\n",
    "        # If external mask exists, AND it\n",
    "        mpath = r.get('mask_path', None)\n",
    "        if isinstance(mpath, str) and len(mpath)>0 and Path(mpath).exists():\n",
    "            ext_m = np.load(mpath).astype('float32')\n",
    "            if ext_m.shape[0] == m.shape[0]:\n",
    "                m = m * ext_m\n",
    "        if self.cov is not None:\n",
    "            cov_t = torch.from_numpy(self.cov[i])\n",
    "        else:\n",
    "            cov_t = torch.empty(0)\n",
    "        y = int(r['label'])\n",
    "        pid = str(r['participant_id'])\n",
    "        return torch.from_numpy(x), torch.from_numpy(m), cov_t, torch.tensor(y), pid\n",
    "\n",
    "class DFCDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame,\n",
    "                 impute_strategy: ImputeStrategy = IMPUTE_STRATEGY,\n",
    "                 add_eps_noise_if_all_zero: bool = ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                 cov_pre=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cov_pre = cov_pre\n",
    "        self.impute_strategy = impute_strategy\n",
    "        self.add_eps_noise_if_all_zero = add_eps_noise_if_all_zero\n",
    "        drop_cols = {'participant_id','site','atlas','TR','label'}\n",
    "        self.feat_cols = [c for c in self.df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(self.df[c])]\n",
    "        if cov_pre is not None:\n",
    "            cov_input = self.df[[c for c in (cov_cols_cont+cov_cols_cat) if c in self.df.columns]].copy()\n",
    "            self.cov = cov_pre.transform(cov_input)\n",
    "            self.cov = np.asarray(self.cov, dtype=np.float32)\n",
    "        else:\n",
    "            self.cov = None\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        x = self.df.loc[i, self.feat_cols].values.astype('float32')\n",
    "        if self.impute_strategy == ImputeStrategy.ROI_MEAN:  # treat each feature individually\n",
    "            if not np.isfinite(x).all():\n",
    "                bad = ~np.isfinite(x)\n",
    "                x[bad] = 0.0  # cannot compute per-feature mean without temporal axis\n",
    "        else:\n",
    "            x[~np.isfinite(x)] = 0.0\n",
    "        if self.add_eps_noise_if_all_zero and not np.any(x):\n",
    "            x += (np.random.randn(*x.shape).astype('float32')) * 1e-3\n",
    "        if self.cov is not None:\n",
    "            cov_t = torch.from_numpy(self.cov[i])\n",
    "        else:\n",
    "            cov_t = torch.empty(0)\n",
    "        y = int(r['label'])\n",
    "        pid = str(r['participant_id'])\n",
    "        return torch.from_numpy(x), torch.tensor(1.0), cov_t, torch.tensor(y), pid\n",
    "\n",
    "# Oversampling helper (replicate minority rows)\n",
    "def oversample_df(df, label_col='label'):\n",
    "    counts = df[label_col].value_counts()\n",
    "    max_n = counts.max()\n",
    "    parts = []\n",
    "    for lab, cnt in counts.items():\n",
    "        subset = df[df[label_col]==lab]\n",
    "        if cnt == max_n:\n",
    "            parts.append(subset)\n",
    "        else:\n",
    "            reps = int(np.ceil(max_n / cnt))\n",
    "            augmented = pd.concat([subset]*reps, ignore_index=True).iloc[:max_n]\n",
    "            parts.append(augmented)\n",
    "    out = pd.concat(parts, ignore_index=True).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def make_fold_dataloaders(df, fold_idx=0,\n",
    "                          mode: DataMode = DataMode.SEQ_NPY,\n",
    "                          enable_autobalance=ENABLE_AUTOBALANCE,\n",
    "                          balance_strategy=BALANCE_STRATEGY,\n",
    "                          class_weight_mode=CLASS_WEIGHT_MODE,\n",
    "                          max_class_weight_ratio=MAX_CLASS_WEIGHT_RATIO,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          impute_strategy: ImputeStrategy = IMPUTE_STRATEGY,\n",
    "                          add_eps_noise_if_all_zero: bool = ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                          cov_pipeline=None):\n",
    "    groups = df['participant_id'].astype(str).values\n",
    "    y = df['label'].values\n",
    "    class_counts = pd.Series(y).value_counts()\n",
    "    base_splits = 5\n",
    "    min_class = class_counts.min()\n",
    "    n_splits = base_splits if min_class >= base_splits else max(2, int(min_class))\n",
    "    if len(np.unique(y))>1 and n_splits >=2:\n",
    "        splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    folds = list(splitter.split(X=np.zeros_like(y), y=y, groups=groups))\n",
    "    if fold_idx >= len(folds):\n",
    "        fold_idx = 0\n",
    "    tr_idx, va_idx = folds[fold_idx]\n",
    "\n",
    "    df_train = df.iloc[tr_idx].copy()\n",
    "    df_val = df.iloc[va_idx].copy()\n",
    "\n",
    "    if enable_autobalance and balance_strategy == BalanceStrategy.OVERSAMPLE:\n",
    "        df_train = oversample_df(df_train, label_col='label')\n",
    "\n",
    "    if cov_pipeline is not None:\n",
    "        cov_fitted = Pipeline(steps=cov_pipeline.steps) if hasattr(cov_pipeline,'steps') else cov_pipeline\n",
    "        cov_fitted.fit(df_train[[c for c in (cov_cols_cont+cov_cols_cat) if c in df_train.columns]])\n",
    "    else:\n",
    "        cov_fitted = None\n",
    "\n",
    "    if mode in (DataMode.SEQ_NPY, DataMode.SEQ_TSV):\n",
    "        train_ds = TimeSeriesDataset(df_train, mode, impute_strategy=impute_strategy, add_eps_noise_if_all_zero=add_eps_noise_if_all_zero, cov_pre=cov_fitted)\n",
    "        val_ds = TimeSeriesDataset(df_val, mode, impute_strategy=impute_strategy, add_eps_noise_if_all_zero=add_eps_noise_if_all_zero, cov_pre=cov_fitted)\n",
    "    else:\n",
    "        train_ds = DFCDataset(df_train, impute_strategy=impute_strategy, add_eps_noise_if_all_zero=add_eps_noise_if_all_zero, cov_pre=cov_fitted)\n",
    "        val_ds = DFCDataset(df_val, impute_strategy=impute_strategy, add_eps_noise_if_all_zero=add_eps_noise_if_all_zero, cov_pre=cov_fitted)\n",
    "    if enable_autobalance and balance_strategy == BalanceStrategy.SAMPLER:\n",
    "        labels_train = df_train['label'].values\n",
    "        counts_train = pd.Series(labels_train).value_counts()\n",
    "        if class_weight_mode == ClassWeightMode.INV_SQRT_FREQ:\n",
    "            raw_w = {lab: 1.0/np.sqrt(cnt) for lab,cnt in counts_train.items()}\n",
    "        else:\n",
    "            raw_w = {lab: 1.0/cnt for lab,cnt in counts_train.items()}\n",
    "        w_vals = np.array(list(raw_w.values()))\n",
    "        w_vals /= w_vals.min()\n",
    "        ratio = w_vals.max()/w_vals.min()\n",
    "        if ratio > max_class_weight_ratio:\n",
    "            w_vals = w_vals / w_vals.max() * max_class_weight_ratio\n",
    "        for i,(lab,_) in enumerate(raw_w.items()):\n",
    "            raw_w[lab] = w_vals[i]\n",
    "        sample_weights = np.array([raw_w[lab] for lab in labels_train], dtype=np.float64)\n",
    "        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Модели: LSTM / GRU / MLP / TCN+BiGRU+Self-Attention (SE, FiLM) - ROISequenceNet\n",
    "- **LSTM/GRU**: компактные RNN-блоки. Ковариаты (если есть) конкатенируются к финальному скрытому состоянию.\n",
    "- **MLP**: полносвязная сеть по усреднённым по времени признакам (среднее/дисперсия по ROI).\n",
    "- **ROISequenceNet (TCN+BiGRU+Self-Attention+SE+FiLM)**: темпоральные свёртки (локальные паттерны) → двунаправленный GRU (дальние зависимости) → self-attention и SE-внимание по ROI; ковариаты подаются через FiLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _final_timestep_from_packed(out_padded, lengths):\n",
    "    # out_padded: (B, T_max, H*) после pad_packed_sequence\n",
    "    # lengths: (B,) реальные длины (int64)\n",
    "    idx = (lengths - 1).to(out_padded.device)                 # (B,)\n",
    "    B = out_padded.size(0)\n",
    "    return out_padded[torch.arange(B, device=out_padded.device), idx]  # (B, H*)\n",
    "\n",
    "# === Простые модели LSTM / GRU / MLP ===\n",
    "\n",
    "# Простая модель LSTM для классификации временных рядов\n",
    "# Вход: (B,T,R) - батч временных рядов с R признаками\n",
    "# Выход: (B,C) - логиты по классам\n",
    "# Используется последний таймстеп LSTM\n",
    "# Число слоёв, bidir, дропаут настраиваются через параметры. Дефолтные значение: 1 слой, unidir, dropout=0.2.\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, n_rois, n_classes=2, cov_dim=0, hidden=128, num_layers=1,\n",
    "                 bidir=False, dropout=0.2, use_pack=False):\n",
    "        super().__init__()\n",
    "        self.use_pack = use_pack\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_rois, hidden_size=hidden, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=bidir,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        d = hidden * (2 if bidir else 1)\n",
    "        self.cov_proj = nn.Linear(cov_dim, d) if cov_dim > 0 else None\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        # x: (B,T,R), mask: (B,T) in {0,1}\n",
    "        if self.use_pack and mask is not None:\n",
    "            lengths = mask.sum(dim=1).to(torch.int64).cpu()\n",
    "            packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            out, _ = self.lstm(packed)\n",
    "            out_padded, _ = pad_packed_sequence(out, batch_first=True)  # (B,T_max,H*)\n",
    "            h = _final_timestep_from_packed(out_padded, lengths)        # (B,H*)\n",
    "        else:\n",
    "            if mask is not None:\n",
    "                x = x * mask.unsqueeze(-1)  # простой и быстрый вариант\n",
    "            out, _ = self.lstm(x)           # (B,T,H*)\n",
    "            h = out[:, -1]                  # берём последний таймстеп\n",
    "\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            h = h + self.cov_proj(cov)\n",
    "        return self.head(h)\n",
    "\n",
    "# Простая модель GRU для классификации временных рядов\n",
    "# Вход: (B,T,R) - батч временных рядов с R признаками\n",
    "# Выход: (B,C) - логиты по классам\n",
    "# Используется последний таймстеп GRU\n",
    "# Число слоёв, bidir, дропаут настраиваются через параметры. Дефолтные значение: 1 слой, unidir, dropout=0.2.\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, n_rois, n_classes=2, cov_dim=0, hidden=128, num_layers=1,\n",
    "                 bidir=False, dropout=0.2, use_pack=False):\n",
    "        super().__init__()\n",
    "        self.use_pack = use_pack\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_rois, hidden_size=hidden, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=bidir,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        d = hidden * (2 if bidir else 1)\n",
    "        self.cov_proj = nn.Linear(cov_dim, d) if cov_dim > 0 else None\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        # x: (B,T,R), mask: (B,T) in {0,1}\n",
    "        if self.use_pack and mask is not None:\n",
    "            lengths = mask.sum(dim=1).to(torch.int64).cpu()\n",
    "            packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            out, _ = self.gru(packed)\n",
    "            out_padded, _ = pad_packed_sequence(out, batch_first=True)  # (B,T_max,H*)\n",
    "            h = _final_timestep_from_packed(out_padded, lengths)        # (B,H*)\n",
    "        else:\n",
    "            if mask is not None:\n",
    "                x = x * mask.unsqueeze(-1)\n",
    "            out, _ = self.gru(x)\n",
    "            h = out[:, -1]\n",
    "\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            h = h + self.cov_proj(cov)\n",
    "        return self.head(h)\n",
    "\n",
    "# Простая MLP модель для классификации (для DFC)\n",
    "# Вход: (B,F) - батч с F признаками\n",
    "# Выход: (B,C) - логиты по классам\n",
    "# Число слоёв, дропаут настраиваются через параметры. Дефолтные значение: 2 слоя, dropout=0.2.\n",
    "class  SimpleMLP(nn.Module):  # для DFC\n",
    "    def __init__(self, in_dim, n_classes=2, cov_dim=0, hidden=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cov_proj = nn.Linear(cov_dim, hidden) if cov_dim>0 else None\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, n_classes)\n",
    "        )\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        out = self.net(x)\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            out = out + self.cov_proj(cov)\n",
    "        return out\n",
    "\n",
    "\n",
    "# === Сложная многосоставная (целевая) модель TCN+BiGRU+Self-Attn (SE, FiLM) ===\n",
    "\n",
    "# Вспомогательный Chomp слой для TCN (удаляет лишние таймстепы после паддинга)\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size): super().__init__(); self.chomp_size=chomp_size\n",
    "    def forward(self, x): return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout=0.1):\n",
    "        super().__init__()\n",
    "        pad = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=pad, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(pad)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=pad, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(pad)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.down = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        out = self.chomp1(self.conv1(x)); out = self.relu(out); out = self.dropout(out)\n",
    "        out = self.chomp2(self.conv2(out)); out = self.relu(out); out = self.dropout(out)\n",
    "        return self.relu(out + self.down(x))\n",
    "\n",
    "# Squeeze-and-Excitation блок для 1D тензоров\n",
    "class SE1D(nn.Module):\n",
    "    def __init__(self, channels, r=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, max(1, channels // r))\n",
    "        self.fc2 = nn.Linear(max(1, channels // r), channels)\n",
    "    def forward(self, x):\n",
    "        s = x.mean(dim=2); w = torch.sigmoid(self.fc2(F.relu(self.fc1(s))))\n",
    "        return x * w.unsqueeze(-1)\n",
    "\n",
    "# FiLM блок для условной модуляции признаков по ковариатам\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, cov_dim, feat_ch):\n",
    "        super().__init__(); self.gamma = nn.Linear(cov_dim, feat_ch); self.beta = nn.Linear(cov_dim, feat_ch)\n",
    "    def forward(self, x, z):\n",
    "        g = self.gamma(z).unsqueeze(-1); b = self.beta(z).unsqueeze(-1); return x * (1 + g) + b\n",
    "\n",
    "# Многоголовое временное внимание с нормализацией и FFN для агрегации временных признаков\n",
    "class MultiHeadTemporalAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4):\n",
    "        super().__init__(); self.mha = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(d_model); self.ff = nn.Sequential(nn.Linear(d_model,2*d_model), nn.ReLU(), nn.Linear(2*d_model,d_model))\n",
    "    def forward(self, X, mask=None):\n",
    "        key_padding_mask = (~mask.bool()) if mask is not None else None\n",
    "        Y,_ = self.mha(X,X,X, key_padding_mask=key_padding_mask)\n",
    "        X = self.ln(X+Y); Z = self.ln(X + self.ff(X))\n",
    "        if mask is None: return Z.mean(dim=1)\n",
    "        w = mask.float().unsqueeze(-1); return (Z*w).sum(dim=1)/(w.sum(dim=1)+1e-8)\n",
    "\n",
    "# Основная модель ROISequenceNet: FiLM + SE + TCN + SE + BiGRU + MultiHeadAttention + Head\n",
    "# Вход: (B,T,R) - батч временных рядов с R признаками\n",
    "# Выход: (B,C) - логиты по классам\n",
    "# Параметры настраивают размерности, дропауты и использование FiLM\n",
    "class ROISequenceNet(nn.Module):\n",
    "    def __init__(self, n_roi, n_classes=4, cov_dim=0, tcn_dropout=0.1, gru_hidden=128, attn_heads=4):\n",
    "        super().__init__()\n",
    "        self.film = FiLM(cov_dim, 128) if cov_dim>0 else None\n",
    "        self.se1 = SE1D(n_roi)\n",
    "        self.tcn = nn.Sequential(\n",
    "            TemporalBlock(n_roi, 128, kernel_size=5, dilation=1, dropout=tcn_dropout),\n",
    "            TemporalBlock(128, 128, kernel_size=5, dilation=2, dropout=tcn_dropout),\n",
    "            TemporalBlock(128, 128, kernel_size=5, dilation=4, dropout=tcn_dropout),\n",
    "        )\n",
    "        self.se2 = SE1D(128)\n",
    "        self.bigru = nn.GRU(input_size=128, hidden_size=gru_hidden, batch_first=True, bidirectional=True)\n",
    "        self.attn = MultiHeadTemporalAttention(d_model=2*gru_hidden, n_heads=attn_heads)\n",
    "        self.head = nn.Sequential(nn.Linear(2*gru_hidden,128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, n_classes))\n",
    "    def forward(self, x, mask=None, z=None):\n",
    "        x = x.transpose(1,2); x = self.se1(x)\n",
    "        if self.film is not None and z is not None: x = self.film(x, z)\n",
    "        x = self.tcn(x); x = self.se2(x); x = x.transpose(1,2)\n",
    "        y,_ = self.bigru(x); emb = self.attn(y, mask=mask); return self.head(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Обучение и метрики\n",
    "\n",
    "### Организация обучения\n",
    "- Используется стандартный цикл обучения PyTorch с оптимизатором Adam и планировщиком lr.ReduceLROnPlateau.\n",
    "- Метрики: accuracy, precision, AUC, F1-score (макро).\n",
    "- Веса классов учитываются в функции потерь (CrossEntropyLoss).\n",
    "- Последовательно обучаем модели LSTM, GRU и ROISequenceNet, сравнивая их производительность на валидационном наборе. Используем раннюю остановку для предотвращения переобучения. Так же используем разные варианты сэмплирования для балансировки классов (sampling - добавление \"веса\" каждому классу, oversampling - увеличение числа сэмплов для меньших классов).\n",
    "- Обучаем модель SimpleMLP на усреднённых по времени признаках (mean/std) для сравнения с RNN-моделями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2044b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Универсальный класс тренировки модели\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dl, val_dl, class_counts: pd.Series, device, lr=1e-3, weight_decay=1e-4):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.device = device\n",
    "        self.class_labels = sorted(class_counts.index.tolist())\n",
    "        self.class_count = len(self.class_labels)\n",
    "        weights = (1.0 / (class_counts + 1e-9))\n",
    "        weights = (weights / weights.sum()) * len(class_counts)\n",
    "        class_weights = torch.tensor(weights.values, dtype=torch.float32).to(device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def _forward_model(self, X, M, C):\n",
    "        if C is not None and C.nelement() > 0:\n",
    "            # Пытаемся вызвать с аргументом cov, fallback на z\n",
    "            try:\n",
    "                return self.model(X, mask=M, cov=C)\n",
    "            except TypeError:\n",
    "                return self.model(X, mask=M, z=C)\n",
    "        else:\n",
    "            return self.model(X, mask=M)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch in self.train_dl:\n",
    "            # Поддержка различных форматов батча\n",
    "            if len(batch) == 5:\n",
    "                X, M, C, y, _ = batch\n",
    "            elif len(batch) == 4:\n",
    "                X, M, C, y = batch\n",
    "            elif len(batch) == 3:\n",
    "                X, C, y = batch\n",
    "                M = None\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            M = M.to(self.device) if M is not None else None\n",
    "            C = C.to(self.device) if (C is not None and C.nelement() > 0) else None\n",
    "            outputs = self._forward_model(X, M, C)\n",
    "            loss = self.criterion(outputs, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "        return total_loss / len(self.train_dl.dataset)\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dl:\n",
    "                if len(batch) == 5:\n",
    "                    X, M, C, y, _ = batch\n",
    "                elif len(batch) == 4:\n",
    "                    X, M, C, y = batch\n",
    "                elif len(batch) == 3:\n",
    "                    X, C, y = batch\n",
    "                    M = None\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                M = M.to(self.device) if M is not None else None\n",
    "                C = C.to(self.device) if (C is not None and C.nelement() > 0) else None\n",
    "                outputs = self._forward_model(X, M, C)\n",
    "                loss = self.criterion(outputs, y)\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "        all_probs = np.vstack(all_probs) if all_probs else np.zeros((0, self.class_count))\n",
    "        accuracy = accuracy_score(all_labels, all_preds) if all_labels else float('nan')\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0) if all_labels else float('nan')\n",
    "        try:\n",
    "            auc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr', labels=self.class_labels) if all_labels else float('nan')\n",
    "        except ValueError:\n",
    "            auc = float('nan')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0) if all_labels else float('nan')\n",
    "        return total_loss / len(self.val_dl.dataset), accuracy, precision, auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, opt, data_loader, sanitize_inputs=SANITIZE_INPUTS, max_grad_norm=MAX_GRAD_NORM, device='cuda'):\n",
    "    model.train(); losses=[]; ce=nn.CrossEntropyLoss()\n",
    "    for xb, mb, cb, yb, _ in data_loader:\n",
    "        xb=xb.to(device).float(); yb=yb.to(device).long(); cb=cb.to(device).float() if cb is not None else None\n",
    "        if sanitize_inputs:\n",
    "            xb = torch.nan_to_num(xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        logits = model(xb, mask=mb, cov=cb)\n",
    "        if torch.isnan(logits).any():\n",
    "            print('[WARN] NaN logits detected, skipping batch')\n",
    "            continue\n",
    "        loss = ce(logits, yb)\n",
    "        if torch.isnan(loss):\n",
    "            print('[WARN] NaN loss detected, skipping batch')\n",
    "            continue\n",
    "        opt.zero_grad(); loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    return float(np.mean(losses)) if losses else float('nan')\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_metrics(model, data_loader, sanitize_inputs=SANITIZE_INPUTS, device='cuda'):\n",
    "    model.eval(); ys=[]; yh=[]; yp=[]\n",
    "    for xb, mb, cb, yb, _ in data_loader:\n",
    "        xb=xb.to(device).float(); yb=yb.to(device).long(); cb=cb.to(device).float() if cb is not None else None\n",
    "        if sanitize_inputs:\n",
    "            xb = torch.nan_to_num(xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        logits = model(xb, mask=mb, cov=cb)\n",
    "        if torch.isnan(logits).any():\n",
    "            continue\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        pred  = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        ys += yb.cpu().numpy().tolist(); yh += pred; yp += probs\n",
    "    if not ys:\n",
    "        return float('nan'), float('nan'), float('nan')\n",
    "    acc = accuracy_score(ys, yh)\n",
    "    try:\n",
    "        if probs.shape[1] > 2:\n",
    "            auc = roc_auc_score(ys, yp, multi_class='ovr')\n",
    "        else:\n",
    "            auc = roc_auc_score(ys, np.vstack(yp)[:,1])\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    f1  = f1_score(ys, yh, average='weighted')\n",
    "    return acc, auc, f1\n",
    "\n",
    "# Weight init helper\n",
    "def init_weights_if_requested(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.uniform_(m.bias, -0.05, 0.05)\n",
    "        elif isinstance(m, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name and param.ndimension() >= 2:\n",
    "                    # use .data to avoid in-place ops on leaf views\n",
    "                    nn.init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    # safe zero init\n",
    "                    param.data.zero_()\n",
    "                    # forget gate bias boost (only LSTM: bias_hh and bias_ih concatenated gates)\n",
    "                    if isinstance(m, nn.LSTM):\n",
    "                        hidden_size = m.hidden_size\n",
    "                        # bias structure: [i, f, g, o]; set forget gate (f) to 1\n",
    "                        param.data[hidden_size:2*hidden_size].fill_(1.0)\n",
    "\n",
    "# Head reinit helper\n",
    "def reinit_head(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if name.endswith('head') and isinstance(module, nn.Sequential):\n",
    "            for sub in module:\n",
    "                if isinstance(sub, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(sub.weight)\n",
    "                    if sub.bias is not None:\n",
    "                        nn.init.uniform_(sub.bias, -0.05, 0.05)\n",
    "            print('[INFO] Reinitialized classification head for stagnation recovery.')\n",
    "            break\n",
    "\n",
    "# Функция для обучения модели с поддержкой: history, early stopping, debug, санитизация, клиппинг, стагнация.\n",
    "\n",
    "def train_model(model, train_dl, val_dl, class_counts, device, epochs=10, checkpoint_dir=None, lr=1e-3, weight_decay=1e-4, debug=False,\n",
    "                early_metric=EARLY_STOP_METRIC,\n",
    "                patience=EARLY_STOP_PATIENCE,\n",
    "                min_delta=MIN_DELTA_IMPROVE,\n",
    "                sanitize_inputs=SANITIZE_INPUTS,\n",
    "                max_grad_norm=MAX_GRAD_NORM,\n",
    "                head_reinit=HEAD_REINIT,\n",
    "                stagnation_reset_epochs=STAGNATION_RESET_EPOCHS,\n",
    "                reinit_on_nan=REINIT_ON_NAN):\n",
    "    if checkpoint_dir and not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    trainer = Trainer(model, train_dl, val_dl, class_counts, device, lr, weight_decay)\n",
    "    best_acc = 0.0\n",
    "    history = []\n",
    "    if early_metric not in (EarlyStopMetric.VAL_LOSS, EarlyStopMetric.VAL_ACC, EarlyStopMetric.VAL_F1):\n",
    "        early_metric = EarlyStopMetric.VAL_LOSS\n",
    "    early_best = None\n",
    "    early_counter = 0\n",
    "\n",
    "    init_weights_if_requested(model)\n",
    "    stagnation_epochs = 0\n",
    "\n",
    "    def param_vector(m):\n",
    "        return torch.cat([p.detach().flatten() for p in m.parameters() if p.requires_grad])\n",
    "    prev_params = param_vector(model)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(); total_loss=0.0; batch_losses=[]; grad_norms=[]; skipped_batches=0\n",
    "        for batch in train_dl:\n",
    "            if len(batch)==5: X,M,C,y,_ = batch\n",
    "            elif len(batch)==4: X,M,C,y = batch\n",
    "            elif len(batch)==3: X,C,y = batch; M=None\n",
    "            else: raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            M = M.to(device) if M is not None else None\n",
    "            C = C.to(device) if (C is not None and C.nelement()>0) else None\n",
    "            if sanitize_inputs:\n",
    "                X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            outputs = trainer._forward_model(X, M, C)\n",
    "            if torch.isnan(outputs).any():\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            loss = trainer.criterion(outputs, y)\n",
    "            if torch.isnan(loss):\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            trainer.optimizer.zero_grad(); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            gnorm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    gnorm += p.grad.detach().data.norm(2).item()\n",
    "            trainer.optimizer.step()\n",
    "            total_loss += loss.item()*X.size(0)\n",
    "            batch_losses.append(loss.item())\n",
    "            grad_norms.append(gnorm)\n",
    "        train_loss = total_loss / len(train_dl.dataset) if batch_losses else float('nan')\n",
    "        val_loss, val_acc, val_prec, val_auc, val_f1 = trainer.evaluate()\n",
    "        cur_params = param_vector(model)\n",
    "        delta = (cur_params - prev_params).abs().mean().item()\n",
    "        prev_params = cur_params\n",
    "        if torch.isnan(cur_params).any() and reinit_on_nan:\n",
    "            print('[WARN] NaN detected in parameters -> reinitializing linear + recurrent layers')\n",
    "            init_weights_if_requested(model)\n",
    "\n",
    "        print(f\"Эпоха {epoch+1}/{epochs} | TrainLoss {train_loss:.4f} | ValLoss {val_loss:.4f} | Acc {val_acc:.4f} | Prec {val_prec:.4f} | AUC {val_auc:.4f} | F1 {val_f1:.4f} | Δparam {delta:.6e} | skipped {skipped_batches}\")\n",
    "        if debug and batch_losses:\n",
    "            print(f\"  BatchLoss[min/median/max]: {np.min(batch_losses):.4f}/{np.median(batch_losses):.4f}/{np.max(batch_losses):.4f}; GradNorm[mean]: {np.mean(grad_norms):.4f}\")\n",
    "\n",
    "        if val_acc > best_acc and not torch.isnan(torch.tensor(val_acc)):\n",
    "            best_acc = val_acc\n",
    "            if checkpoint_dir:\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pth'))\n",
    "                if debug: print('  ↳ saved best checkpoint')\n",
    "\n",
    "        # stagnation logic\n",
    "        if val_acc == 0.0:\n",
    "            stagnation_epochs += 1\n",
    "            if head_reinit and stagnation_epochs >= stagnation_reset_epochs:\n",
    "                print(f\"[STAGNATION] val_acc remained 0 for {stagnation_epochs} epochs -> reinit head\")\n",
    "                reinit_head(model)\n",
    "                stagnation_epochs = 0\n",
    "        else:\n",
    "            stagnation_epochs = 0\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_prec': val_prec,\n",
    "            'val_auc': val_auc,\n",
    "            'val_f1': val_f1,\n",
    "            'param_delta_mean_abs': delta,\n",
    "            'skipped_batches': skipped_batches,\n",
    "            'grad_norm_mean': float(np.mean(grad_norms)) if grad_norms else float('nan'),\n",
    "            'stagnation_epochs': stagnation_epochs\n",
    "        })\n",
    "\n",
    "        metric_value = {'val_loss': val_loss, 'val_acc': val_acc, 'val_f1': val_f1}[early_metric]\n",
    "        improve = False\n",
    "        if early_best is None:\n",
    "            early_best = metric_value\n",
    "            improve = True\n",
    "        else:\n",
    "            if early_metric == 'val_loss':\n",
    "                if early_best - metric_value > min_delta:\n",
    "                    improve = True\n",
    "            else:\n",
    "                if metric_value - early_best > min_delta:\n",
    "                    improve = True\n",
    "        if improve:\n",
    "            early_best = metric_value\n",
    "            early_counter = 0\n",
    "        else:\n",
    "            early_counter += 1\n",
    "            if early_counter >= patience:\n",
    "                print(f\"[EARLY STOP] metric={early_metric} no improve {patience} epochs (best={early_best:.4f}).\")\n",
    "                break\n",
    "\n",
    "    print(\"Лучший валид. Accuracy:\", best_acc)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Создание тренировочной и валидационной выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95046a8c",
   "metadata": {},
   "source": [
    "Даталоадер DataMode.SEQ_NPY с балансировкой классов (sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Даталоадер: режим DataMode.SEQ_NPY балансировка: BalanceStrategy.SAMPLER\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, число ROI 353, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 4\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY + sampler: (array([0, 1, 2, 3]), array([2, 5, 5, 4]))\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, число ROI 353, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 4\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY + sampler: (array([0, 1, 2, 3]), array([2, 5, 5, 4]))\n"
     ]
    }
   ],
   "source": [
    "# Создаём даталоадер для mode DataMode.SEQ_NPY со стратегией балансировки sampler\n",
    "print(\"Даталоадер: режим\", DataMode.SEQ_NPY, \"балансировка:\", BalanceStrategy.SAMPLER)\n",
    "train_dl_sampler, val_dl_sampler = make_fold_dataloaders(data_df, fold_idx=0,\n",
    "                                                         mode=DataMode.SEQ_NPY,\n",
    "                                                         enable_autobalance=True,\n",
    "                                                         balance_strategy=BalanceStrategy.SAMPLER,\n",
    "                                                         class_weight_mode=CLASS_WEIGHT_MODE,\n",
    "                                                         max_class_weight_ratio=MAX_CLASS_WEIGHT_RATIO,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         impute_strategy=IMPUTE_STRATEGY,\n",
    "                                                         add_eps_noise_if_all_zero=ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                                                         cov_pipeline=pre)\n",
    "xb_s, mb_s, cb_s, yb_s, pid_s = next(iter(train_dl_sampler))\n",
    "print(\"Пример батча: xb:\", xb_s.shape, \"mb:\", mb_s.shape, \"cb:\", cb_s.shape if cb_s is not None else None, \"yb:\", yb_s.shape, \"pid:\", len(pid_s))\n",
    "\n",
    "# cb теперь всегда тензор (пустой если нет ковариат)\n",
    "cov_dim_s = (cb_s.shape[-1] if (cb_s is not None and cb_s.numel() > 0) else 0)\n",
    "\n",
    "cls_counts_s = len(torch.unique(yb_s))\n",
    "\n",
    "ROI = xb_s.shape[-1]      # число ROI (должно быть универсальным)\n",
    "in_dim_s = ROI\n",
    "\n",
    "print(f\"Входные данные: режим {DataMode.SEQ_NPY}, число ROI {ROI}, стратегия балансировки классов: {BalanceStrategy.SAMPLER}, размер ковариат {cov_dim_s}, число классов {cls_counts_s}\")\n",
    "\n",
    "# Разбивка по классам:\n",
    "print(\"Train классы для Даталоадера DataMode.SEQ_NPY + sampler:\", np.unique(yb_s.numpy(), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697cb57",
   "metadata": {},
   "source": [
    "Даталоадер DataMode.SEQ_NPY с балансировкой классов (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe78ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Даталоадер: режим DataMode.SEQ_NPY балансировка: BalanceStrategy.OVERSAMPLE\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, стратегия балансировки классов: BalanceStrategy.OVERSAMPLE, число ROI 353, размер ковариат 0, число классов 4\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY + sampler: (array([0, 1, 2, 3]), array([5, 4, 4, 3]))\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, стратегия балансировки классов: BalanceStrategy.OVERSAMPLE, число ROI 353, размер ковариат 0, число классов 4\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY + sampler: (array([0, 1, 2, 3]), array([5, 4, 4, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Даталоадер: режим\", DataMode.SEQ_NPY, \"балансировка:\", BalanceStrategy.OVERSAMPLE)\n",
    "train_dl_over, val_dl_over = make_fold_dataloaders(data_df, fold_idx=0,\n",
    "                                                   mode=DataMode.SEQ_NPY,\n",
    "                                                   enable_autobalance=True,\n",
    "                                                   balance_strategy=BalanceStrategy.OVERSAMPLE,\n",
    "                                                   class_weight_mode=CLASS_WEIGHT_MODE,\n",
    "                                                   max_class_weight_ratio=MAX_CLASS_WEIGHT_RATIO,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   impute_strategy=IMPUTE_STRATEGY,\n",
    "                                                   add_eps_noise_if_all_zero=ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                                                   cov_pipeline=pre)\n",
    "xb_o, mb_o, cb_o, yb_o, pid_o = next(iter(train_dl_over))\n",
    "print(\"Пример батча: xb:\", xb_o.shape, \"mb:\", mb_o.shape, \"cb:\", cb_o.shape if cb_o is not None else None, \"yb:\", yb_o.shape, \"pid:\", len(pid_o))\n",
    "\n",
    "# cb теперь всегда тензор (пустой если нет ковариат)\n",
    "cov_dim_o = (cb_o.shape[-1] if (cb_o is not None and cb_o.numel() > 0) else 0)\n",
    "\n",
    "cls_counts_o = len(torch.unique(yb_o))\n",
    "\n",
    "ROI = xb_o.shape[-1]      # число ROI (должно быть универсальным)\n",
    "in_dim_o = ROI\n",
    "\n",
    "print(f\"Входные данные: режим {DataMode.SEQ_NPY}, стратегия балансировки классов: {BalanceStrategy.OVERSAMPLE}, число ROI {ROI}, размер ковариат {cov_dim_o}, число классов {cls_counts_o}\")\n",
    "\n",
    "# Разбивка по классам:\n",
    "print(\"Train классы для Даталоадера DataMode.SEQ_NPY + sampler:\", np.unique(yb_o.numpy(), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b6e9d",
   "metadata": {},
   "source": [
    "Даталоадер DataMode.SEQ_NPY без балансировки классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "958c7980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Даталоадер: режим DataMode.SEQ_NPY балансировка: None\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, число ROI 353, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 3\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY без балансировки: (array([0, 1, 3]), array([10,  3,  3]))\n",
      "Пример батча: xb: torch.Size([16, 200, 353]) mb: torch.Size([16, 200]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.SEQ_NPY, число ROI 353, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 3\n",
      "Train классы для Даталоадера DataMode.SEQ_NPY без балансировки: (array([0, 1, 3]), array([10,  3,  3]))\n"
     ]
    }
   ],
   "source": [
    "# Создаём даталоадер для mode DataMode.SEQ_NPY без балансировки\n",
    "print(\"Даталоадер: режим\", DataMode.SEQ_NPY, \"балансировка:\", None)\n",
    "train_dl, val_dl = make_fold_dataloaders(data_df, fold_idx=0,\n",
    "                                                         mode=DataMode.SEQ_NPY,\n",
    "                                                         enable_autobalance=False,\n",
    "                                                         balance_strategy=None,\n",
    "                                                         class_weight_mode=CLASS_WEIGHT_MODE,\n",
    "                                                         max_class_weight_ratio=MAX_CLASS_WEIGHT_RATIO,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         impute_strategy=IMPUTE_STRATEGY,\n",
    "                                                         add_eps_noise_if_all_zero=ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                                                         cov_pipeline=pre)\n",
    "xb, mb, cb, yb, pid = next(iter(train_dl))\n",
    "print(\"Пример батча: xb:\", xb.shape, \"mb:\", mb.shape, \"cb:\", cb.shape if cb is not None else None, \"yb:\", yb.shape, \"pid:\", len(pid))\n",
    "\n",
    "# cb теперь всегда тензор (пустой если нет ковариат)\n",
    "cov_dim = (cb.shape[-1] if (cb is not None and cb.numel() > 0) else 0)\n",
    "\n",
    "cls_counts = len(torch.unique(yb))\n",
    "\n",
    "ROI = xb.shape[-1]      # число ROI (должно быть универсальным)\n",
    "in_dim = ROI\n",
    "\n",
    "print(f\"Входные данные: режим {DataMode.SEQ_NPY}, число ROI {ROI}, стратегия балансировки классов: {BalanceStrategy.SAMPLER}, размер ковариат {cov_dim}, число классов {cls_counts}\")\n",
    "\n",
    "# Разбивка по классам:\n",
    "print(\"Train классы для Даталоадера DataMode.SEQ_NPY без балансировки:\", np.unique(yb.numpy(), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ce2462b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Даталоадер: режим DataMode.DFC балансировка: BalanceStrategy.SAMPLER\n",
      "Пример батча: xb: torch.Size([16, 12]) mb: torch.Size([16]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.DFC, число признаков 12, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 3\n",
      "Пример батча: xb: torch.Size([16, 12]) mb: torch.Size([16]) cb: torch.Size([16, 0]) yb: torch.Size([16]) pid: 16\n",
      "Входные данные: режим DataMode.DFC, число признаков 12, стратегия балансировки классов: BalanceStrategy.SAMPLER, размер ковариат 0, число классов 3\n"
     ]
    }
   ],
   "source": [
    "if DFC_CSV is not None:\n",
    "    # Создаём даталоадер для mode DataMode.DFC с балансировкой sampler\n",
    "    print(\"Даталоадер: режим\", DataMode.DFC, \"балансировка:\", BalanceStrategy.SAMPLER)\n",
    "    train_dl_dfc_nb, val_dl_dfc_nb = make_fold_dataloaders(data_df, fold_idx=0,\n",
    "                                                             mode=DataMode.DFC,\n",
    "                                                             enable_autobalance=False,\n",
    "                                                             balance_strategy=BalanceStrategy.SAMPLER,\n",
    "                                                             class_weight_mode=CLASS_WEIGHT_MODE,\n",
    "                                                             max_class_weight_ratio=MAX_CLASS_WEIGHT_RATIO,\n",
    "                                                             batch_size=BATCH_SIZE,\n",
    "                                                             impute_strategy=IMPUTE_STRATEGY,\n",
    "                                                             add_eps_noise_if_all_zero=ADD_EPS_NOISE_IF_ALL_ZERO,\n",
    "                                                             cov_pipeline=pre)\n",
    "    xb_dfc_nb, mb_dfc_nb, cb_dfc_nb, yb_dfc_nb, pid_dfc_nb = next(iter(train_dl_dfc_nb))\n",
    "    print(\"Пример батча: xb:\", xb_dfc_nb.shape, \"mb:\", mb_dfc_nb.shape, \"cb:\", cb_dfc_nb.shape if cb_dfc_nb is not None else None, \"yb:\", yb_dfc_nb.shape, \"pid:\", len(pid_dfc_nb))\n",
    "\n",
    "    # cb теперь всегда тензор (пустой если нет ковариат)\n",
    "    cov_dim_dfc_nb = (cb_dfc_nb.shape[-1] if (cb_dfc_nb is not None and cb_dfc_nb.numel() > 0) else 0)\n",
    "\n",
    "    cls_counts_dfc_nb = len(torch.unique(yb_dfc_nb))\n",
    "\n",
    "    in_dim_dfc_nb = xb_dfc_nb.shape[-1]\n",
    "    ROI_DFC = in_dim_dfc_nb\n",
    "\n",
    "    print(f\"Входные данные: режим {DataMode.DFC}, число признаков {in_dim_dfc_nb}, стратегия балансировки классов: {BalanceStrategy.SAMPLER}, размер ковариат {cov_dim_dfc_nb}, число классов {cls_counts_dfc_nb}\")\n",
    "else:\n",
    "    train_dl_dfc_nb, val_dl_dfc_nb = None, None\n",
    "    print(\"DFC_CSV не задан, пропускаем даталоадер для DataMode.DFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49bba4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы в основном датафрейме: {0: 1164, 1: 399, 3: 325, 2: 33}\n"
     ]
    }
   ],
   "source": [
    "# Извлечём количество классов каждого типа из главного датафрейма\n",
    "class_counts_main = data_df['label'].value_counts()\n",
    "print(\"Классы в основном датафрейме:\", class_counts_main.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2186767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DIAG] Начало диагностики батча\n",
      "  Train batch shape: torch.Size([16, 200, 353]) labels shape: torch.Size([16])\n",
      "  Unique labels in batch: (array([0, 1, 2, 3]), array([6, 1, 5, 4]))\n",
      "  Any NaN in Xd: False\n",
      "  Any Inf in Xd: False\n",
      "  Preds before training step: (array([0, 1, 3]), array([10,  3,  3]))\n",
      "  Preds after one step: (array([0, 1, 2, 3]), array([10,  2,  3,  1]))\n",
      "[DIAG] Завершено. Если preds не меняются и всегда один класс, возможно входы вырожденные или head не обновляется.\n"
     ]
    }
   ],
   "source": [
    "# === Диагностика батчей: распределение меток и предсказаний до и после одной итерации ===\n",
    "print('\\n[DIAG] Начало диагностики батча')\n",
    "first_batch = next(iter(train_dl))\n",
    "if len(first_batch)==5:\n",
    "    Xd, Md, Cd, yd, _ = first_batch\n",
    "elif len(first_batch)==4:\n",
    "    Xd, Md, Cd, yd = first_batch\n",
    "else:\n",
    "    Xd, Cd, yd = first_batch; Md=None\n",
    "print('  Train batch shape:', Xd.shape, 'labels shape:', yd.shape)\n",
    "print('  Unique labels in batch:', np.unique(yd.numpy(), return_counts=True))\n",
    "print('  Any NaN in Xd:', np.isnan(Xd.numpy()).any())\n",
    "print('  Any Inf in Xd:', np.isinf(Xd.numpy()).any())\n",
    "\n",
    "# Создаём временную модель для теста (LSTM)\n",
    "_diag_model = SimpleLSTM(n_rois=Xd.shape[-1], n_classes=N_CLASSES, cov_dim=(Cd.shape[-1] if Cd is not None and Cd.numel()>0 else 0), hidden=32)\n",
    "init_weights_if_requested(_diag_model)\n",
    "_diag_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits0 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "    probs0 = torch.softmax(logits0, dim=1)\n",
    "    preds0 = probs0.argmax(1)\n",
    "print('  Preds before training step:', np.unique(preds0.numpy(), return_counts=True))\n",
    "\n",
    "# Один шаг обучения для проверки обновления\n",
    "opt_tmp = torch.optim.Adam(_diag_model.parameters(), lr=1e-3)\n",
    "_diag_model.train()\n",
    "logits1 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "loss1 = nn.CrossEntropyLoss()(logits1, yd)\n",
    "loss1.backward(); torch.nn.utils.clip_grad_norm_(_diag_model.parameters(), MAX_GRAD_NORM); opt_tmp.step()\n",
    "\n",
    "_diag_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits2 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "    preds2 = logits2.argmax(1)\n",
    "print('  Preds after one step:', np.unique(preds2.numpy(), return_counts=True))\n",
    "print('[DIAG] Завершено. Если preds не меняются и всегда один класс, возможно входы вырожденные или head не обновляется.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e60ad2",
   "metadata": {},
   "source": [
    "### Обучение Simple LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811132c",
   "metadata": {},
   "source": [
    "Обучение модели Simple LSTM на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера с балансировкой классов (sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "21abc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DIAG] class counts (full df): {0: 1164, 1: 399, 3: 325, 2: 33}\n",
      "[DIAG] unique labels: [0, 1, 2, 3]\n",
      "\n",
      "=== SimpleLSTM: балансировка sampler (взвешенный семплинг) ===\n",
      "Эпоха 1/50 | TrainLoss 0.7985 | ValLoss 1.2689 | Acc 0.2096 | Prec 0.4447 | AUC 0.4838 | F1 0.1121 | Δparam 8.766305e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2333/0.6785/2.5757; GradNorm[mean]: 8.0335\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 1/50 | TrainLoss 0.7985 | ValLoss 1.2689 | Acc 0.2096 | Prec 0.4447 | AUC 0.4838 | F1 0.1121 | Δparam 8.766305e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2333/0.6785/2.5757; GradNorm[mean]: 8.0335\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.5230 | ValLoss 1.1918 | Acc 0.2045 | Prec 0.6802 | AUC 0.5193 | F1 0.0895 | Δparam 6.246426e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1777/0.4447/1.5332; GradNorm[mean]: 6.7945\n",
      "Эпоха 2/50 | TrainLoss 0.5230 | ValLoss 1.1918 | Acc 0.2045 | Prec 0.6802 | AUC 0.5193 | F1 0.0895 | Δparam 6.246426e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1777/0.4447/1.5332; GradNorm[mean]: 6.7945\n",
      "Эпоха 3/50 | TrainLoss 0.3986 | ValLoss 1.2426 | Acc 0.2197 | Prec 0.6948 | AUC 0.5011 | F1 0.1172 | Δparam 5.551557e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0750/0.3614/1.3347; GradNorm[mean]: 4.5242\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 3/50 | TrainLoss 0.3986 | ValLoss 1.2426 | Acc 0.2197 | Prec 0.6948 | AUC 0.5011 | F1 0.1172 | Δparam 5.551557e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0750/0.3614/1.3347; GradNorm[mean]: 4.5242\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 4/50 | TrainLoss 0.3406 | ValLoss 1.3558 | Acc 0.2172 | Prec 0.4782 | AUC 0.5377 | F1 0.1376 | Δparam 5.529447e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0867/0.3093/1.2515; GradNorm[mean]: 4.6954\n",
      "Эпоха 4/50 | TrainLoss 0.3406 | ValLoss 1.3558 | Acc 0.2172 | Prec 0.4782 | AUC 0.5377 | F1 0.1376 | Δparam 5.529447e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0867/0.3093/1.2515; GradNorm[mean]: 4.6954\n",
      "Эпоха 5/50 | TrainLoss 0.3140 | ValLoss 1.3865 | Acc 0.2247 | Prec 0.4715 | AUC 0.4882 | F1 0.1596 | Δparam 5.337881e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0790/0.2719/2.0786; GradNorm[mean]: 4.5423\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 5/50 | TrainLoss 0.3140 | ValLoss 1.3865 | Acc 0.2247 | Prec 0.4715 | AUC 0.4882 | F1 0.1596 | Δparam 5.337881e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0790/0.2719/2.0786; GradNorm[mean]: 4.5423\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 6/50 | TrainLoss 0.2842 | ValLoss 1.4555 | Acc 0.2020 | Prec 0.4305 | AUC 0.5025 | F1 0.1525 | Δparam 4.794692e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0560/0.2577/0.8567; GradNorm[mean]: 4.5575\n",
      "Эпоха 6/50 | TrainLoss 0.2842 | ValLoss 1.4555 | Acc 0.2020 | Prec 0.4305 | AUC 0.5025 | F1 0.1525 | Δparam 4.794692e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0560/0.2577/0.8567; GradNorm[mean]: 4.5575\n",
      "Эпоха 7/50 | TrainLoss 0.2018 | ValLoss 1.7655 | Acc 0.2247 | Prec 0.4320 | AUC 0.5130 | F1 0.1949 | Δparam 3.936326e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0564/0.1667/0.7878; GradNorm[mean]: 3.1268\n",
      "Эпоха 7/50 | TrainLoss 0.2018 | ValLoss 1.7655 | Acc 0.2247 | Prec 0.4320 | AUC 0.5130 | F1 0.1949 | Δparam 3.936326e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0564/0.1667/0.7878; GradNorm[mean]: 3.1268\n",
      "Эпоха 8/50 | TrainLoss 0.2126 | ValLoss 1.6092 | Acc 0.2449 | Prec 0.4279 | AUC 0.5253 | F1 0.2275 | Δparam 5.335533e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0421/0.1776/0.7162; GradNorm[mean]: 3.4240\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 8/50 | TrainLoss 0.2126 | ValLoss 1.6092 | Acc 0.2449 | Prec 0.4279 | AUC 0.5253 | F1 0.2275 | Δparam 5.335533e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0421/0.1776/0.7162; GradNorm[mean]: 3.4240\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/50 | TrainLoss 0.2544 | ValLoss 1.8184 | Acc 0.2828 | Prec 0.4406 | AUC 0.5007 | F1 0.2845 | Δparam 4.537345e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0416/0.2035/1.3799; GradNorm[mean]: 2.9933\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/50 | TrainLoss 0.2544 | ValLoss 1.8184 | Acc 0.2828 | Prec 0.4406 | AUC 0.5007 | F1 0.2845 | Δparam 4.537345e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0416/0.2035/1.3799; GradNorm[mean]: 2.9933\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 10/50 | TrainLoss 0.1943 | ValLoss 1.8288 | Acc 0.3258 | Prec 0.4994 | AUC 0.5338 | F1 0.3512 | Δparam 4.901394e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0395/0.1591/0.8866; GradNorm[mean]: 3.3411\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 10/50 | TrainLoss 0.1943 | ValLoss 1.8288 | Acc 0.3258 | Prec 0.4994 | AUC 0.5338 | F1 0.3512 | Δparam 4.901394e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0395/0.1591/0.8866; GradNorm[mean]: 3.3411\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 11/50 | TrainLoss 0.2243 | ValLoss 1.7093 | Acc 0.2424 | Prec 0.3962 | AUC 0.5167 | F1 0.2254 | Δparam 6.498951e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0315/0.1700/1.1960; GradNorm[mean]: 4.1413\n",
      "Эпоха 11/50 | TrainLoss 0.2243 | ValLoss 1.7093 | Acc 0.2424 | Prec 0.3962 | AUC 0.5167 | F1 0.2254 | Δparam 6.498951e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0315/0.1700/1.1960; GradNorm[mean]: 4.1413\n",
      "Эпоха 12/50 | TrainLoss 0.1957 | ValLoss 2.0061 | Acc 0.2702 | Prec 0.4348 | AUC 0.5354 | F1 0.2966 | Δparam 6.282653e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0214/0.1465/0.7392; GradNorm[mean]: 4.1039\n",
      "Эпоха 12/50 | TrainLoss 0.1957 | ValLoss 2.0061 | Acc 0.2702 | Prec 0.4348 | AUC 0.5354 | F1 0.2966 | Δparam 6.282653e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0214/0.1465/0.7392; GradNorm[mean]: 4.1039\n",
      "Эпоха 13/50 | TrainLoss 0.1989 | ValLoss 1.9560 | Acc 0.2222 | Prec 0.4201 | AUC 0.5001 | F1 0.2100 | Δparam 6.772314e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0425/0.1604/0.8146; GradNorm[mean]: 3.7720\n",
      "Эпоха 13/50 | TrainLoss 0.1989 | ValLoss 1.9560 | Acc 0.2222 | Prec 0.4201 | AUC 0.5001 | F1 0.2100 | Δparam 6.772314e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0425/0.1604/0.8146; GradNorm[mean]: 3.7720\n",
      "Эпоха 14/50 | TrainLoss 0.1637 | ValLoss 2.0255 | Acc 0.2955 | Prec 0.4559 | AUC 0.5199 | F1 0.3239 | Δparam 5.491224e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0287/0.1228/0.9280; GradNorm[mean]: 2.7814\n",
      "Эпоха 14/50 | TrainLoss 0.1637 | ValLoss 2.0255 | Acc 0.2955 | Prec 0.4559 | AUC 0.5199 | F1 0.3239 | Δparam 5.491224e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0287/0.1228/0.9280; GradNorm[mean]: 2.7814\n",
      "Эпоха 15/50 | TrainLoss 0.2984 | ValLoss 1.8243 | Acc 0.2096 | Prec 0.4539 | AUC 0.4994 | F1 0.1971 | Δparam 7.316696e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0244/0.1588/3.4135; GradNorm[mean]: 4.5843\n",
      "Эпоха 15/50 | TrainLoss 0.2984 | ValLoss 1.8243 | Acc 0.2096 | Prec 0.4539 | AUC 0.4994 | F1 0.1971 | Δparam 7.316696e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0244/0.1588/3.4135; GradNorm[mean]: 4.5843\n",
      "Эпоха 16/50 | TrainLoss 0.1807 | ValLoss 2.0330 | Acc 0.2348 | Prec 0.4655 | AUC 0.4957 | F1 0.2393 | Δparam 6.186891e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0232/0.1275/1.5050; GradNorm[mean]: 3.7471\n",
      "Эпоха 16/50 | TrainLoss 0.1807 | ValLoss 2.0330 | Acc 0.2348 | Prec 0.4655 | AUC 0.4957 | F1 0.2393 | Δparam 6.186891e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0232/0.1275/1.5050; GradNorm[mean]: 3.7471\n",
      "Эпоха 17/50 | TrainLoss 0.1215 | ValLoss 2.2614 | Acc 0.2727 | Prec 0.4178 | AUC 0.5045 | F1 0.2803 | Δparam 5.723254e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0161/0.0872/0.4167; GradNorm[mean]: 2.5670\n",
      "Эпоха 17/50 | TrainLoss 0.1215 | ValLoss 2.2614 | Acc 0.2727 | Prec 0.4178 | AUC 0.5045 | F1 0.2803 | Δparam 5.723254e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0161/0.0872/0.4167; GradNorm[mean]: 2.5670\n",
      "Эпоха 18/50 | TrainLoss 0.1044 | ValLoss 2.3129 | Acc 0.3333 | Prec 0.4425 | AUC 0.5122 | F1 0.3641 | Δparam 5.034033e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0142/0.0793/0.8417; GradNorm[mean]: 2.3714\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 18/50 | TrainLoss 0.1044 | ValLoss 2.3129 | Acc 0.3333 | Prec 0.4425 | AUC 0.5122 | F1 0.3641 | Δparam 5.034033e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0142/0.0793/0.8417; GradNorm[mean]: 2.3714\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 19/50 | TrainLoss 0.1101 | ValLoss 2.6340 | Acc 0.3005 | Prec 0.4091 | AUC 0.4979 | F1 0.3325 | Δparam 5.497991e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0100/0.0758/0.6689; GradNorm[mean]: 3.0619\n",
      "Эпоха 19/50 | TrainLoss 0.1101 | ValLoss 2.6340 | Acc 0.3005 | Prec 0.4091 | AUC 0.4979 | F1 0.3325 | Δparam 5.497991e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0100/0.0758/0.6689; GradNorm[mean]: 3.0619\n",
      "Эпоха 20/50 | TrainLoss 0.1152 | ValLoss 2.6306 | Acc 0.4141 | Prec 0.4622 | AUC 0.5509 | F1 0.4301 | Δparam 6.139501e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0147/0.0817/1.2715; GradNorm[mean]: 2.7850\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 20/50 | TrainLoss 0.1152 | ValLoss 2.6306 | Acc 0.4141 | Prec 0.4622 | AUC 0.5509 | F1 0.4301 | Δparam 6.139501e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0147/0.0817/1.2715; GradNorm[mean]: 2.7850\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 21/50 | TrainLoss 0.1440 | ValLoss 2.0235 | Acc 0.2955 | Prec 0.4393 | AUC 0.5235 | F1 0.2978 | Δparam 6.362401e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0111/0.0617/2.0417; GradNorm[mean]: 3.0083\n",
      "Эпоха 21/50 | TrainLoss 0.1440 | ValLoss 2.0235 | Acc 0.2955 | Prec 0.4393 | AUC 0.5235 | F1 0.2978 | Δparam 6.362401e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0111/0.0617/2.0417; GradNorm[mean]: 3.0083\n",
      "Эпоха 22/50 | TrainLoss 0.0828 | ValLoss 2.2463 | Acc 0.3939 | Prec 0.4530 | AUC 0.5499 | F1 0.4107 | Δparam 4.931912e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0056/0.0581/1.0623; GradNorm[mean]: 1.9666\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1918).\n",
      "Лучший валид. Accuracy: 0.41414141414141414\n",
      "\n",
      "[HISTORY - sampler] Последние строки:\n",
      "Эпоха 22/50 | TrainLoss 0.0828 | ValLoss 2.2463 | Acc 0.3939 | Prec 0.4530 | AUC 0.5499 | F1 0.4107 | Δparam 4.931912e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0056/0.0581/1.0623; GradNorm[mean]: 1.9666\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1918).\n",
      "Лучший валид. Accuracy: 0.41414141414141414\n",
      "\n",
      "[HISTORY - sampler] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1ca77262-855c-405c-9673-15ffc683edba",
       "rows": [
        [
         "17",
         "18",
         "0.10442562564474638",
         "2.3128576639926797",
         "0.3333333333333333",
         "0.4425154565398468",
         "0.5121565430739989",
         "0.3640841438255231",
         "0.0050340332090854645",
         "0",
         "2.371410730125111",
         "0"
        ],
        [
         "18",
         "19",
         "0.11010398387847865",
         "2.6339576449057067",
         "0.3005050505050505",
         "0.40913690125095237",
         "0.4978551305138033",
         "0.3324850132072031",
         "0.005497990641742945",
         "0",
         "3.061877304011432",
         "0"
        ],
        [
         "19",
         "20",
         "0.11515531645446528",
         "2.6306183747570926",
         "0.41414141414141414",
         "0.46218684871707777",
         "0.5508983719229608",
         "0.4300768377671952",
         "0.0061395009979605675",
         "0",
         "2.785004128658329",
         "0"
        ],
        [
         "20",
         "21",
         "0.14402081164180255",
         "2.0234958704071815",
         "0.29545454545454547",
         "0.4393133844235529",
         "0.5235264879929056",
         "0.29778875647592706",
         "0.006362400949001312",
         "0",
         "3.008271347336631",
         "0"
        ],
        [
         "21",
         "22",
         "0.08278665683797148",
         "2.2463290667293045",
         "0.3939393939393939",
         "0.45303554848766764",
         "0.5499196991028014",
         "0.4107167881866096",
         "0.004931912291795015",
         "0",
         "1.9665559320261916",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.104426</td>\n",
       "      <td>2.312858</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.442515</td>\n",
       "      <td>0.512157</td>\n",
       "      <td>0.364084</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0</td>\n",
       "      <td>2.371411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.110104</td>\n",
       "      <td>2.633958</td>\n",
       "      <td>0.300505</td>\n",
       "      <td>0.409137</td>\n",
       "      <td>0.497855</td>\n",
       "      <td>0.332485</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0</td>\n",
       "      <td>3.061877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.115155</td>\n",
       "      <td>2.630618</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.462187</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0</td>\n",
       "      <td>2.785004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.144021</td>\n",
       "      <td>2.023496</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.439313</td>\n",
       "      <td>0.523526</td>\n",
       "      <td>0.297789</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0</td>\n",
       "      <td>3.008271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.082787</td>\n",
       "      <td>2.246329</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.453036</td>\n",
       "      <td>0.549920</td>\n",
       "      <td>0.410717</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0</td>\n",
       "      <td>1.966556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "17     18    0.104426  2.312858  0.333333  0.442515  0.512157  0.364084              0.005034                0        2.371411                  0\n",
       "18     19    0.110104  2.633958  0.300505  0.409137  0.497855  0.332485              0.005498                0        3.061877                  0\n",
       "19     20    0.115155  2.630618  0.414141  0.462187  0.550898  0.430077              0.006140                0        2.785004                  0\n",
       "20     21    0.144021  2.023496  0.295455  0.439313  0.523526  0.297789              0.006362                0        3.008271                  0\n",
       "21     22    0.082787  2.246329  0.393939  0.453036  0.549920  0.410717              0.004932                0        1.966556                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] SimpleLSTM - Val Acc: 0.4141 | Val F1: 0.4301 | Val AUC: 0.5509\n"
     ]
    }
   ],
   "source": [
    "model_lstm_sampler = SimpleLSTM(n_rois=ROI, n_classes=N_CLASSES, cov_dim=cov_dim, hidden=64, num_layers=1).to(DEVICE)\n",
    "checkpoint_dir_path_lstm = f\"{CHECKPOINT_DIR}/SimpleLSTM_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_lstm, exist_ok=True)\n",
    "\n",
    "print('[DIAG] class counts (full df):', class_counts_main.to_dict())\n",
    "print('[DIAG] unique labels:', sorted(data_df['label'].unique().tolist()))\n",
    "\n",
    "# Прогон со стратегией sampler (WeightedRandomSampler)\n",
    "print('\\n=== SimpleLSTM: балансировка sampler (взвешенный семплинг) ===')\n",
    "history_lstm_sampler = train_model(\n",
    "    model_lstm_sampler, train_dl_sampler, val_dl_sampler, class_counts_main, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_lstm,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "\n",
    "hist_lstm_sampler_df = pd.DataFrame(history_lstm_sampler)\n",
    "print('\\n[HISTORY - sampler] Последние строки:')\n",
    "display(hist_lstm_sampler_df.tail())\n",
    "\n",
    "# Оценка итоговой и лучшей модели\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_lstm, 'best_model.pth')):\n",
    "    model_lstm_sampler.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_lstm, 'best_model.pth')))\n",
    "model_lstm_sampler.eval()\n",
    "val_loss_lstm, val_acc_lstm, val_prec_lstm, val_auc_lstm, val_f1_lstm = Trainer(model_lstm_sampler, train_dl_sampler, val_dl_sampler, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] SimpleLSTM - Val Acc: {val_acc_lstm:.4f} | Val F1: {val_f1_lstm:.4f} | Val AUC: {val_auc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70636061",
   "metadata": {},
   "source": [
    "Обучение модели SimpleLSTM на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера с балансировкой классов (oversample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e641c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DIAG] class counts (full df): {0: 1164, 1: 399, 3: 325, 2: 33}\n",
      "[DIAG] unique labels: [0, 1, 2, 3]\n",
      "\n",
      "=== SimpleLSTM: балансировка oversampling ===\n",
      "Эпоха 1/50 | TrainLoss 0.5929 | ValLoss 1.2530 | Acc 0.1869 | Prec 0.0777 | AUC 0.4686 | F1 0.0943 | Δparam 1.160788e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1462/0.4844/2.3646; GradNorm[mean]: 6.4441\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 1/50 | TrainLoss 0.5929 | ValLoss 1.2530 | Acc 0.1869 | Prec 0.0777 | AUC 0.4686 | F1 0.0943 | Δparam 1.160788e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1462/0.4844/2.3646; GradNorm[mean]: 6.4441\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.3172 | ValLoss 1.4650 | Acc 0.2273 | Prec 0.4291 | AUC 0.5074 | F1 0.1523 | Δparam 8.564926e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0459/0.2719/1.2905; GradNorm[mean]: 4.0780\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.3172 | ValLoss 1.4650 | Acc 0.2273 | Prec 0.4291 | AUC 0.5074 | F1 0.1523 | Δparam 8.564926e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0459/0.2719/1.2905; GradNorm[mean]: 4.0780\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 3/50 | TrainLoss 0.2559 | ValLoss 1.6908 | Acc 0.1894 | Prec 0.4355 | AUC 0.4989 | F1 0.1471 | Δparam 9.903369e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0555/0.1798/1.1536; GradNorm[mean]: 4.6911\n",
      "Эпоха 3/50 | TrainLoss 0.2559 | ValLoss 1.6908 | Acc 0.1894 | Prec 0.4355 | AUC 0.4989 | F1 0.1471 | Δparam 9.903369e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0555/0.1798/1.1536; GradNorm[mean]: 4.6911\n",
      "Эпоха 4/50 | TrainLoss 0.1379 | ValLoss 2.1333 | Acc 0.2222 | Prec 0.3863 | AUC 0.4971 | F1 0.2131 | Δparam 7.995189e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0193/0.1100/1.4113; GradNorm[mean]: 2.9186\n",
      "Эпоха 4/50 | TrainLoss 0.1379 | ValLoss 2.1333 | Acc 0.2222 | Prec 0.3863 | AUC 0.4971 | F1 0.2131 | Δparam 7.995189e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0193/0.1100/1.4113; GradNorm[mean]: 2.9186\n",
      "Эпоха 5/50 | TrainLoss 0.0901 | ValLoss 2.2110 | Acc 0.3157 | Prec 0.4509 | AUC 0.5008 | F1 0.3416 | Δparam 6.560280e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0190/0.0729/0.7553; GradNorm[mean]: 2.1830\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 5/50 | TrainLoss 0.0901 | ValLoss 2.2110 | Acc 0.3157 | Prec 0.4509 | AUC 0.5008 | F1 0.3416 | Δparam 6.560280e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0190/0.0729/0.7553; GradNorm[mean]: 2.1830\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 6/50 | TrainLoss 0.0943 | ValLoss 2.8292 | Acc 0.3586 | Prec 0.4717 | AUC 0.5449 | F1 0.3760 | Δparam 7.786226e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0083/0.0633/1.9736; GradNorm[mean]: 2.4323\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 6/50 | TrainLoss 0.0943 | ValLoss 2.8292 | Acc 0.3586 | Prec 0.4717 | AUC 0.5449 | F1 0.3760 | Δparam 7.786226e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0083/0.0633/1.9736; GradNorm[mean]: 2.4323\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 7/50 | TrainLoss 0.0723 | ValLoss 2.7562 | Acc 0.3485 | Prec 0.4357 | AUC 0.5150 | F1 0.3747 | Δparam 7.708376e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0080/0.0483/1.7773; GradNorm[mean]: 2.0513\n",
      "Эпоха 7/50 | TrainLoss 0.0723 | ValLoss 2.7562 | Acc 0.3485 | Prec 0.4357 | AUC 0.5150 | F1 0.3747 | Δparam 7.708376e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0080/0.0483/1.7773; GradNorm[mean]: 2.0513\n",
      "Эпоха 8/50 | TrainLoss 0.0639 | ValLoss 2.5855 | Acc 0.3965 | Prec 0.4371 | AUC 0.5344 | F1 0.4133 | Δparam 7.585987e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0039/0.0351/1.9736; GradNorm[mean]: 1.6931\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 8/50 | TrainLoss 0.0639 | ValLoss 2.5855 | Acc 0.3965 | Prec 0.4371 | AUC 0.5344 | F1 0.4133 | Δparam 7.585987e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0039/0.0351/1.9736; GradNorm[mean]: 1.6931\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/50 | TrainLoss 0.0489 | ValLoss 2.7614 | Acc 0.3914 | Prec 0.4619 | AUC 0.5321 | F1 0.4150 | Δparam 8.442896e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0041/0.0357/0.4061; GradNorm[mean]: 1.9107\n",
      "Эпоха 9/50 | TrainLoss 0.0489 | ValLoss 2.7614 | Acc 0.3914 | Prec 0.4619 | AUC 0.5321 | F1 0.4150 | Δparam 8.442896e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0041/0.0357/0.4061; GradNorm[mean]: 1.9107\n",
      "Эпоха 10/50 | TrainLoss 0.0724 | ValLoss 2.1006 | Acc 0.3359 | Prec 0.4838 | AUC 0.5532 | F1 0.3555 | Δparam 1.025996e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0024/0.0387/1.5786; GradNorm[mean]: 2.1796\n",
      "Эпоха 10/50 | TrainLoss 0.0724 | ValLoss 2.1006 | Acc 0.3359 | Prec 0.4838 | AUC 0.5532 | F1 0.3555 | Δparam 1.025996e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0024/0.0387/1.5786; GradNorm[mean]: 2.1796\n",
      "Эпоха 11/50 | TrainLoss 0.0658 | ValLoss 2.2832 | Acc 0.3106 | Prec 0.4423 | AUC 0.5220 | F1 0.3267 | Δparam 1.124489e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0043/0.0434/1.1059; GradNorm[mean]: 2.3890\n",
      "Эпоха 11/50 | TrainLoss 0.0658 | ValLoss 2.2832 | Acc 0.3106 | Prec 0.4423 | AUC 0.5220 | F1 0.3267 | Δparam 1.124489e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0043/0.0434/1.1059; GradNorm[mean]: 2.3890\n",
      "Эпоха 12/50 | TrainLoss 0.0534 | ValLoss 2.6095 | Acc 0.3737 | Prec 0.4433 | AUC 0.5205 | F1 0.3967 | Δparam 8.739933e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0037/0.0358/1.0528; GradNorm[mean]: 1.8384\n",
      "Эпоха 12/50 | TrainLoss 0.0534 | ValLoss 2.6095 | Acc 0.3737 | Prec 0.4433 | AUC 0.5205 | F1 0.3967 | Δparam 8.739933e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0037/0.0358/1.0528; GradNorm[mean]: 1.8384\n",
      "Эпоха 13/50 | TrainLoss 0.0356 | ValLoss 2.7479 | Acc 0.4520 | Prec 0.4779 | AUC 0.5644 | F1 0.4631 | Δparam 8.036168e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0021/0.0211/0.5574; GradNorm[mean]: 1.4185\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 13/50 | TrainLoss 0.0356 | ValLoss 2.7479 | Acc 0.4520 | Prec 0.4779 | AUC 0.5644 | F1 0.4631 | Δparam 8.036168e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0021/0.0211/0.5574; GradNorm[mean]: 1.4185\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 14/50 | TrainLoss 0.0483 | ValLoss 2.5242 | Acc 0.3788 | Prec 0.4278 | AUC 0.5135 | F1 0.3972 | Δparam 8.450970e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0029/0.0199/2.1972; GradNorm[mean]: 1.5502\n",
      "Эпоха 14/50 | TrainLoss 0.0483 | ValLoss 2.5242 | Acc 0.3788 | Prec 0.4278 | AUC 0.5135 | F1 0.3972 | Δparam 8.450970e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0029/0.0199/2.1972; GradNorm[mean]: 1.5502\n",
      "Эпоха 15/50 | TrainLoss 0.0396 | ValLoss 2.5368 | Acc 0.4318 | Prec 0.4549 | AUC 0.5493 | F1 0.4404 | Δparam 9.722433e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0240/0.8116; GradNorm[mean]: 1.6222\n",
      "Эпоха 15/50 | TrainLoss 0.0396 | ValLoss 2.5368 | Acc 0.4318 | Prec 0.4549 | AUC 0.5493 | F1 0.4404 | Δparam 9.722433e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0240/0.8116; GradNorm[mean]: 1.6222\n",
      "Эпоха 16/50 | TrainLoss 0.0391 | ValLoss 2.6699 | Acc 0.4495 | Prec 0.4695 | AUC 0.5535 | F1 0.4576 | Δparam 8.954310e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0018/0.0188/0.8792; GradNorm[mean]: 1.5132\n",
      "Эпоха 16/50 | TrainLoss 0.0391 | ValLoss 2.6699 | Acc 0.4495 | Prec 0.4695 | AUC 0.5535 | F1 0.4576 | Δparam 8.954310e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0018/0.0188/0.8792; GradNorm[mean]: 1.5132\n",
      "Эпоха 17/50 | TrainLoss 0.0208 | ValLoss 2.8340 | Acc 0.4773 | Prec 0.4530 | AUC 0.5611 | F1 0.4638 | Δparam 5.501345e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0092/0.9967; GradNorm[mean]: 0.7422\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 17/50 | TrainLoss 0.0208 | ValLoss 2.8340 | Acc 0.4773 | Prec 0.4530 | AUC 0.5611 | F1 0.4638 | Δparam 5.501345e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0092/0.9967; GradNorm[mean]: 0.7422\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 18/50 | TrainLoss 0.0139 | ValLoss 3.0428 | Acc 0.4798 | Prec 0.4585 | AUC 0.5801 | F1 0.4682 | Δparam 6.027061e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0003/0.0064/0.1451; GradNorm[mean]: 0.8194\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 18/50 | TrainLoss 0.0139 | ValLoss 3.0428 | Acc 0.4798 | Prec 0.4585 | AUC 0.5801 | F1 0.4682 | Δparam 6.027061e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0003/0.0064/0.1451; GradNorm[mean]: 0.8194\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 19/50 | TrainLoss 0.0237 | ValLoss 3.3279 | Acc 0.4621 | Prec 0.4682 | AUC 0.5617 | F1 0.4650 | Δparam 9.431161e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0005/0.0087/0.6204; GradNorm[mean]: 1.2664\n",
      "Эпоха 19/50 | TrainLoss 0.0237 | ValLoss 3.3279 | Acc 0.4621 | Prec 0.4682 | AUC 0.5617 | F1 0.4650 | Δparam 9.431161e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0005/0.0087/0.6204; GradNorm[mean]: 1.2664\n",
      "Эпоха 20/50 | TrainLoss 0.0630 | ValLoss 2.7913 | Acc 0.4495 | Prec 0.4602 | AUC 0.5530 | F1 0.4541 | Δparam 1.252445e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0242/1.0511; GradNorm[mean]: 2.0181\n",
      "Эпоха 20/50 | TrainLoss 0.0630 | ValLoss 2.7913 | Acc 0.4495 | Prec 0.4602 | AUC 0.5530 | F1 0.4541 | Δparam 1.252445e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0242/1.0511; GradNorm[mean]: 2.0181\n",
      "Эпоха 21/50 | TrainLoss 0.0256 | ValLoss 3.0590 | Acc 0.3712 | Prec 0.4504 | AUC 0.5391 | F1 0.3944 | Δparam 9.778411e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0013/0.0152/0.4346; GradNorm[mean]: 1.1420\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.2530).\n",
      "Лучший валид. Accuracy: 0.4797979797979798\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n",
      "Эпоха 21/50 | TrainLoss 0.0256 | ValLoss 3.0590 | Acc 0.3712 | Prec 0.4504 | AUC 0.5391 | F1 0.3944 | Δparam 9.778411e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0013/0.0152/0.4346; GradNorm[mean]: 1.1420\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.2530).\n",
      "Лучший валид. Accuracy: 0.4797979797979798\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "98ef8254-e1bf-48c8-a63a-55984bbf65df",
       "rows": [
        [
         "16",
         "17",
         "0.020827262271537236",
         "2.833969719482191",
         "0.4772727272727273",
         "0.4530130951183583",
         "0.5610886237529203",
         "0.46384488458242007",
         "0.00550134526565671",
         "0",
         "0.7421807738964759",
         "0"
        ],
        [
         "17",
         "18",
         "0.013877008880484556",
         "3.0428294250459382",
         "0.4797979797979798",
         "0.45845823807683406",
         "0.5801104809687637",
         "0.4682134381464776",
         "0.0060270605608820915",
         "0",
         "0.819358479822109",
         "0"
        ],
        [
         "18",
         "19",
         "0.02367354386954286",
         "3.3279042280081548",
         "0.4621212121212121",
         "0.46816693407602494",
         "0.561651109570599",
         "0.4650442652989343",
         "0.009431160986423492",
         "0",
         "1.2663888416622098",
         "0"
        ],
        [
         "19",
         "20",
         "0.06304852179620322",
         "2.7912686479212057",
         "0.4494949494949495",
         "0.4601724850847658",
         "0.5529538070958355",
         "0.45407693564315527",
         "0.012524452060461044",
         "0",
         "2.0180838251233517",
         "0"
        ],
        [
         "20",
         "21",
         "0.025602094304648416",
         "3.059045399078215",
         "0.3712121212121212",
         "0.45044052094076353",
         "0.5391222882240713",
         "0.394399771672499",
         "0.009778411127626896",
         "0",
         "1.1420317559737856",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>2.833970</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.453013</td>\n",
       "      <td>0.561089</td>\n",
       "      <td>0.463845</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>3.042829</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.580110</td>\n",
       "      <td>0.468213</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>3.327904</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>0.468167</td>\n",
       "      <td>0.561651</td>\n",
       "      <td>0.465044</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0</td>\n",
       "      <td>1.266389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>2.791269</td>\n",
       "      <td>0.449495</td>\n",
       "      <td>0.460172</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.454077</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0</td>\n",
       "      <td>2.018084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>3.059045</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.450441</td>\n",
       "      <td>0.539122</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "16     17    0.020827  2.833970  0.477273  0.453013  0.561089  0.463845              0.005501                0        0.742181                  0\n",
       "17     18    0.013877  3.042829  0.479798  0.458458  0.580110  0.468213              0.006027                0        0.819358                  0\n",
       "18     19    0.023674  3.327904  0.462121  0.468167  0.561651  0.465044              0.009431                0        1.266389                  0\n",
       "19     20    0.063049  2.791269  0.449495  0.460172  0.552954  0.454077              0.012524                0        2.018084                  0\n",
       "20     21    0.025602  3.059045  0.371212  0.450441  0.539122  0.394400              0.009778                0        1.142032                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Oversample] SimpleLSTM - Val Acc: 0.4798 | Val F1: 0.4682 | Val AUC: 0.5801\n"
     ]
    }
   ],
   "source": [
    "model_lstm_over = SimpleLSTM(n_rois=ROI, n_classes=N_CLASSES, cov_dim=cov_dim, hidden=64, num_layers=1).to(DEVICE)\n",
    "checkpoint_dir_path_lstm_over = f\"{CHECKPOINT_DIR}/SimpleLSTM_oversample\"\n",
    "os.makedirs(checkpoint_dir_path_lstm_over, exist_ok=True)\n",
    "\n",
    "print('[DIAG] class counts (full df):', class_counts_main.to_dict())\n",
    "print('[DIAG] unique labels:', sorted(data_df['label'].unique().tolist()))\n",
    "\n",
    "# Прогон со стратегией sampler (WeightedRandomSampler)\n",
    "print('\\n=== SimpleLSTM: балансировка oversampling ===')\n",
    "history_lstm_over = train_model(\n",
    "    model_lstm_over, train_dl_over, val_dl_over, class_counts_main, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_lstm_over,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "\n",
    "hist_lstm_oversample_df = pd.DataFrame(history_lstm_over)\n",
    "print('\\n[HISTORY - oversample] Последние строки:')\n",
    "display(hist_lstm_oversample_df.tail())\n",
    "\n",
    "# Оценка итоговой и лучшей модели\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_lstm_over, 'best_model.pth')):\n",
    "    model_lstm_over.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_lstm_over, 'best_model.pth')))\n",
    "model_lstm_over.eval()\n",
    "val_loss_lstm_over, val_acc_lstm_over, val_prec_lstm_over, val_auc_lstm_over, val_f1_lstm_over = Trainer(model_lstm_over, train_dl_over, val_dl_over, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@Oversample] SimpleLSTM - Val Acc: {val_acc_lstm_over:.4f} | Val F1: {val_f1_lstm_over:.4f} | Val AUC: {val_auc_lstm_over:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d509e0",
   "metadata": {},
   "source": [
    "### Обучение Simple GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14584d2",
   "metadata": {},
   "source": [
    "Обучение модели SimpleGRU на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера с балансировкой классов (sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f9496f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SimpleGRU: балансировка sampler (взвешенный sampling) ===\n",
      "Эпоха 1/50 | TrainLoss 0.6904 | ValLoss 1.4263 | Acc 0.1944 | Prec 0.0380 | AUC 0.4530 | F1 0.0636 | Δparam 9.235657e-03 | skipped 0\n",
      "Эпоха 1/50 | TrainLoss 0.6904 | ValLoss 1.4263 | Acc 0.1944 | Prec 0.0380 | AUC 0.4530 | F1 0.0636 | Δparam 9.235657e-03 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 0.5353 | ValLoss 1.2552 | Acc 0.1944 | Prec 0.0691 | AUC 0.5047 | F1 0.0681 | Δparam 6.248489e-03 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 0.5353 | ValLoss 1.2552 | Acc 0.1944 | Prec 0.0691 | AUC 0.5047 | F1 0.0681 | Δparam 6.248489e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 0.4654 | ValLoss 1.2593 | Acc 0.1818 | Prec 0.0582 | AUC 0.5120 | F1 0.0683 | Δparam 5.068660e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 0.4654 | ValLoss 1.2593 | Acc 0.1818 | Prec 0.0582 | AUC 0.5120 | F1 0.0683 | Δparam 5.068660e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 0.4537 | ValLoss 1.2152 | Acc 0.1919 | Prec 0.0776 | AUC 0.4695 | F1 0.0751 | Δparam 5.807148e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 0.4537 | ValLoss 1.2152 | Acc 0.1919 | Prec 0.0776 | AUC 0.4695 | F1 0.0751 | Δparam 5.807148e-03 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 0.4030 | ValLoss 1.1641 | Acc 0.1995 | Prec 0.3877 | AUC 0.4833 | F1 0.0953 | Δparam 4.244945e-03 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 0.4030 | ValLoss 1.1641 | Acc 0.1995 | Prec 0.3877 | AUC 0.4833 | F1 0.0953 | Δparam 4.244945e-03 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 0.4008 | ValLoss 1.2557 | Acc 0.1919 | Prec 0.5461 | AUC 0.4699 | F1 0.0974 | Δparam 4.871617e-03 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 0.4008 | ValLoss 1.2557 | Acc 0.1919 | Prec 0.5461 | AUC 0.4699 | F1 0.0974 | Δparam 4.871617e-03 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 0.3618 | ValLoss 1.3044 | Acc 0.1894 | Prec 0.3940 | AUC 0.4648 | F1 0.1110 | Δparam 3.839786e-03 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 0.3618 | ValLoss 1.3044 | Acc 0.1894 | Prec 0.3940 | AUC 0.4648 | F1 0.1110 | Δparam 3.839786e-03 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 0.3501 | ValLoss 1.2954 | Acc 0.1970 | Prec 0.4709 | AUC 0.4571 | F1 0.1142 | Δparam 4.262185e-03 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 0.3501 | ValLoss 1.2954 | Acc 0.1970 | Prec 0.4709 | AUC 0.4571 | F1 0.1142 | Δparam 4.262185e-03 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 0.3705 | ValLoss 1.3407 | Acc 0.1793 | Prec 0.3221 | AUC 0.4550 | F1 0.1265 | Δparam 3.740568e-03 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 0.3705 | ValLoss 1.3407 | Acc 0.1793 | Prec 0.3221 | AUC 0.4550 | F1 0.1265 | Δparam 3.740568e-03 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 0.3661 | ValLoss 1.3693 | Acc 0.1995 | Prec 0.3705 | AUC 0.4796 | F1 0.1740 | Δparam 4.468021e-03 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 0.3661 | ValLoss 1.3693 | Acc 0.1995 | Prec 0.3705 | AUC 0.4796 | F1 0.1740 | Δparam 4.468021e-03 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 0.3471 | ValLoss 1.4770 | Acc 0.2323 | Prec 0.4099 | AUC 0.4540 | F1 0.2204 | Δparam 3.974829e-03 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 0.3471 | ValLoss 1.4770 | Acc 0.2323 | Prec 0.4099 | AUC 0.4540 | F1 0.2204 | Δparam 3.974829e-03 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 0.3511 | ValLoss 1.4953 | Acc 0.2576 | Prec 0.4291 | AUC 0.4637 | F1 0.2640 | Δparam 4.540916e-03 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 0.3511 | ValLoss 1.4953 | Acc 0.2576 | Prec 0.4291 | AUC 0.4637 | F1 0.2640 | Δparam 4.540916e-03 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 0.3165 | ValLoss 1.5404 | Acc 0.2551 | Prec 0.4181 | AUC 0.4645 | F1 0.2658 | Δparam 4.643826e-03 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 0.3165 | ValLoss 1.5404 | Acc 0.2551 | Prec 0.4181 | AUC 0.4645 | F1 0.2658 | Δparam 4.643826e-03 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 0.3168 | ValLoss 1.6427 | Acc 0.2626 | Prec 0.4226 | AUC 0.4749 | F1 0.2729 | Δparam 4.779903e-03 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 0.3168 | ValLoss 1.6427 | Acc 0.2626 | Prec 0.4226 | AUC 0.4749 | F1 0.2729 | Δparam 4.779903e-03 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.3103 | ValLoss 1.5919 | Acc 0.2424 | Prec 0.4252 | AUC 0.4817 | F1 0.2515 | Δparam 5.816665e-03 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.3103 | ValLoss 1.5919 | Acc 0.2424 | Prec 0.4252 | AUC 0.4817 | F1 0.2515 | Δparam 5.816665e-03 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 0.3164 | ValLoss 1.6446 | Acc 0.2727 | Prec 0.4233 | AUC 0.4858 | F1 0.2923 | Δparam 5.073991e-03 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 0.3164 | ValLoss 1.6446 | Acc 0.2727 | Prec 0.4233 | AUC 0.4858 | F1 0.2923 | Δparam 5.073991e-03 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 0.3078 | ValLoss 1.5616 | Acc 0.2424 | Prec 0.4056 | AUC 0.4731 | F1 0.2569 | Δparam 4.498675e-03 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 0.3078 | ValLoss 1.5616 | Acc 0.2424 | Prec 0.4056 | AUC 0.4731 | F1 0.2569 | Δparam 4.498675e-03 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 0.2653 | ValLoss 1.7079 | Acc 0.2551 | Prec 0.4083 | AUC 0.4723 | F1 0.2645 | Δparam 4.795399e-03 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 0.2653 | ValLoss 1.7079 | Acc 0.2551 | Prec 0.4083 | AUC 0.4723 | F1 0.2645 | Δparam 4.795399e-03 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.2482 | ValLoss 1.7099 | Acc 0.2677 | Prec 0.4097 | AUC 0.4699 | F1 0.2784 | Δparam 4.970825e-03 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.2482 | ValLoss 1.7099 | Acc 0.2677 | Prec 0.4097 | AUC 0.4699 | F1 0.2784 | Δparam 4.970825e-03 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.3034 | ValLoss 1.6110 | Acc 0.2652 | Prec 0.4163 | AUC 0.4842 | F1 0.2798 | Δparam 5.688427e-03 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.3034 | ValLoss 1.6110 | Acc 0.2652 | Prec 0.4163 | AUC 0.4842 | F1 0.2798 | Δparam 5.688427e-03 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.2385 | ValLoss 1.6400 | Acc 0.2626 | Prec 0.4218 | AUC 0.4766 | F1 0.2739 | Δparam 5.671598e-03 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.2385 | ValLoss 1.6400 | Acc 0.2626 | Prec 0.4218 | AUC 0.4766 | F1 0.2739 | Δparam 5.671598e-03 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 0.2767 | ValLoss 1.6503 | Acc 0.2348 | Prec 0.4463 | AUC 0.4833 | F1 0.2079 | Δparam 1.204438e-02 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 0.2767 | ValLoss 1.6503 | Acc 0.2348 | Prec 0.4463 | AUC 0.4833 | F1 0.2079 | Δparam 1.204438e-02 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 0.2498 | ValLoss 1.8711 | Acc 0.2475 | Prec 0.4254 | AUC 0.4644 | F1 0.2639 | Δparam 9.380688e-03 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 0.2498 | ValLoss 1.8711 | Acc 0.2475 | Prec 0.4254 | AUC 0.4644 | F1 0.2639 | Δparam 9.380688e-03 | skipped 0\n",
      "Эпоха 24/50 | TrainLoss 0.1972 | ValLoss 1.7051 | Acc 0.2222 | Prec 0.4091 | AUC 0.4690 | F1 0.2229 | Δparam 1.072664e-02 | skipped 0\n",
      "Эпоха 24/50 | TrainLoss 0.1972 | ValLoss 1.7051 | Acc 0.2222 | Prec 0.4091 | AUC 0.4690 | F1 0.2229 | Δparam 1.072664e-02 | skipped 0\n",
      "Эпоха 25/50 | TrainLoss 0.1536 | ValLoss 1.9398 | Acc 0.2121 | Prec 0.3770 | AUC 0.4513 | F1 0.2107 | Δparam 7.644636e-03 | skipped 0\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1641).\n",
      "Лучший валид. Accuracy: 0.2727272727272727\n",
      "[HISTORY GRU - sampler (взвешенный sampling)] Последние строки:\n",
      "Эпоха 25/50 | TrainLoss 0.1536 | ValLoss 1.9398 | Acc 0.2121 | Prec 0.3770 | AUC 0.4513 | F1 0.2107 | Δparam 7.644636e-03 | skipped 0\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1641).\n",
      "Лучший валид. Accuracy: 0.2727272727272727\n",
      "[HISTORY GRU - sampler (взвешенный sampling)] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a5c2592f-67f4-41d6-86a4-8fd308463b30",
       "rows": [
        [
         "20",
         "21",
         "0.23850770010322822",
         "1.6399657654039788",
         "0.26262626262626265",
         "0.42182334573638913",
         "0.47655363166572184",
         "0.2738618277236164",
         "0.005671598017215729",
         "0",
         "2.4288659347609305",
         "0"
        ],
        [
         "21",
         "22",
         "0.2767422653026268",
         "1.6502584495929757",
         "0.23484848484848486",
         "0.4462620916000395",
         "0.4832813797702568",
         "0.20792422581073897",
         "0.012044381350278854",
         "0",
         "3.1554054492638293",
         "0"
        ],
        [
         "22",
         "23",
         "0.2497841834166988",
         "1.8710782166683313",
         "0.2474747474747475",
         "0.4254465819546237",
         "0.4643661786174159",
         "0.2638952058347828",
         "0.009380687959492207",
         "0",
         "3.1495839568572896",
         "0"
        ],
        [
         "23",
         "24",
         "0.1971947952176704",
         "1.7050898147351814",
         "0.2222222222222222",
         "0.4090781265350231",
         "0.46903720350459804",
         "0.22285207633618034",
         "0.010726643726229668",
         "0",
         "4.217957499660163",
         "0"
        ],
        [
         "24",
         "25",
         "0.1535887616066659",
         "1.939805852042304",
         "0.21212121212121213",
         "0.37703734365088953",
         "0.45133480618855804",
         "0.2106514936564863",
         "0.00764463609084487",
         "0",
         "2.7554980039712973",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.238508</td>\n",
       "      <td>1.639966</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.421823</td>\n",
       "      <td>0.476554</td>\n",
       "      <td>0.273862</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0</td>\n",
       "      <td>2.428866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.276742</td>\n",
       "      <td>1.650258</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.446262</td>\n",
       "      <td>0.483281</td>\n",
       "      <td>0.207924</td>\n",
       "      <td>0.012044</td>\n",
       "      <td>0</td>\n",
       "      <td>3.155405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.249784</td>\n",
       "      <td>1.871078</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.425447</td>\n",
       "      <td>0.464366</td>\n",
       "      <td>0.263895</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0</td>\n",
       "      <td>3.149584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.197195</td>\n",
       "      <td>1.705090</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.409078</td>\n",
       "      <td>0.469037</td>\n",
       "      <td>0.222852</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0</td>\n",
       "      <td>4.217957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.153589</td>\n",
       "      <td>1.939806</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.377037</td>\n",
       "      <td>0.451335</td>\n",
       "      <td>0.210651</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0</td>\n",
       "      <td>2.755498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "20     21    0.238508  1.639966  0.262626  0.421823  0.476554  0.273862              0.005672                0        2.428866                  0\n",
       "21     22    0.276742  1.650258  0.234848  0.446262  0.483281  0.207924              0.012044                0        3.155405                  0\n",
       "22     23    0.249784  1.871078  0.247475  0.425447  0.464366  0.263895              0.009381                0        3.149584                  0\n",
       "23     24    0.197195  1.705090  0.222222  0.409078  0.469037  0.222852              0.010727                0        4.217957                  0\n",
       "24     25    0.153589  1.939806  0.212121  0.377037  0.451335  0.210651              0.007645                0        2.755498                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] SimpleGRU - Val Acc: 0.2727 | Val F1: 0.2923 | Val AUC: 0.4858\n"
     ]
    }
   ],
   "source": [
    "model_gru_sampler = SimpleGRU(n_rois=ROI, hidden=64, num_layers=1, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_gru_sampler = f\"{CHECKPOINT_DIR}/SimpleGRU_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_gru_sampler, exist_ok=True)\n",
    "\n",
    "print('\\n=== SimpleGRU: балансировка sampler (взвешенный sampling) ===')\n",
    "if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_gru_sampler, 'best_model.pth')):\n",
    "    history_gru_sampler = train_model(\n",
    "        model_gru_sampler, train_dl_sampler, val_dl_sampler, class_counts_main, DEVICE,\n",
    "        epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_gru_sampler,\n",
    "        lr=LR, weight_decay=WEIGHT_DECAY, debug=False,\n",
    "        early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    "    )\n",
    "    hist_gru_sampler_df = pd.DataFrame(history_gru_sampler)\n",
    "    print('[HISTORY GRU - sampler (взвешенный sampling)] Последние строки:')\n",
    "    display(hist_gru_sampler_df.tail())\n",
    "else:\n",
    "    model_gru_sampler.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_gru_sampler, 'best_model.pth')))\n",
    "    print(\"Загружен существующий чекпоинт SimpleGRU.\")\n",
    "\n",
    "model_gru_sampler.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_gru_sampler, 'best_model.pth')))\n",
    "model_gru_sampler.eval()\n",
    "val_loss_gru_sampler, val_acc_gru_sampler, val_prec_gru_sampler, val_auc_gru_sampler, val_f1_gru_sampler = Trainer(model_gru_sampler, train_dl, val_dl, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] SimpleGRU - Val Acc: {val_acc_gru_sampler:.4f} | Val F1: {val_f1_gru_sampler:.4f} | Val AUC: {val_auc_gru_sampler:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3832d",
   "metadata": {},
   "source": [
    "### Обучение модели ROISequenceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f969cc0",
   "metadata": {},
   "source": [
    "Обучение модели ROISequenceNet на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера со взвешенной балансировкой классов (sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eed1f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ROISequenceNet: балансировка sampler ===\n",
      "Эпоха 1/50 | TrainLoss 0.8690 | ValLoss 1.2307 | Acc 0.1944 | Prec 0.0378 | AUC 0.5211 | F1 0.0633 | Δparam 1.050052e-02 | skipped 0\n",
      "Эпоха 1/50 | TrainLoss 0.8690 | ValLoss 1.2307 | Acc 0.1944 | Prec 0.0378 | AUC 0.5211 | F1 0.0633 | Δparam 1.050052e-02 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 0.8109 | ValLoss 1.4299 | Acc 0.1944 | Prec 0.0380 | AUC 0.5628 | F1 0.0636 | Δparam 6.431568e-03 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 0.8109 | ValLoss 1.4299 | Acc 0.1944 | Prec 0.0380 | AUC 0.5628 | F1 0.0636 | Δparam 6.431568e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 0.4561 | ValLoss 1.2709 | Acc 0.2071 | Prec 0.0444 | AUC 0.5666 | F1 0.0730 | Δparam 5.077603e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 0.4561 | ValLoss 1.2709 | Acc 0.2071 | Prec 0.0444 | AUC 0.5666 | F1 0.0730 | Δparam 5.077603e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 0.4840 | ValLoss 1.0173 | Acc 0.1944 | Prec 0.0387 | AUC 0.5355 | F1 0.0645 | Δparam 3.926505e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 0.4840 | ValLoss 1.0173 | Acc 0.1944 | Prec 0.0387 | AUC 0.5355 | F1 0.0645 | Δparam 3.926505e-03 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 0.3654 | ValLoss 1.2208 | Acc 0.1944 | Prec 0.0378 | AUC 0.5369 | F1 0.0633 | Δparam 4.709755e-03 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 0.3654 | ValLoss 1.2208 | Acc 0.1944 | Prec 0.0378 | AUC 0.5369 | F1 0.0633 | Δparam 4.709755e-03 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 0.3269 | ValLoss 1.0860 | Acc 0.2298 | Prec 0.1057 | AUC 0.5765 | F1 0.1164 | Δparam 4.215213e-03 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 0.3269 | ValLoss 1.0860 | Acc 0.2298 | Prec 0.1057 | AUC 0.5765 | F1 0.1164 | Δparam 4.215213e-03 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 0.2878 | ValLoss 1.7585 | Acc 0.1944 | Prec 0.0378 | AUC 0.5308 | F1 0.0633 | Δparam 4.964369e-03 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 0.2878 | ValLoss 1.7585 | Acc 0.1944 | Prec 0.0378 | AUC 0.5308 | F1 0.0633 | Δparam 4.964369e-03 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 0.3690 | ValLoss 1.2178 | Acc 0.2121 | Prec 0.0802 | AUC 0.5420 | F1 0.1147 | Δparam 3.934637e-03 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 0.3690 | ValLoss 1.2178 | Acc 0.2121 | Prec 0.0802 | AUC 0.5420 | F1 0.1147 | Δparam 3.934637e-03 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 0.2429 | ValLoss 1.2277 | Acc 0.2146 | Prec 0.0833 | AUC 0.5714 | F1 0.1201 | Δparam 3.654540e-03 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 0.2429 | ValLoss 1.2277 | Acc 0.2146 | Prec 0.0833 | AUC 0.5714 | F1 0.1201 | Δparam 3.654540e-03 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 0.1960 | ValLoss 1.4708 | Acc 0.2096 | Prec 0.0866 | AUC 0.5724 | F1 0.0983 | Δparam 3.450034e-03 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 0.1960 | ValLoss 1.4708 | Acc 0.2096 | Prec 0.0866 | AUC 0.5724 | F1 0.0983 | Δparam 3.450034e-03 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 0.1670 | ValLoss 1.3336 | Acc 0.2222 | Prec 0.0842 | AUC 0.5516 | F1 0.1219 | Δparam 3.155163e-03 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 0.1670 | ValLoss 1.3336 | Acc 0.2222 | Prec 0.0842 | AUC 0.5516 | F1 0.1219 | Δparam 3.155163e-03 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 0.1324 | ValLoss 1.6951 | Acc 0.2071 | Prec 0.0789 | AUC 0.5204 | F1 0.1143 | Δparam 2.984650e-03 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 0.1324 | ValLoss 1.6951 | Acc 0.2071 | Prec 0.0789 | AUC 0.5204 | F1 0.1143 | Δparam 2.984650e-03 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 0.1319 | ValLoss 2.0599 | Acc 0.2222 | Prec 0.0982 | AUC 0.5539 | F1 0.1304 | Δparam 4.065870e-03 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 0.1319 | ValLoss 2.0599 | Acc 0.2222 | Prec 0.0982 | AUC 0.5539 | F1 0.1304 | Δparam 4.065870e-03 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 0.1165 | ValLoss 2.0929 | Acc 0.2273 | Prec 0.0893 | AUC 0.5228 | F1 0.1193 | Δparam 2.771439e-03 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 0.1165 | ValLoss 2.0929 | Acc 0.2273 | Prec 0.0893 | AUC 0.5228 | F1 0.1193 | Δparam 2.771439e-03 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.1353 | ValLoss 1.5827 | Acc 0.2146 | Prec 0.0821 | AUC 0.5564 | F1 0.1186 | Δparam 3.509351e-03 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.1353 | ValLoss 1.5827 | Acc 0.2146 | Prec 0.0821 | AUC 0.5564 | F1 0.1186 | Δparam 3.509351e-03 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 0.1097 | ValLoss 2.2328 | Acc 0.2222 | Prec 0.6825 | AUC 0.5511 | F1 0.1427 | Δparam 2.286538e-03 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 0.1097 | ValLoss 2.2328 | Acc 0.2222 | Prec 0.6825 | AUC 0.5511 | F1 0.1427 | Δparam 2.286538e-03 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 0.0844 | ValLoss 3.3925 | Acc 0.2500 | Prec 0.4586 | AUC 0.5452 | F1 0.2280 | Δparam 1.973905e-03 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 0.0844 | ValLoss 3.3925 | Acc 0.2500 | Prec 0.4586 | AUC 0.5452 | F1 0.2280 | Δparam 1.973905e-03 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 0.0650 | ValLoss 3.5790 | Acc 0.2904 | Prec 0.4403 | AUC 0.5270 | F1 0.2874 | Δparam 1.758496e-03 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 0.0650 | ValLoss 3.5790 | Acc 0.2904 | Prec 0.4403 | AUC 0.5270 | F1 0.2874 | Δparam 1.758496e-03 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.0634 | ValLoss 4.1314 | Acc 0.3611 | Prec 0.4481 | AUC 0.5457 | F1 0.3767 | Δparam 1.687393e-03 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.0634 | ValLoss 4.1314 | Acc 0.3611 | Prec 0.4481 | AUC 0.5457 | F1 0.3767 | Δparam 1.687393e-03 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.1183 | ValLoss 1.7318 | Acc 0.2475 | Prec 0.4557 | AUC 0.5192 | F1 0.1711 | Δparam 2.897068e-03 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.1183 | ValLoss 1.7318 | Acc 0.2475 | Prec 0.4557 | AUC 0.5192 | F1 0.1711 | Δparam 2.897068e-03 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.1202 | ValLoss 2.2850 | Acc 0.2475 | Prec 0.4181 | AUC 0.5538 | F1 0.2014 | Δparam 2.879278e-03 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.1202 | ValLoss 2.2850 | Acc 0.2475 | Prec 0.4181 | AUC 0.5538 | F1 0.2014 | Δparam 2.879278e-03 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 0.0660 | ValLoss 3.5006 | Acc 0.2929 | Prec 0.4171 | AUC 0.5401 | F1 0.3011 | Δparam 1.908917e-03 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 0.0660 | ValLoss 3.5006 | Acc 0.2929 | Prec 0.4171 | AUC 0.5401 | F1 0.3011 | Δparam 1.908917e-03 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 0.0727 | ValLoss 2.6761 | Acc 0.3662 | Prec 0.4568 | AUC 0.5388 | F1 0.3816 | Δparam 1.990265e-03 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 0.0727 | ValLoss 2.6761 | Acc 0.3662 | Prec 0.4568 | AUC 0.5388 | F1 0.3816 | Δparam 1.990265e-03 | skipped 0\n",
      "Эпоха 24/50 | TrainLoss 0.0538 | ValLoss 3.1225 | Acc 0.4141 | Prec 0.4736 | AUC 0.5565 | F1 0.4325 | Δparam 2.360703e-03 | skipped 0\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.0173).\n",
      "Лучший валид. Accuracy: 0.41414141414141414\n",
      "[HISTORY ROISequenceNet - sampler] Последние строки:\n",
      "Эпоха 24/50 | TrainLoss 0.0538 | ValLoss 3.1225 | Acc 0.4141 | Prec 0.4736 | AUC 0.5565 | F1 0.4325 | Δparam 2.360703e-03 | skipped 0\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.0173).\n",
      "Лучший валид. Accuracy: 0.41414141414141414\n",
      "[HISTORY ROISequenceNet - sampler] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c1b90a40-d793-42e9-ad6d-6b11ba8e39bc",
       "rows": [
        [
         "19",
         "20",
         "0.11825905893914035",
         "1.7318457060992116",
         "0.2474747474747475",
         "0.4556661799624748",
         "0.5191800849534782",
         "0.17114203465198252",
         "0.002897067693993449",
         "0",
         "3.8702603341979605",
         "0"
        ],
        [
         "20",
         "21",
         "0.12017533332598014",
         "2.2849858367081843",
         "0.2474747474747475",
         "0.4180999904638248",
         "0.553784280766714",
         "0.20141315125172973",
         "0.0028792780358344316",
         "0",
         "3.4314061119937698",
         "0"
        ],
        [
         "21",
         "22",
         "0.06599267129282482",
         "3.5005661441822244",
         "0.29292929292929293",
         "0.4171027880849309",
         "0.5401020689327851",
         "0.301135017552928",
         "0.0019089170964434743",
         "0",
         "1.7816388843387017",
         "0"
        ],
        [
         "22",
         "23",
         "0.07269408287327797",
         "2.6760904813053634",
         "0.3661616161616162",
         "0.4567504532958998",
         "0.5387513361653381",
         "0.3816192892983593",
         "0.001990264980122447",
         "0",
         "2.1542401769728534",
         "0"
        ],
        [
         "23",
         "24",
         "0.05384361424651302",
         "3.1224747029217808",
         "0.41414141414141414",
         "0.4736052732375577",
         "0.5565309065662691",
         "0.4324627820167196",
         "0.0023607034236192703",
         "0",
         "2.2421031845975854",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.118259</td>\n",
       "      <td>1.731846</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.455666</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.171142</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0</td>\n",
       "      <td>3.870260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.120175</td>\n",
       "      <td>2.284986</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>0.418100</td>\n",
       "      <td>0.553784</td>\n",
       "      <td>0.201413</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0</td>\n",
       "      <td>3.431406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.065993</td>\n",
       "      <td>3.500566</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.417103</td>\n",
       "      <td>0.540102</td>\n",
       "      <td>0.301135</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0</td>\n",
       "      <td>1.781639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.072694</td>\n",
       "      <td>2.676090</td>\n",
       "      <td>0.366162</td>\n",
       "      <td>0.456750</td>\n",
       "      <td>0.538751</td>\n",
       "      <td>0.381619</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0</td>\n",
       "      <td>2.154240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.053844</td>\n",
       "      <td>3.122475</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.473605</td>\n",
       "      <td>0.556531</td>\n",
       "      <td>0.432463</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0</td>\n",
       "      <td>2.242103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "19     20    0.118259  1.731846  0.247475  0.455666  0.519180  0.171142              0.002897                0        3.870260                  0\n",
       "20     21    0.120175  2.284986  0.247475  0.418100  0.553784  0.201413              0.002879                0        3.431406                  0\n",
       "21     22    0.065993  3.500566  0.292929  0.417103  0.540102  0.301135              0.001909                0        1.781639                  0\n",
       "22     23    0.072694  2.676090  0.366162  0.456750  0.538751  0.381619              0.001990                0        2.154240                  0\n",
       "23     24    0.053844  3.122475  0.414141  0.473605  0.556531  0.432463              0.002361                0        2.242103                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] ROISequenceNet - Val Acc: 0.4141 | Val F1: 0.4325 | Val AUC: 0.5565\n"
     ]
    }
   ],
   "source": [
    "model_roi_seq_net_sampler = ROISequenceNet(n_roi=R, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net_sampler = f\"{CHECKPOINT_DIR}/ROISequenceNet_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net_sampler, exist_ok=True)\n",
    "\n",
    "print('\\n=== ROISequenceNet: балансировка sampler ===')\n",
    "if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net_sampler, 'best_model.pth')):\n",
    "    history_roi_seq_sampler = train_model(\n",
    "        model_roi_seq_net_sampler, train_dl_sampler, val_dl_sampler, class_counts_main, DEVICE,\n",
    "        epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net_sampler,\n",
    "        lr=LR, weight_decay=WEIGHT_DECAY, debug=False,\n",
    "        early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    "    )\n",
    "    hist_roi_seq_sampler_df = pd.DataFrame(history_roi_seq_sampler)\n",
    "    print('[HISTORY ROISequenceNet - sampler] Последние строки:')\n",
    "    display(hist_roi_seq_sampler_df.tail())\n",
    "else:\n",
    "    model_roi_seq_net_sampler.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_sampler, 'best_model.pth')))\n",
    "    print(\"Загружен существующий чекпоинт ROISequenceNet.\")\n",
    "\n",
    "model_roi_seq_net_sampler.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_sampler, 'best_model.pth')))\n",
    "model_roi_seq_net_sampler.eval()\n",
    "val_loss_roi_seq_net_sampler, val_acc_roi_seq_net_sampler, val_prec_roi_seq_net_sampler, val_auc_roi_seq_net_sampler, val_f1_roi_seq_net_sampler = Trainer(model_roi_seq_net_sampler, train_dl_sampler, val_dl_sampler, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] ROISequenceNet - Val Acc: {val_acc_roi_seq_net_sampler:.4f} | Val F1: {val_f1_roi_seq_net_sampler:.4f} | Val AUC: {val_auc_roi_seq_net_sampler:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a51f5",
   "metadata": {},
   "source": [
    "Обучение модели ROISequenceNet на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера с балансировкой классов (oversample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "36f5b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ROISequenceNet: альтернативный прогон с oversample =====\n",
      "Эпоха 1/50 | TrainLoss 0.7531 | ValLoss 1.3115 | Acc 0.1843 | Prec 0.0391 | AUC 0.5145 | F1 0.0645 | Δparam 1.667507e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2797/0.6779/2.9995; GradNorm[mean]: 4.7090\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 1/50 | TrainLoss 0.7531 | ValLoss 1.3115 | Acc 0.1843 | Prec 0.0391 | AUC 0.5145 | F1 0.0645 | Δparam 1.667507e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2797/0.6779/2.9995; GradNorm[mean]: 4.7090\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.4691 | ValLoss 1.4332 | Acc 0.1944 | Prec 0.1325 | AUC 0.5105 | F1 0.0826 | Δparam 8.010887e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1515/0.4231/1.8607; GradNorm[mean]: 4.4240\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.4691 | ValLoss 1.4332 | Acc 0.1944 | Prec 0.1325 | AUC 0.5105 | F1 0.0826 | Δparam 8.010887e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1515/0.4231/1.8607; GradNorm[mean]: 4.4240\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 3/50 | TrainLoss 0.3958 | ValLoss 1.1635 | Acc 0.1970 | Prec 0.0933 | AUC 0.4968 | F1 0.0993 | Δparam 6.665973e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1132/0.3322/1.9458; GradNorm[mean]: 4.6819\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 3/50 | TrainLoss 0.3958 | ValLoss 1.1635 | Acc 0.1970 | Prec 0.0933 | AUC 0.4968 | F1 0.0993 | Δparam 6.665973e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1132/0.3322/1.9458; GradNorm[mean]: 4.6819\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 4/50 | TrainLoss 0.3077 | ValLoss 1.9203 | Acc 0.2096 | Prec 0.0839 | AUC 0.4938 | F1 0.1169 | Δparam 6.066298e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0785/0.2559/1.3383; GradNorm[mean]: 5.0690\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 4/50 | TrainLoss 0.3077 | ValLoss 1.9203 | Acc 0.2096 | Prec 0.0839 | AUC 0.4938 | F1 0.1169 | Δparam 6.066298e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0785/0.2559/1.3383; GradNorm[mean]: 5.0690\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 5/50 | TrainLoss 0.2415 | ValLoss 1.8907 | Acc 0.2045 | Prec 0.0791 | AUC 0.5058 | F1 0.1129 | Δparam 6.869670e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0584/0.1973/2.3935; GradNorm[mean]: 5.2417\n",
      "Эпоха 5/50 | TrainLoss 0.2415 | ValLoss 1.8907 | Acc 0.2045 | Prec 0.0791 | AUC 0.5058 | F1 0.1129 | Δparam 6.869670e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0584/0.1973/2.3935; GradNorm[mean]: 5.2417\n",
      "Эпоха 6/50 | TrainLoss 0.1878 | ValLoss 2.0332 | Acc 0.1919 | Prec 0.0735 | AUC 0.5106 | F1 0.1053 | Δparam 6.145091e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0215/0.1286/1.2750; GradNorm[mean]: 4.1890\n",
      "Эпоха 6/50 | TrainLoss 0.1878 | ValLoss 2.0332 | Acc 0.1919 | Prec 0.0735 | AUC 0.5106 | F1 0.1053 | Δparam 6.145091e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0215/0.1286/1.2750; GradNorm[mean]: 4.1890\n",
      "Эпоха 7/50 | TrainLoss 0.1612 | ValLoss 1.9923 | Acc 0.2020 | Prec 0.0777 | AUC 0.4952 | F1 0.1120 | Δparam 5.525019e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0227/0.1173/1.0922; GradNorm[mean]: 4.0037\n",
      "Эпоха 7/50 | TrainLoss 0.1612 | ValLoss 1.9923 | Acc 0.2020 | Prec 0.0777 | AUC 0.4952 | F1 0.1120 | Δparam 5.525019e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0227/0.1173/1.0922; GradNorm[mean]: 4.0037\n",
      "Эпоха 8/50 | TrainLoss 0.1024 | ValLoss 3.3087 | Acc 0.2197 | Prec 0.3908 | AUC 0.5079 | F1 0.1597 | Δparam 3.515279e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0119/0.0816/0.4736; GradNorm[mean]: 2.2689\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 8/50 | TrainLoss 0.1024 | ValLoss 3.3087 | Acc 0.2197 | Prec 0.3908 | AUC 0.5079 | F1 0.1597 | Δparam 3.515279e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0119/0.0816/0.4736; GradNorm[mean]: 2.2689\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/50 | TrainLoss 0.0906 | ValLoss 3.7993 | Acc 0.3030 | Prec 0.4311 | AUC 0.5246 | F1 0.3104 | Δparam 2.938742e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0077/0.0727/0.3735; GradNorm[mean]: 2.1143\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/50 | TrainLoss 0.0906 | ValLoss 3.7993 | Acc 0.3030 | Prec 0.4311 | AUC 0.5246 | F1 0.3104 | Δparam 2.938742e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0077/0.0727/0.3735; GradNorm[mean]: 2.1143\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 10/50 | TrainLoss 0.0924 | ValLoss 3.8107 | Acc 0.2247 | Prec 0.4675 | AUC 0.5209 | F1 0.1609 | Δparam 4.579786e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0067/0.0734/0.8003; GradNorm[mean]: 2.5727\n",
      "Эпоха 10/50 | TrainLoss 0.0924 | ValLoss 3.8107 | Acc 0.2247 | Prec 0.4675 | AUC 0.5209 | F1 0.1609 | Δparam 4.579786e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0067/0.0734/0.8003; GradNorm[mean]: 2.5727\n",
      "Эпоха 11/50 | TrainLoss 0.0754 | ValLoss 4.7651 | Acc 0.3308 | Prec 0.4558 | AUC 0.5219 | F1 0.3445 | Δparam 3.156448e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0120/0.0574/0.4628; GradNorm[mean]: 1.8050\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 11/50 | TrainLoss 0.0754 | ValLoss 4.7651 | Acc 0.3308 | Prec 0.4558 | AUC 0.5219 | F1 0.3445 | Δparam 3.156448e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0120/0.0574/0.4628; GradNorm[mean]: 1.8050\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 12/50 | TrainLoss 0.0631 | ValLoss 4.4847 | Acc 0.3737 | Prec 0.4619 | AUC 0.5147 | F1 0.3955 | Δparam 3.826227e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0088/0.0456/0.5682; GradNorm[mean]: 2.0102\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 12/50 | TrainLoss 0.0631 | ValLoss 4.4847 | Acc 0.3737 | Prec 0.4619 | AUC 0.5147 | F1 0.3955 | Δparam 3.826227e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0088/0.0456/0.5682; GradNorm[mean]: 2.0102\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 13/50 | TrainLoss 0.1179 | ValLoss 4.5205 | Acc 0.2045 | Prec 0.5289 | AUC 0.4859 | F1 0.1453 | Δparam 6.237110e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0056/0.0805/0.6725; GradNorm[mean]: 3.7718\n",
      "Эпоха 13/50 | TrainLoss 0.1179 | ValLoss 4.5205 | Acc 0.2045 | Prec 0.5289 | AUC 0.4859 | F1 0.1453 | Δparam 6.237110e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0056/0.0805/0.6725; GradNorm[mean]: 3.7718\n",
      "Эпоха 14/50 | TrainLoss 0.0931 | ValLoss 4.2632 | Acc 0.2879 | Prec 0.4384 | AUC 0.5134 | F1 0.2812 | Δparam 3.817247e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0079/0.0695/0.8228; GradNorm[mean]: 2.3168\n",
      "Эпоха 14/50 | TrainLoss 0.0931 | ValLoss 4.2632 | Acc 0.2879 | Prec 0.4384 | AUC 0.5134 | F1 0.2812 | Δparam 3.817247e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0079/0.0695/0.8228; GradNorm[mean]: 2.3168\n",
      "Эпоха 15/50 | TrainLoss 0.0662 | ValLoss 4.4243 | Acc 0.3763 | Prec 0.4307 | AUC 0.5033 | F1 0.3940 | Δparam 3.820260e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0049/0.0435/0.8248; GradNorm[mean]: 2.1620\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 15/50 | TrainLoss 0.0662 | ValLoss 4.4243 | Acc 0.3763 | Prec 0.4307 | AUC 0.5033 | F1 0.3940 | Δparam 3.820260e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0049/0.0435/0.8248; GradNorm[mean]: 2.1620\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 16/50 | TrainLoss 0.0810 | ValLoss 3.5468 | Acc 0.3485 | Prec 0.4189 | AUC 0.4980 | F1 0.3661 | Δparam 4.147904e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0058/0.0477/1.2762; GradNorm[mean]: 2.5079\n",
      "Эпоха 16/50 | TrainLoss 0.0810 | ValLoss 3.5468 | Acc 0.3485 | Prec 0.4189 | AUC 0.4980 | F1 0.3661 | Δparam 4.147904e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0058/0.0477/1.2762; GradNorm[mean]: 2.5079\n",
      "Эпоха 17/50 | TrainLoss 0.0685 | ValLoss 3.3634 | Acc 0.2929 | Prec 0.4177 | AUC 0.5078 | F1 0.2957 | Δparam 4.136801e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0011/0.0488/0.6816; GradNorm[mean]: 2.4520\n",
      "Эпоха 17/50 | TrainLoss 0.0685 | ValLoss 3.3634 | Acc 0.2929 | Prec 0.4177 | AUC 0.5078 | F1 0.2957 | Δparam 4.136801e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0011/0.0488/0.6816; GradNorm[mean]: 2.4520\n",
      "Эпоха 18/50 | TrainLoss 0.0601 | ValLoss 3.9939 | Acc 0.3131 | Prec 0.4063 | AUC 0.4782 | F1 0.3253 | Δparam 4.462390e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0029/0.0369/0.9016; GradNorm[mean]: 2.3003\n",
      "Эпоха 18/50 | TrainLoss 0.0601 | ValLoss 3.9939 | Acc 0.3131 | Prec 0.4063 | AUC 0.4782 | F1 0.3253 | Δparam 4.462390e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0029/0.0369/0.9016; GradNorm[mean]: 2.3003\n",
      "Эпоха 19/50 | TrainLoss 0.0563 | ValLoss 4.2178 | Acc 0.3510 | Prec 0.4377 | AUC 0.5209 | F1 0.3693 | Δparam 4.186865e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0021/0.0397/0.4814; GradNorm[mean]: 2.3446\n",
      "Эпоха 19/50 | TrainLoss 0.0563 | ValLoss 4.2178 | Acc 0.3510 | Prec 0.4377 | AUC 0.5209 | F1 0.3693 | Δparam 4.186865e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0021/0.0397/0.4814; GradNorm[mean]: 2.3446\n",
      "Эпоха 20/50 | TrainLoss 0.0472 | ValLoss 4.5033 | Acc 0.4495 | Prec 0.4614 | AUC 0.5207 | F1 0.4530 | Δparam 4.005092e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0276/1.3208; GradNorm[mean]: 1.9492\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 20/50 | TrainLoss 0.0472 | ValLoss 4.5033 | Acc 0.4495 | Prec 0.4614 | AUC 0.5207 | F1 0.4530 | Δparam 4.005092e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0276/1.3208; GradNorm[mean]: 1.9492\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 21/50 | TrainLoss 0.0550 | ValLoss 4.3045 | Acc 0.4318 | Prec 0.4534 | AUC 0.5246 | F1 0.4393 | Δparam 5.094570e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0039/0.0331/0.5096; GradNorm[mean]: 2.5384\n",
      "Эпоха 21/50 | TrainLoss 0.0550 | ValLoss 4.3045 | Acc 0.4318 | Prec 0.4534 | AUC 0.5246 | F1 0.4393 | Δparam 5.094570e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0039/0.0331/0.5096; GradNorm[mean]: 2.5384\n",
      "Эпоха 22/50 | TrainLoss 0.0554 | ValLoss 4.1037 | Acc 0.3535 | Prec 0.4135 | AUC 0.4947 | F1 0.3713 | Δparam 4.737828e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0017/0.0333/0.9683; GradNorm[mean]: 2.3070\n",
      "Эпоха 22/50 | TrainLoss 0.0554 | ValLoss 4.1037 | Acc 0.3535 | Prec 0.4135 | AUC 0.4947 | F1 0.3713 | Δparam 4.737828e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0017/0.0333/0.9683; GradNorm[mean]: 2.3070\n",
      "Эпоха 23/50 | TrainLoss 0.0457 | ValLoss 2.9955 | Acc 0.3561 | Prec 0.4253 | AUC 0.4972 | F1 0.3771 | Δparam 3.822792e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0017/0.0271/0.5817; GradNorm[mean]: 2.2107\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1635).\n",
      "Лучший валид. Accuracy: 0.4494949494949495\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n",
      "Эпоха 23/50 | TrainLoss 0.0457 | ValLoss 2.9955 | Acc 0.3561 | Prec 0.4253 | AUC 0.4972 | F1 0.3771 | Δparam 3.822792e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0017/0.0271/0.5817; GradNorm[mean]: 2.2107\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=1.1635).\n",
      "Лучший валид. Accuracy: 0.4494949494949495\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b2950229-5716-47b6-992f-1c201f270b4f",
       "rows": [
        [
         "18",
         "19",
         "0.05625008629231102",
         "4.217801440845836",
         "0.351010101010101",
         "0.4377408724749709",
         "0.5208780711375264",
         "0.36925754021861856",
         "0.004186864942312241",
         "0",
         "2.3446010131114527",
         "0"
        ],
        [
         "19",
         "20",
         "0.0472245185978574",
         "4.503306945164998",
         "0.4494949494949495",
         "0.4613729804191034",
         "0.520660001546453",
         "0.45303824046840807",
         "0.004005091730505228",
         "0",
         "1.9491815273910529",
         "0"
        ],
        [
         "20",
         "21",
         "0.055020485678135125",
         "4.304534134238657",
         "0.4318181818181818",
         "0.4534373235460191",
         "0.5245639976940187",
         "0.4392522255954367",
         "0.005094570107758045",
         "0",
         "2.5384262600479874",
         "0"
        ],
        [
         "21",
         "22",
         "0.055357623992019614",
         "4.103723128636678",
         "0.35353535353535354",
         "0.4135112557292084",
         "0.49472961383586456",
         "0.371265762566703",
         "0.004737828392535448",
         "0",
         "2.3070134521686656",
         "0"
        ],
        [
         "22",
         "23",
         "0.04569560610171822",
         "2.9954764806863032",
         "0.3560606060606061",
         "0.4252640190391195",
         "0.49715674134364163",
         "0.3771174853622534",
         "0.0038227916229516268",
         "0",
         "2.2107251284963074",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>4.217801</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.437741</td>\n",
       "      <td>0.520878</td>\n",
       "      <td>0.369258</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0</td>\n",
       "      <td>2.344601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>4.503307</td>\n",
       "      <td>0.449495</td>\n",
       "      <td>0.461373</td>\n",
       "      <td>0.520660</td>\n",
       "      <td>0.453038</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0</td>\n",
       "      <td>1.949182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.055020</td>\n",
       "      <td>4.304534</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.453437</td>\n",
       "      <td>0.524564</td>\n",
       "      <td>0.439252</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0</td>\n",
       "      <td>2.538426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.055358</td>\n",
       "      <td>4.103723</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.413511</td>\n",
       "      <td>0.494730</td>\n",
       "      <td>0.371266</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0</td>\n",
       "      <td>2.307013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.045696</td>\n",
       "      <td>2.995476</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.425264</td>\n",
       "      <td>0.497157</td>\n",
       "      <td>0.377117</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0</td>\n",
       "      <td>2.210725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "18     19    0.056250  4.217801  0.351010  0.437741  0.520878  0.369258              0.004187                0        2.344601                  0\n",
       "19     20    0.047225  4.503307  0.449495  0.461373  0.520660  0.453038              0.004005                0        1.949182                  0\n",
       "20     21    0.055020  4.304534  0.431818  0.453437  0.524564  0.439252              0.005095                0        2.538426                  0\n",
       "21     22    0.055358  4.103723  0.353535  0.413511  0.494730  0.371266              0.004738                0        2.307013                  0\n",
       "22     23    0.045696  2.995476  0.356061  0.425264  0.497157  0.377117              0.003823                0        2.210725                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Oversample] ROISequenceNet - Val Acc: 0.4495 | Val F1: 0.4530 | Val AUC: 0.5207\n"
     ]
    }
   ],
   "source": [
    "# Альтернативный прогон ROISequenceNet с oversample стратегией\n",
    "print('\\n===== ROISequenceNet: альтернативный прогон с oversample =====')\n",
    "\n",
    "model_roi_seq_net_over = ROISequenceNet(n_roi=ROI, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net_over = f\"{CHECKPOINT_DIR}/ROISequenceNet_oversample\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net_over, exist_ok=True)\n",
    "history_roi_seq_oversample = train_model(\n",
    "    model_roi_seq_net_over, train_dl_over, val_dl_over, class_counts_main, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net_over,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "hist_roi_seq_oversample_df = pd.DataFrame(history_roi_seq_oversample)\n",
    "print('\\n[HISTORY - oversample] Последние строки:')\n",
    "display(hist_roi_seq_oversample_df.tail())\n",
    "\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'best_model.pth')):\n",
    "    model_roi_seq_net_over.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'best_model.pth')))\n",
    "model_roi_seq_net_over.eval()\n",
    "val_loss_roi_seq_o, val_acc_roi_seq_o, val_prec_roi_seq_o, val_auc_roi_seq_o, val_f1_roi_seq_o = Trainer(model_roi_seq_net_over, train_dl_over, val_dl_over, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@Oversample] ROISequenceNet - Val Acc: {val_acc_roi_seq_o:.4f} | Val F1: {val_f1_roi_seq_o:.4f} | Val AUC: {val_auc_roi_seq_o:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611eb794",
   "metadata": {},
   "source": [
    "Обучение модели ROISequenceNet на подготовленных данных с использованием DataMode.SEQ_NPY даталоадера без балансировки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e9d27cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ROISequenceNet: альтернативный прогон без балансировки классов =====\n",
      "Эпоха 1/50 | TrainLoss 1.0074 | ValLoss 0.9589 | Acc 0.1944 | Prec 0.0378 | AUC 0.4724 | F1 0.0633 | Δparam 1.009165e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2735/0.7692/3.8082; GradNorm[mean]: 7.7957\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 1/50 | TrainLoss 1.0074 | ValLoss 0.9589 | Acc 0.1944 | Prec 0.0378 | AUC 0.4724 | F1 0.0633 | Δparam 1.009165e-02 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2735/0.7692/3.8082; GradNorm[mean]: 7.7957\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/50 | TrainLoss 0.7863 | ValLoss 1.0159 | Acc 0.1944 | Prec 0.0378 | AUC 0.5240 | F1 0.0633 | Δparam 3.652075e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2962/0.7083/2.3995; GradNorm[mean]: 3.6153\n",
      "Эпоха 2/50 | TrainLoss 0.7863 | ValLoss 1.0159 | Acc 0.1944 | Prec 0.0378 | AUC 0.5240 | F1 0.0633 | Δparam 3.652075e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2962/0.7083/2.3995; GradNorm[mean]: 3.6153\n",
      "Эпоха 3/50 | TrainLoss 0.8019 | ValLoss 1.0362 | Acc 0.1944 | Prec 0.0378 | AUC 0.5348 | F1 0.0633 | Δparam 2.756598e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2238/0.7289/2.9375; GradNorm[mean]: 3.3993\n",
      "Эпоха 3/50 | TrainLoss 0.8019 | ValLoss 1.0362 | Acc 0.1944 | Prec 0.0378 | AUC 0.5348 | F1 0.0633 | Δparam 2.756598e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2238/0.7289/2.9375; GradNorm[mean]: 3.3993\n",
      "Эпоха 4/50 | TrainLoss 0.8231 | ValLoss 1.0037 | Acc 0.1944 | Prec 0.0378 | AUC 0.5315 | F1 0.0633 | Δparam 1.946111e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1779/0.6993/2.2308; GradNorm[mean]: 3.4797\n",
      "Эпоха 4/50 | TrainLoss 0.8231 | ValLoss 1.0037 | Acc 0.1944 | Prec 0.0378 | AUC 0.5315 | F1 0.0633 | Δparam 1.946111e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1779/0.6993/2.2308; GradNorm[mean]: 3.4797\n",
      "Эпоха 5/50 | TrainLoss 0.8765 | ValLoss 0.9331 | Acc 0.1944 | Prec 0.0378 | AUC 0.5506 | F1 0.0633 | Δparam 1.973864e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3009/0.6990/3.4823; GradNorm[mean]: 3.3002\n",
      "Эпоха 5/50 | TrainLoss 0.8765 | ValLoss 0.9331 | Acc 0.1944 | Prec 0.0378 | AUC 0.5506 | F1 0.0633 | Δparam 1.973864e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3009/0.6990/3.4823; GradNorm[mean]: 3.3002\n",
      "Эпоха 6/50 | TrainLoss 0.7786 | ValLoss 0.9400 | Acc 0.1944 | Prec 0.0378 | AUC 0.5575 | F1 0.0633 | Δparam 2.522267e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.4056/0.7276/2.6388; GradNorm[mean]: 2.9149\n",
      "Эпоха 6/50 | TrainLoss 0.7786 | ValLoss 0.9400 | Acc 0.1944 | Prec 0.0378 | AUC 0.5575 | F1 0.0633 | Δparam 2.522267e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.4056/0.7276/2.6388; GradNorm[mean]: 2.9149\n",
      "Эпоха 7/50 | TrainLoss 0.7689 | ValLoss 1.0328 | Acc 0.1944 | Prec 0.0378 | AUC 0.5383 | F1 0.0633 | Δparam 2.279253e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3406/0.6739/4.8411; GradNorm[mean]: 2.8444\n",
      "Эпоха 7/50 | TrainLoss 0.7689 | ValLoss 1.0328 | Acc 0.1944 | Prec 0.0378 | AUC 0.5383 | F1 0.0633 | Δparam 2.279253e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3406/0.6739/4.8411; GradNorm[mean]: 2.8444\n",
      "Эпоха 8/50 | TrainLoss 0.7811 | ValLoss 0.9301 | Acc 0.1944 | Prec 0.0378 | AUC 0.5495 | F1 0.0633 | Δparam 4.418079e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3270/0.6546/2.5161; GradNorm[mean]: 3.6377\n",
      "Эпоха 8/50 | TrainLoss 0.7811 | ValLoss 0.9301 | Acc 0.1944 | Prec 0.0378 | AUC 0.5495 | F1 0.0633 | Δparam 4.418079e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3270/0.6546/2.5161; GradNorm[mean]: 3.6377\n",
      "Эпоха 9/50 | TrainLoss 0.7485 | ValLoss 0.9480 | Acc 0.1944 | Prec 0.0378 | AUC 0.5410 | F1 0.0633 | Δparam 5.165665e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3316/0.6639/2.4813; GradNorm[mean]: 3.2075\n",
      "Эпоха 9/50 | TrainLoss 0.7485 | ValLoss 0.9480 | Acc 0.1944 | Prec 0.0378 | AUC 0.5410 | F1 0.0633 | Δparam 5.165665e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.3316/0.6639/2.4813; GradNorm[mean]: 3.2075\n",
      "Эпоха 10/50 | TrainLoss 0.7684 | ValLoss 1.0441 | Acc 0.1944 | Prec 0.0378 | AUC 0.5278 | F1 0.0633 | Δparam 6.574912e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2944/0.6669/2.3354; GradNorm[mean]: 4.3546\n",
      "Эпоха 10/50 | TrainLoss 0.7684 | ValLoss 1.0441 | Acc 0.1944 | Prec 0.0378 | AUC 0.5278 | F1 0.0633 | Δparam 6.574912e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2944/0.6669/2.3354; GradNorm[mean]: 4.3546\n",
      "Эпоха 11/50 | TrainLoss 0.7814 | ValLoss 0.9424 | Acc 0.1944 | Prec 0.0378 | AUC 0.5180 | F1 0.0633 | Δparam 7.427934e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2138/0.5992/4.1370; GradNorm[mean]: 4.6667\n",
      "Эпоха 11/50 | TrainLoss 0.7814 | ValLoss 0.9424 | Acc 0.1944 | Prec 0.0378 | AUC 0.5180 | F1 0.0633 | Δparam 7.427934e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2138/0.5992/4.1370; GradNorm[mean]: 4.6667\n",
      "Эпоха 12/50 | TrainLoss 0.7319 | ValLoss 1.1563 | Acc 0.1944 | Prec 0.0378 | AUC 0.5060 | F1 0.0633 | Δparam 6.042744e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2807/0.6127/2.4281; GradNorm[mean]: 4.6137\n",
      "Эпоха 12/50 | TrainLoss 0.7319 | ValLoss 1.1563 | Acc 0.1944 | Prec 0.0378 | AUC 0.5060 | F1 0.0633 | Δparam 6.042744e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2807/0.6127/2.4281; GradNorm[mean]: 4.6137\n",
      "Эпоха 13/50 | TrainLoss 0.6877 | ValLoss 1.0293 | Acc 0.1944 | Prec 0.0378 | AUC 0.5058 | F1 0.0633 | Δparam 7.386077e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2167/0.6452/1.9307; GradNorm[mean]: 5.7291\n",
      "Эпоха 13/50 | TrainLoss 0.6877 | ValLoss 1.0293 | Acc 0.1944 | Prec 0.0378 | AUC 0.5058 | F1 0.0633 | Δparam 7.386077e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2167/0.6452/1.9307; GradNorm[mean]: 5.7291\n",
      "Эпоха 14/50 | TrainLoss 0.6788 | ValLoss 1.1715 | Acc 0.1944 | Prec 0.0378 | AUC 0.4903 | F1 0.0633 | Δparam 5.685919e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2306/0.6101/2.5552; GradNorm[mean]: 5.9365\n",
      "Эпоха 14/50 | TrainLoss 0.6788 | ValLoss 1.1715 | Acc 0.1944 | Prec 0.0378 | AUC 0.4903 | F1 0.0633 | Δparam 5.685919e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2306/0.6101/2.5552; GradNorm[mean]: 5.9365\n",
      "Эпоха 15/50 | TrainLoss 0.5986 | ValLoss 1.1070 | Acc 0.1944 | Prec 0.0378 | AUC 0.5020 | F1 0.0633 | Δparam 5.228791e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2066/0.5636/2.2088; GradNorm[mean]: 5.8654\n",
      "Эпоха 15/50 | TrainLoss 0.5986 | ValLoss 1.1070 | Acc 0.1944 | Prec 0.0378 | AUC 0.5020 | F1 0.0633 | Δparam 5.228791e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.2066/0.5636/2.2088; GradNorm[mean]: 5.8654\n",
      "Эпоха 16/50 | TrainLoss 0.5950 | ValLoss 1.1991 | Acc 0.1793 | Prec 0.0679 | AUC 0.4759 | F1 0.0982 | Δparam 6.090780e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1599/0.5242/2.2046; GradNorm[mean]: 7.3208\n",
      "Эпоха 16/50 | TrainLoss 0.5950 | ValLoss 1.1991 | Acc 0.1793 | Prec 0.0679 | AUC 0.4759 | F1 0.0982 | Δparam 6.090780e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1599/0.5242/2.2046; GradNorm[mean]: 7.3208\n",
      "Эпоха 17/50 | TrainLoss 0.4791 | ValLoss 1.7371 | Acc 0.1869 | Prec 0.0706 | AUC 0.4939 | F1 0.0977 | Δparam 5.268359e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1024/0.3856/1.8544; GradNorm[mean]: 6.8894\n",
      "Эпоха 17/50 | TrainLoss 0.4791 | ValLoss 1.7371 | Acc 0.1869 | Prec 0.0706 | AUC 0.4939 | F1 0.0977 | Δparam 5.268359e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1024/0.3856/1.8544; GradNorm[mean]: 6.8894\n",
      "Эпоха 18/50 | TrainLoss 0.3860 | ValLoss 1.4297 | Acc 0.2500 | Prec 0.3970 | AUC 0.4717 | F1 0.2514 | Δparam 4.626225e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0965/0.3083/1.9281; GradNorm[mean]: 6.2900\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 18/50 | TrainLoss 0.3860 | ValLoss 1.4297 | Acc 0.2500 | Prec 0.3970 | AUC 0.4717 | F1 0.2514 | Δparam 4.626225e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0965/0.3083/1.9281; GradNorm[mean]: 6.2900\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 19/50 | TrainLoss 0.4530 | ValLoss 1.9863 | Acc 0.2247 | Prec 0.4217 | AUC 0.4794 | F1 0.2220 | Δparam 4.438308e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0907/0.3334/2.3879; GradNorm[mean]: 6.6007\n",
      "Эпоха 19/50 | TrainLoss 0.4530 | ValLoss 1.9863 | Acc 0.2247 | Prec 0.4217 | AUC 0.4794 | F1 0.2220 | Δparam 4.438308e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0907/0.3334/2.3879; GradNorm[mean]: 6.6007\n",
      "Эпоха 20/50 | TrainLoss 0.3413 | ValLoss 2.2191 | Acc 0.2399 | Prec 0.4223 | AUC 0.4931 | F1 0.2223 | Δparam 3.427844e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0497/0.2320/3.0057; GradNorm[mean]: 4.1322\n",
      "Эпоха 20/50 | TrainLoss 0.3413 | ValLoss 2.2191 | Acc 0.2399 | Prec 0.4223 | AUC 0.4931 | F1 0.2223 | Δparam 3.427844e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0497/0.2320/3.0057; GradNorm[mean]: 4.1322\n",
      "Эпоха 21/50 | TrainLoss 0.3423 | ValLoss 2.0378 | Acc 0.3409 | Prec 0.4500 | AUC 0.4899 | F1 0.3650 | Δparam 4.470349e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0561/0.2457/1.5469; GradNorm[mean]: 5.7839\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 21/50 | TrainLoss 0.3423 | ValLoss 2.0378 | Acc 0.3409 | Prec 0.4500 | AUC 0.4899 | F1 0.3650 | Δparam 4.470349e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0561/0.2457/1.5469; GradNorm[mean]: 5.7839\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 22/50 | TrainLoss 0.2965 | ValLoss 3.0781 | Acc 0.5000 | Prec 0.3743 | AUC 0.4765 | F1 0.4272 | Δparam 3.281185e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0484/0.2243/1.0128; GradNorm[mean]: 4.1613\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 22/50 | TrainLoss 0.2965 | ValLoss 3.0781 | Acc 0.5000 | Prec 0.3743 | AUC 0.4765 | F1 0.4272 | Δparam 3.281185e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0484/0.2243/1.0128; GradNorm[mean]: 4.1613\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 23/50 | TrainLoss 0.2707 | ValLoss 2.7431 | Acc 0.2980 | Prec 0.4006 | AUC 0.4760 | F1 0.3204 | Δparam 2.974683e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0415/0.2083/1.3759; GradNorm[mean]: 3.5740\n",
      "Эпоха 23/50 | TrainLoss 0.2707 | ValLoss 2.7431 | Acc 0.2980 | Prec 0.4006 | AUC 0.4760 | F1 0.3204 | Δparam 2.974683e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0415/0.2083/1.3759; GradNorm[mean]: 3.5740\n",
      "Эпоха 24/50 | TrainLoss 0.2100 | ValLoss 3.7390 | Acc 0.4343 | Prec 0.4258 | AUC 0.4942 | F1 0.4298 | Δparam 2.231508e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0558/0.1869/0.7778; GradNorm[mean]: 2.9326\n",
      "Эпоха 24/50 | TrainLoss 0.2100 | ValLoss 3.7390 | Acc 0.4343 | Prec 0.4258 | AUC 0.4942 | F1 0.4298 | Δparam 2.231508e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0558/0.1869/0.7778; GradNorm[mean]: 2.9326\n",
      "Эпоха 25/50 | TrainLoss 0.2204 | ValLoss 3.5753 | Acc 0.3763 | Prec 0.4338 | AUC 0.5042 | F1 0.3939 | Δparam 2.534158e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0378/0.1746/0.8922; GradNorm[mean]: 3.6410\n",
      "Эпоха 25/50 | TrainLoss 0.2204 | ValLoss 3.5753 | Acc 0.3763 | Prec 0.4338 | AUC 0.5042 | F1 0.3939 | Δparam 2.534158e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0378/0.1746/0.8922; GradNorm[mean]: 3.6410\n",
      "Эпоха 26/50 | TrainLoss 0.2145 | ValLoss 4.6302 | Acc 0.2879 | Prec 0.4027 | AUC 0.4872 | F1 0.3032 | Δparam 2.474344e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0548/0.1642/1.0812; GradNorm[mean]: 3.5729\n",
      "Эпоха 26/50 | TrainLoss 0.2145 | ValLoss 4.6302 | Acc 0.2879 | Prec 0.4027 | AUC 0.4872 | F1 0.3032 | Δparam 2.474344e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0548/0.1642/1.0812; GradNorm[mean]: 3.5729\n",
      "Эпоха 27/50 | TrainLoss 0.2253 | ValLoss 3.7149 | Acc 0.3737 | Prec 0.4175 | AUC 0.4961 | F1 0.3897 | Δparam 2.725424e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0188/0.1647/1.8062; GradNorm[mean]: 3.6758\n",
      "Эпоха 27/50 | TrainLoss 0.2253 | ValLoss 3.7149 | Acc 0.3737 | Prec 0.4175 | AUC 0.4961 | F1 0.3897 | Δparam 2.725424e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0188/0.1647/1.8062; GradNorm[mean]: 3.6758\n",
      "Эпоха 28/50 | TrainLoss 0.1915 | ValLoss 4.9026 | Acc 0.3636 | Prec 0.4435 | AUC 0.5485 | F1 0.3721 | Δparam 2.736091e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0120/0.1371/0.7949; GradNorm[mean]: 3.2585\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=0.9301).\n",
      "Лучший валид. Accuracy: 0.5\n",
      "\n",
      "[HISTORY - no balance] Последние строки:\n",
      "Эпоха 28/50 | TrainLoss 0.1915 | ValLoss 4.9026 | Acc 0.3636 | Prec 0.4435 | AUC 0.5485 | F1 0.3721 | Δparam 2.736091e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0120/0.1371/0.7949; GradNorm[mean]: 3.2585\n",
      "[EARLY STOP] metric=val_loss no improve 20 epochs (best=0.9301).\n",
      "Лучший валид. Accuracy: 0.5\n",
      "\n",
      "[HISTORY - no balance] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "027e8745-2521-4bfa-878c-6662f5b80510",
       "rows": [
        [
         "23",
         "24",
         "0.2099864125447195",
         "3.7390078631314365",
         "0.43434343434343436",
         "0.4257959365397382",
         "0.49416276312601126",
         "0.4298338308010357",
         "0.0022315082605928183",
         "0",
         "2.9326339216672994",
         "0"
        ],
        [
         "24",
         "25",
         "0.22044243867280053",
         "3.575323001302854",
         "0.37626262626262624",
         "0.43378843821110136",
         "0.504230909839096",
         "0.3938574594360529",
         "0.002534158295020461",
         "0",
         "3.641003075394645",
         "0"
        ],
        [
         "25",
         "26",
         "0.21448166706522956",
         "4.6301599030542855",
         "0.2878787878787879",
         "0.4026785714285714",
         "0.48719704058388863",
         "0.3031977688150016",
         "0.0024743443354964256",
         "0",
         "3.572903988164493",
         "0"
        ],
        [
         "26",
         "27",
         "0.2253367746364875",
         "3.7149089129284176",
         "0.37373737373737376",
         "0.4174947664939266",
         "0.49613992539508567",
         "0.3897401995410104",
         "0.0027254242449998856",
         "0",
         "3.6757744536388564",
         "0"
        ],
        [
         "27",
         "28",
         "0.19147764921921198",
         "4.902567976652974",
         "0.36363636363636365",
         "0.44350356458309187",
         "0.5484729585090298",
         "0.37212182663564114",
         "0.0027360906824469566",
         "0",
         "3.2585326275197986",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.209986</td>\n",
       "      <td>3.739008</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.425796</td>\n",
       "      <td>0.494163</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0</td>\n",
       "      <td>2.932634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.220442</td>\n",
       "      <td>3.575323</td>\n",
       "      <td>0.376263</td>\n",
       "      <td>0.433788</td>\n",
       "      <td>0.504231</td>\n",
       "      <td>0.393857</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0</td>\n",
       "      <td>3.641003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.214482</td>\n",
       "      <td>4.630160</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.402679</td>\n",
       "      <td>0.487197</td>\n",
       "      <td>0.303198</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0</td>\n",
       "      <td>3.572904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.225337</td>\n",
       "      <td>3.714909</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.417495</td>\n",
       "      <td>0.496140</td>\n",
       "      <td>0.389740</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0</td>\n",
       "      <td>3.675774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.191478</td>\n",
       "      <td>4.902568</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.443504</td>\n",
       "      <td>0.548473</td>\n",
       "      <td>0.372122</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0</td>\n",
       "      <td>3.258533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "23     24    0.209986  3.739008  0.434343  0.425796  0.494163  0.429834              0.002232                0        2.932634                  0\n",
       "24     25    0.220442  3.575323  0.376263  0.433788  0.504231  0.393857              0.002534                0        3.641003                  0\n",
       "25     26    0.214482  4.630160  0.287879  0.402679  0.487197  0.303198              0.002474                0        3.572904                  0\n",
       "26     27    0.225337  3.714909  0.373737  0.417495  0.496140  0.389740              0.002725                0        3.675774                  0\n",
       "27     28    0.191478  4.902568  0.363636  0.443504  0.548473  0.372122              0.002736                0        3.258533                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@NoBalance] ROISequenceNet - Val Acc: 0.5000 | Val F1: 0.4272 | Val AUC: 0.4765\n"
     ]
    }
   ],
   "source": [
    "# Альтернативный прогон ROISequenceNet без балансировки классов\n",
    "print('\\n===== ROISequenceNet: альтернативный прогон без балансировки классов =====')\n",
    "\n",
    "model_roi_seq_net_nb = ROISequenceNet(n_roi=ROI, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net_nb = f\"{CHECKPOINT_DIR}/ROISequenceNet_nobalance\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net_nb, exist_ok=True)\n",
    "history_roi_seq_nobalance = train_model(\n",
    "    model_roi_seq_net_nb, train_dl, val_dl, class_counts_main, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net_nb,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "hist_roi_seq_nobalance_df = pd.DataFrame(history_roi_seq_nobalance)\n",
    "print('\\n[HISTORY - no balance] Последние строки:')\n",
    "display(hist_roi_seq_nobalance_df.tail())\n",
    "\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'best_model.pth')):\n",
    "    model_roi_seq_net_nb.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'best_model.pth')))\n",
    "model_roi_seq_net_nb.eval()\n",
    "val_loss_roi_seq_nb, val_acc_roi_seq_nb, val_prec_roi_seq_nb, val_auc_roi_seq_nb, val_f1_roi_seq_nb = Trainer(model_roi_seq_net_nb, train_dl, val_dl, class_counts_main, DEVICE).evaluate()\n",
    "print(f\"[BEST@NoBalance] ROISequenceNet - Val Acc: {val_acc_roi_seq_nb:.4f} | Val F1: {val_f1_roi_seq_nb:.4f} | Val AUC: {val_auc_roi_seq_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002cb25e",
   "metadata": {},
   "source": [
    "### Обучение Simple MLP (по усреднённым признакам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "920fedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/50 | TrainLoss 82541.5135 | ValLoss 107672.6108 | Acc 0.5985 | Prec 0.3582 | AUC 0.5000 | F1 0.4482 | Δparam 2.739517e-02 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 38200.1107 | ValLoss 7483.2852 | Acc 0.1944 | Prec 0.0378 | AUC 0.4921 | F1 0.0633 | Δparam 6.006883e-03 | skipped 0\n",
      "Эпоха 2/50 | TrainLoss 38200.1107 | ValLoss 7483.2852 | Acc 0.1944 | Prec 0.0378 | AUC 0.4921 | F1 0.0633 | Δparam 6.006883e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 4655.2078 | ValLoss 1.3400 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.199699e-03 | skipped 0\n",
      "Эпоха 3/50 | TrainLoss 4655.2078 | ValLoss 1.3400 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.199699e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 99.2959 | ValLoss 1.2342 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 1.553851e-03 | skipped 0\n",
      "Эпоха 4/50 | TrainLoss 99.2959 | ValLoss 1.2342 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 1.553851e-03 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 74.8804 | ValLoss 1.1610 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 8.704203e-04 | skipped 0\n",
      "Эпоха 5/50 | TrainLoss 74.8804 | ValLoss 1.1610 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 8.704203e-04 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 35.3173 | ValLoss 1.1135 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 8.186849e-04 | skipped 0\n",
      "Эпоха 6/50 | TrainLoss 35.3173 | ValLoss 1.1135 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 8.186849e-04 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 48.0596 | ValLoss 1.0784 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.756908e-04 | skipped 0\n",
      "Эпоха 7/50 | TrainLoss 48.0596 | ValLoss 1.0784 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.756908e-04 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 6.5546 | ValLoss 1.0533 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 6.088678e-04 | skipped 0\n",
      "Эпоха 8/50 | TrainLoss 6.5546 | ValLoss 1.0533 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 6.088678e-04 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 4.0179 | ValLoss 1.0353 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.546962e-04 | skipped 0\n",
      "Эпоха 9/50 | TrainLoss 4.0179 | ValLoss 1.0353 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.546962e-04 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 1.8740 | ValLoss 1.0205 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.663414e-04 | skipped 0\n",
      "Эпоха 10/50 | TrainLoss 1.8740 | ValLoss 1.0205 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.663414e-04 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 29.6899 | ValLoss 1.0092 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.176212e-04 | skipped 0\n",
      "Эпоха 11/50 | TrainLoss 29.6899 | ValLoss 1.0092 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.176212e-04 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 1.8958 | ValLoss 1.0006 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.452314e-04 | skipped 0\n",
      "Эпоха 12/50 | TrainLoss 1.8958 | ValLoss 1.0006 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.452314e-04 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 9.9502 | ValLoss 0.9947 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.654711e-04 | skipped 0\n",
      "Эпоха 13/50 | TrainLoss 9.9502 | ValLoss 0.9947 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.654711e-04 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 11.4427 | ValLoss 0.9898 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.095570e-04 | skipped 0\n",
      "Эпоха 14/50 | TrainLoss 11.4427 | ValLoss 0.9898 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.095570e-04 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.9544 | ValLoss 0.9866 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.820136e-04 | skipped 0\n",
      "Эпоха 15/50 | TrainLoss 0.9544 | ValLoss 0.9866 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.820136e-04 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 11.1666 | ValLoss 0.9843 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.530728e-04 | skipped 0\n",
      "Эпоха 16/50 | TrainLoss 11.1666 | ValLoss 0.9843 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.530728e-04 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 1.3233 | ValLoss 0.9820 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.795956e-04 | skipped 0\n",
      "Эпоха 17/50 | TrainLoss 1.3233 | ValLoss 0.9820 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.795956e-04 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 2.2575 | ValLoss 0.9812 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.384446e-04 | skipped 0\n",
      "Эпоха 18/50 | TrainLoss 2.2575 | ValLoss 0.9812 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.384446e-04 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.8775 | ValLoss 0.9792 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.898341e-04 | skipped 0\n",
      "Эпоха 19/50 | TrainLoss 0.8775 | ValLoss 0.9792 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.898341e-04 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.8166 | ValLoss 0.9777 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 1.950175e-04 | skipped 0\n",
      "Эпоха 20/50 | TrainLoss 0.8166 | ValLoss 0.9777 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 1.950175e-04 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.9772 | ValLoss 0.9760 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.259733e-04 | skipped 0\n",
      "Эпоха 21/50 | TrainLoss 0.9772 | ValLoss 0.9760 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.259733e-04 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 4.0987 | ValLoss 0.9753 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.822704e-04 | skipped 0\n",
      "Эпоха 22/50 | TrainLoss 4.0987 | ValLoss 0.9753 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 5.822704e-04 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 2.2676 | ValLoss 0.9746 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.181352e-04 | skipped 0\n",
      "Эпоха 23/50 | TrainLoss 2.2676 | ValLoss 0.9746 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.181352e-04 | skipped 0\n",
      "Эпоха 24/50 | TrainLoss 0.8124 | ValLoss 0.9731 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.746072e-04 | skipped 0\n",
      "Эпоха 24/50 | TrainLoss 0.8124 | ValLoss 0.9731 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.746072e-04 | skipped 0\n",
      "Эпоха 25/50 | TrainLoss 0.8092 | ValLoss 0.9719 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.480001e-04 | skipped 0\n",
      "Эпоха 25/50 | TrainLoss 0.8092 | ValLoss 0.9719 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.480001e-04 | skipped 0\n",
      "Эпоха 26/50 | TrainLoss 2.3922 | ValLoss 0.9696 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.890264e-04 | skipped 0\n",
      "Эпоха 26/50 | TrainLoss 2.3922 | ValLoss 0.9696 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.890264e-04 | skipped 0\n",
      "Эпоха 27/50 | TrainLoss 0.8082 | ValLoss 0.9689 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.366830e-04 | skipped 0\n",
      "Эпоха 27/50 | TrainLoss 0.8082 | ValLoss 0.9689 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.366830e-04 | skipped 0\n",
      "Эпоха 28/50 | TrainLoss 5.6637 | ValLoss 0.9680 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.799158e-04 | skipped 0\n",
      "Эпоха 28/50 | TrainLoss 5.6637 | ValLoss 0.9680 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.799158e-04 | skipped 0\n",
      "Эпоха 29/50 | TrainLoss 0.8265 | ValLoss 0.9652 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.784710e-04 | skipped 0\n",
      "Эпоха 29/50 | TrainLoss 0.8265 | ValLoss 0.9652 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.784710e-04 | skipped 0\n",
      "Эпоха 30/50 | TrainLoss 0.8137 | ValLoss 0.9639 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.393552e-04 | skipped 0\n",
      "Эпоха 30/50 | TrainLoss 0.8137 | ValLoss 0.9639 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.393552e-04 | skipped 0\n",
      "Эпоха 31/50 | TrainLoss 0.8354 | ValLoss 0.9645 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.162642e-04 | skipped 0\n",
      "Эпоха 31/50 | TrainLoss 0.8354 | ValLoss 0.9645 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.162642e-04 | skipped 0\n",
      "Эпоха 32/50 | TrainLoss 0.8256 | ValLoss 0.9620 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.063807e-04 | skipped 0\n",
      "Эпоха 32/50 | TrainLoss 0.8256 | ValLoss 0.9620 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.063807e-04 | skipped 0\n",
      "Эпоха 33/50 | TrainLoss 0.9689 | ValLoss 0.9627 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.808447e-04 | skipped 0\n",
      "Эпоха 33/50 | TrainLoss 0.9689 | ValLoss 0.9627 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.808447e-04 | skipped 0\n",
      "Эпоха 34/50 | TrainLoss 0.7781 | ValLoss 0.9625 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.795728e-04 | skipped 0\n",
      "Эпоха 34/50 | TrainLoss 0.7781 | ValLoss 0.9625 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.795728e-04 | skipped 0\n",
      "Эпоха 35/50 | TrainLoss 1.6705 | ValLoss 0.9614 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.498699e-04 | skipped 0\n",
      "Эпоха 35/50 | TrainLoss 1.6705 | ValLoss 0.9614 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.498699e-04 | skipped 0\n",
      "Эпоха 36/50 | TrainLoss 0.8097 | ValLoss 0.9598 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.506968e-04 | skipped 0\n",
      "Эпоха 36/50 | TrainLoss 0.8097 | ValLoss 0.9598 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.506968e-04 | skipped 0\n",
      "Эпоха 37/50 | TrainLoss 0.7783 | ValLoss 0.9595 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.099499e-04 | skipped 0\n",
      "Эпоха 37/50 | TrainLoss 0.7783 | ValLoss 0.9595 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.099499e-04 | skipped 0\n",
      "Эпоха 38/50 | TrainLoss 1.4334 | ValLoss 0.9578 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.721452e-04 | skipped 0\n",
      "Эпоха 38/50 | TrainLoss 1.4334 | ValLoss 0.9578 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.721452e-04 | skipped 0\n",
      "Эпоха 39/50 | TrainLoss 13.7222 | ValLoss 0.9566 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.936021e-04 | skipped 0\n",
      "Эпоха 39/50 | TrainLoss 13.7222 | ValLoss 0.9566 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.936021e-04 | skipped 0\n",
      "Эпоха 40/50 | TrainLoss 0.8077 | ValLoss 0.9557 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.174418e-04 | skipped 0\n",
      "Эпоха 40/50 | TrainLoss 0.8077 | ValLoss 0.9557 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.174418e-04 | skipped 0\n",
      "Эпоха 41/50 | TrainLoss 1.2664 | ValLoss 0.9551 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.499541e-04 | skipped 0\n",
      "Эпоха 41/50 | TrainLoss 1.2664 | ValLoss 0.9551 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.499541e-04 | skipped 0\n",
      "Эпоха 42/50 | TrainLoss 0.7980 | ValLoss 0.9538 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.017407e-04 | skipped 0\n",
      "Эпоха 42/50 | TrainLoss 0.7980 | ValLoss 0.9538 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.017407e-04 | skipped 0\n",
      "Эпоха 43/50 | TrainLoss 0.8010 | ValLoss 0.9546 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.476468e-04 | skipped 0\n",
      "Эпоха 43/50 | TrainLoss 0.8010 | ValLoss 0.9546 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.476468e-04 | skipped 0\n",
      "Эпоха 44/50 | TrainLoss 0.8260 | ValLoss 0.9541 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.590012e-04 | skipped 0\n",
      "Эпоха 44/50 | TrainLoss 0.8260 | ValLoss 0.9541 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.590012e-04 | skipped 0\n",
      "Эпоха 45/50 | TrainLoss 0.9787 | ValLoss 0.9556 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.472738e-04 | skipped 0\n",
      "Эпоха 45/50 | TrainLoss 0.9787 | ValLoss 0.9556 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 3.472738e-04 | skipped 0\n",
      "Эпоха 46/50 | TrainLoss 0.8014 | ValLoss 0.9546 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.089003e-04 | skipped 0\n",
      "Эпоха 46/50 | TrainLoss 0.8014 | ValLoss 0.9546 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.089003e-04 | skipped 0\n",
      "Эпоха 47/50 | TrainLoss 0.8332 | ValLoss 0.9549 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.621436e-04 | skipped 0\n",
      "Эпоха 47/50 | TrainLoss 0.8332 | ValLoss 0.9549 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.621436e-04 | skipped 0\n",
      "Эпоха 48/50 | TrainLoss 6.8863 | ValLoss 0.9542 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.051079e-04 | skipped 0\n",
      "Эпоха 48/50 | TrainLoss 6.8863 | ValLoss 0.9542 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 4.051079e-04 | skipped 0\n",
      "Эпоха 49/50 | TrainLoss 3.6091 | ValLoss 0.9535 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.693184e-04 | skipped 0\n",
      "Эпоха 49/50 | TrainLoss 3.6091 | ValLoss 0.9535 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.693184e-04 | skipped 0\n",
      "Эпоха 50/50 | TrainLoss 0.7572 | ValLoss 0.9549 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.703191e-04 | skipped 0\n",
      "Лучший валид. Accuracy: 0.5984848484848485\n",
      "[HISTORY MLP] Последние строки:\n",
      "Эпоха 50/50 | TrainLoss 0.7572 | ValLoss 0.9549 | Acc 0.1944 | Prec 0.0378 | AUC 0.5000 | F1 0.0633 | Δparam 2.703191e-04 | skipped 0\n",
      "Лучший валид. Accuracy: 0.5984848484848485\n",
      "[HISTORY MLP] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b2ca3648-9640-406d-bc81-e5ad143f5b8f",
       "rows": [
        [
         "45",
         "46",
         "0.8013802883273266",
         "0.954552697713929",
         "0.19444444444444445",
         "0.03780864197530864",
         "0.5",
         "0.06330749354005169",
         "0.00020890029554720968",
         "0",
         "0.20269380579702556",
         "0"
        ],
        [
         "46",
         "47",
         "0.8332090133917136",
         "0.9549169633725677",
         "0.19444444444444445",
         "0.03780864197530864",
         "0.5",
         "0.06330749354005169",
         "0.00026214358513243496",
         "0",
         "0.26247348978084367",
         "0"
        ],
        [
         "47",
         "48",
         "6.886340914085263",
         "0.9541639372555897",
         "0.19444444444444445",
         "0.03780864197530864",
         "0.5",
         "0.06330749354005169",
         "0.0004051078576594591",
         "0",
         "0.5085506978395341",
         "0"
        ],
        [
         "48",
         "49",
         "3.6090514846121677",
         "0.9534987265413458",
         "0.19444444444444445",
         "0.03780864197530864",
         "0.5",
         "0.06330749354005169",
         "0.0002693183778319508",
         "0",
         "0.3386232904469992",
         "0"
        ],
        [
         "49",
         "50",
         "0.7571694805583016",
         "0.9548673864566919",
         "0.19444444444444445",
         "0.03780864197530864",
         "0.5",
         "0.06330749354005169",
         "0.00027031914214603603",
         "0",
         "0.22733565186875518",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.801380</td>\n",
       "      <td>0.954553</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.037809</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.833209</td>\n",
       "      <td>0.954917</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.037809</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>6.886341</td>\n",
       "      <td>0.954164</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.037809</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>3.609051</td>\n",
       "      <td>0.953499</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.037809</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.757169</td>\n",
       "      <td>0.954867</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.037809</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss   val_acc  val_prec  val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "45     46    0.801380  0.954553  0.194444  0.037809      0.5  0.063307              0.000209                0        0.202694                  0\n",
       "46     47    0.833209  0.954917  0.194444  0.037809      0.5  0.063307              0.000262                0        0.262473                  0\n",
       "47     48    6.886341  0.954164  0.194444  0.037809      0.5  0.063307              0.000405                0        0.508551                  0\n",
       "48     49    3.609051  0.953499  0.194444  0.037809      0.5  0.063307              0.000269                0        0.338623                  0\n",
       "49     50    0.757169  0.954867  0.194444  0.037809      0.5  0.063307              0.000270                0        0.227336                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP - Val Acc: 0.1944 | Val F1: 0.0633 | Val AUC: 0.5000\n",
      "Лучшая модель SimpleMLP:\n",
      "Лучшая модель SimpleMLP - Val Acc: 0.5985 | Val F1: 0.4482 | Val AUC: 0.5000\n",
      "Лучшая модель SimpleMLP - Val Acc: 0.5985 | Val F1: 0.4482 | Val AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "if DFC_CSV is not None:\n",
    "    mlp_model = SimpleMLP(in_dim=in_dim_dfc_nb, n_classes=N_CLASSES, cov_dim=cov_dim_dfc_nb).to(DEVICE)\n",
    "    # Создадим директорию для чекпоинтов\n",
    "    checkpoint_dir_path_mlp = f\"{CHECKPOINT_DIR}/SimpleMLP\"\n",
    "    os.makedirs(checkpoint_dir_path_mlp, exist_ok=True)\n",
    "    # Запустим обучение модели, если не нужно переиспользовать существующую\n",
    "    if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')):\n",
    "        history_mlp = train_model(\n",
    "            mlp_model, train_dl_dfc_nb, val_dl_dfc_nb, class_counts_main, DEVICE,\n",
    "            epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_mlp,\n",
    "            lr=LR, weight_decay=WEIGHT_DECAY, debug=False\n",
    "        )\n",
    "        hist_mlp_df = pd.DataFrame(history_mlp)\n",
    "        print('[HISTORY MLP] Последние строки:')\n",
    "        display(hist_mlp_df.tail())\n",
    "    else:\n",
    "        mlp_model.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')))\n",
    "        print(\"Загружен существующий чекпоинт SimpleMLP.\")\n",
    "    # Статистика обучения SimpleMLP\n",
    "    val_loss_mlp, val_acc_mlp, val_prec_mlp, val_auc_mlp, val_f1_mlp = Trainer(mlp_model, train_dl_dfc_nb, val_dl_dfc_nb, class_counts_main, DEVICE).evaluate()\n",
    "    print(f\"SimpleMLP - Val Acc: {val_acc_mlp:.4f} | Val F1: {val_f1_mlp:.4f} | Val AUC: {val_auc_mlp:.4f}\")\n",
    "    # Лучшая модель SimpleMLP:\n",
    "    print(\"Лучшая модель SimpleMLP:\")\n",
    "    if os.path.exists(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')):\n",
    "        mlp_model.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')))\n",
    "        mlp_model.eval()\n",
    "        val_loss_mlp, val_acc_mlp, val_prec_mlp, val_auc_mlp, val_f1_mlp = Trainer(mlp_model, val_dl_dfc_nb, val_dl_dfc_nb, class_counts_main, DEVICE).evaluate()\n",
    "        print(f\"Лучшая модель SimpleMLP - Val Acc: {val_acc_mlp:.4f} | Val F1: {val_f1_mlp:.4f} | Val AUC: {val_auc_mlp:.4f}\")\n",
    "else:\n",
    "    print(\"DFC_CSV отсутствует - невозмжно обучить модель.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c297aa",
   "metadata": {},
   "source": [
    "## 8) Оценка всех нейросетевых моделей на валидационном наборе\n",
    "\n",
    "Здесь мы оцениваем все обученные модели на валидационном наборе и выводим их метрики.\n",
    "Модели:\n",
    "- Simple LSTM\n",
    "- Simple GRU\n",
    "- Simple MLP\n",
    "- ROISequenceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2c449b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0, 1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3600x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сводная таблица финальных метрик:\n",
      "                       model   val_acc   val_auc    val_f1\n",
      "0         SimpleLSTM_sampler  0.414141  0.603018  0.430077\n",
      "1      SimpleLSTM_oversample  0.479798  0.569941  0.468213\n",
      "2          SimpleGRU_sampler  0.272727  0.460871  0.292268\n",
      "3     ROISequenceNet_sampler  0.414141  0.609034  0.432463\n",
      "4  ROISequenceNet_oversample  0.449495  0.477971  0.453038\n",
      "5   ROISequenceNet_nobalance  0.500000  0.498558  0.427223\n",
      "\n",
      "[INFO] Завершено: построение ROC (если было возможно), метрики, сохранение историй.\n"
     ]
    }
   ],
   "source": [
    "# === ROC Curves и сводные метрики (устойчиво к отсутствию oversample / других моделей) ===\n",
    "from sklearn.preprocessing import label_binarize\n",
    "try:\n",
    "    roc_curve\n",
    "except NameError:\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "try:\n",
    "    F\n",
    "except NameError:\n",
    "    import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_probs_and_labels(model, val_loader, device):\n",
    "    model.eval(); all_probs=[]; all_labels=[]\n",
    "    for batch in val_loader:\n",
    "        if len(batch)==5: X,M,C,y,_ = batch\n",
    "        elif len(batch)==4: X,M,C,y = batch\n",
    "        elif len(batch)==3: X,C,y = batch; M=None\n",
    "        else: raise ValueError(\"Unexpected batch format\")\n",
    "        X=X.to(device)\n",
    "        M = M.to(device) if M is not None else None\n",
    "        C = C.to(device) if (C is not None and C.nelement()>0) else None\n",
    "        # Унификация вызова\n",
    "        if M is None and C is None:\n",
    "            out = model(X)\n",
    "        else:\n",
    "            # поддержка аргумента z vs cov\n",
    "            try:\n",
    "                out = model(X, mask=M, cov=C)\n",
    "            except TypeError:\n",
    "                out = model(X, mask=M, z=C)\n",
    "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
    "        all_probs.append(probs); all_labels.extend(y.numpy())\n",
    "    if not all_probs:\n",
    "        return np.zeros((0, N_CLASSES)), np.zeros((0,), dtype=int)\n",
    "    return np.vstack(all_probs), np.array(all_labels)\n",
    "\n",
    "classes_sorted = sorted(class_counts_main.index.tolist())\n",
    "print('Classes:', classes_sorted)\n",
    "\n",
    "# --- Сбор вероятностей (только для существующих моделей) ---\n",
    "lstm_sampler_probs, lstm_sampler_labels = (None, None)\n",
    "if 'model_lstm_sampler' in globals() and model_lstm_sampler is not None and 'val_dl_sampler' in globals() and val_dl_sampler is not None:\n",
    "    lstm_sampler_probs, lstm_sampler_labels = collect_probs_and_labels(model_lstm_sampler, val_dl_sampler, DEVICE)\n",
    "\n",
    "lstm_over_probs, lstm_over_labels = (None, None)\n",
    "if 'model_lstm_over' in globals() and model_lstm_over is not None and 'val_dl_over' in globals() and val_dl_over is not None:\n",
    "    lstm_over_probs, lstm_over_labels = collect_probs_and_labels(model_lstm_over, val_dl_over, DEVICE)\n",
    "\n",
    "gru_sampler_probs, gru_sampler_labels = (None, None)\n",
    "if 'model_gru_sampler' in globals():\n",
    "    gru_sampler_probs, gru_sampler_labels = collect_probs_and_labels(model_gru_sampler, val_dl_sampler, DEVICE)\n",
    "\n",
    "roi_sampler_probs, roi_sampler_labels = (None, None)\n",
    "if 'model_roi_seq_net_sampler' in globals():\n",
    "    roi_sampler_probs, roi_sampler_labels = collect_probs_and_labels(model_roi_seq_net_sampler, val_dl_sampler, DEVICE)\n",
    "\n",
    "roi_over_probs, roi_over_labels = (None, None)\n",
    "if 'model_roi_seq_net_over' in globals() and model_roi_seq_net_over is not None and 'val_dl_over' in globals() and val_dl_over is not None:\n",
    "    roi_over_probs, roi_over_labels = collect_probs_and_labels(model_roi_seq_net_over, val_dl_over, DEVICE)\n",
    "\n",
    "roi_nb_probs, roi_nb_labels = (None, None)\n",
    "if 'model_roi_seq_net_nb' in globals():\n",
    "    roi_nb_probs, roi_nb_labels = collect_probs_and_labels(model_roi_seq_net_nb, val_dl, DEVICE)\n",
    "\n",
    "# --- Binarization helper (skip if probs is None) ---\n",
    "def binarize(labels):\n",
    "    if labels is None: return None\n",
    "    return label_binarize(labels, classes=classes_sorted)\n",
    "\n",
    "lstm_sampler_bin = binarize(lstm_sampler_labels)\n",
    "lstm_over_bin    = binarize(lstm_over_labels)\n",
    "gru_sampler_bin  = binarize(gru_sampler_labels)\n",
    "roi_sampler_bin  = binarize(roi_sampler_labels)\n",
    "roi_over_bin     = binarize(roi_over_labels)\n",
    "roi_nb_bin       = binarize(roi_nb_labels)\n",
    "\n",
    "# --- Подготовка списка для построения ROC ---\n",
    "plot_items = []\n",
    "if lstm_sampler_bin is not None:\n",
    "    plot_items.append(('SimpleLSTM (sampler)', lstm_sampler_bin, lstm_sampler_probs))\n",
    "if lstm_over_bin is not None:\n",
    "    plot_items.append(('SimpleLSTM (oversample)', lstm_over_bin, lstm_over_probs))\n",
    "if gru_sampler_bin is not None:\n",
    "    plot_items.append(('SimpleGRU (sampler)', gru_sampler_bin, gru_sampler_probs))\n",
    "if roi_sampler_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (sampler)', roi_sampler_bin, roi_sampler_probs))\n",
    "if roi_over_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (oversample)', roi_over_bin, roi_over_probs))\n",
    "if roi_nb_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (no balance)', roi_nb_bin, roi_nb_probs))\n",
    "\n",
    "if plot_items:\n",
    "    fig, axes = plt.subplots(1, len(plot_items), figsize=(6*len(plot_items), 5))\n",
    "    if len(plot_items) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (title, y_bin, probs) in zip(axes, plot_items):\n",
    "        for c_idx, c_lab in enumerate(classes_sorted):\n",
    "            try:\n",
    "                fpr, tpr, _ = roc_curve(y_bin[:, c_idx], probs[:, c_idx])\n",
    "                ax.plot(fpr, tpr, label=f'class {c_lab}')\n",
    "            except Exception:\n",
    "                pass\n",
    "        ax.set_title(f'{title} ROC')\n",
    "        ax.set_xlabel('FPR'); ax.set_ylabel('TPR'); ax.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"[INFO] Нет моделей для построения ROC.\")\n",
    "\n",
    "# --- Сводная таблица метрик ---\n",
    "summary_rows = []\n",
    "\n",
    "def add_summary(name, probs, labels):\n",
    "    if probs is None or labels is None:\n",
    "        return\n",
    "    try:\n",
    "        preds = probs.argmax(1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        try:\n",
    "            auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "        except Exception:\n",
    "            auc = float('nan')\n",
    "        f1 = f1_score(labels, preds, average='weighted')\n",
    "        summary_rows.append({'model': name, 'val_acc': acc, 'val_auc': auc, 'val_f1': f1})\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Summary failed for {name}: {e}\")\n",
    "\n",
    "add_summary('SimpleLSTM_sampler', lstm_sampler_probs, lstm_sampler_labels)\n",
    "add_summary('SimpleLSTM_oversample', lstm_over_probs, lstm_over_labels)\n",
    "add_summary('SimpleGRU_sampler', gru_sampler_probs, gru_sampler_labels)\n",
    "add_summary('ROISequenceNet_sampler', roi_sampler_probs, roi_sampler_labels)\n",
    "add_summary('ROISequenceNet_oversample', roi_over_probs, roi_over_labels)\n",
    "add_summary('ROISequenceNet_nobalance', roi_nb_probs, roi_nb_labels)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print('\\nСводная таблица финальных метрик:')\n",
    "print(summary_df if not summary_df.empty else '[EMPTY]')\n",
    "\n",
    "# --- Сохранение историй (проверка наличия) ---\n",
    "if 'hist_lstm_sampler_df' in globals():\n",
    "    hist_lstm_sampler_df.to_csv(os.path.join(checkpoint_dir_path_lstm, 'history_lstm_sampler.csv'), index=False)\n",
    "if 'hist_lstm_oversample_df' in globals() and hist_lstm_oversample_df is not None:\n",
    "    hist_lstm_oversample_df.to_csv(os.path.join(checkpoint_dir_path_lstm_over, 'history_lstm_oversample.csv'), index=False)\n",
    "if 'hist_gru_sampler_df' in globals():\n",
    "    hist_gru_sampler_df.to_csv(os.path.join(checkpoint_dir_path_gru_sampler, 'history_gru_sampler.csv'), index=False)\n",
    "if 'hist_roi_seq_sampler_df' in globals():\n",
    "    hist_roi_seq_sampler_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net_sampler, 'history_roi_seq_sampler.csv'), index=False)\n",
    "if 'hist_roi_seq_oversample_df' in globals():\n",
    "    hist_roi_seq_oversample_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'history_roi_seq_oversample.csv'), index=False)\n",
    "if 'hist_roi_seq_nobalance_df' in globals():\n",
    "    hist_roi_seq_nobalance_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'history_roi_seq_nobalance.csv'), index=False)\n",
    "print('\\n[INFO] Завершено: построение ROC (если было возможно), метрики, сохранение историй.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Baseline A — Статический функциональный коннектом (FC) + логистическая регрессия\n",
    "Идея: из каждого временного ряда NPY `(T,R)` считаем корреляционную матрицу `R×R` (Пирсон), применяем Z **Фишера** и векторизуем верхний треугольник. Т.о. получаем признак фиксированной длины. \n",
    "\n",
    "Затем обучаем **LogisticRegression (multinomial)**, опционально предваряя **PCA** до `FC_PCA_COMPONENTS`.\n",
    "\n",
    "Разбиение — то же групповое (без утечек)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3480b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train N=1438, val N=483; groups → train:7, val:2\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(len(data_df))\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=VAL_SIZE, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(idx, groups=data_df['site_x'].values))\n",
    "train_df, val_df = data_df.iloc[train_idx].reset_index(drop=True), data_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"train N={len(train_df)}, val N={len(val_df)}; groups → train:{train_df['site_x'].nunique()}, val:{val_df['site_x'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FC-LogReg] val_acc=0.472 | val_auc=0.484 | val_f1=0.276\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    def fisher_z(r):\n",
    "        r = np.clip(r, -0.999999, 0.999999)\n",
    "        return 0.5 * np.log((1+r)/(1-r))\n",
    "\n",
    "    def vec_uppertri(M):\n",
    "        iu = np.triu_indices_from(M, k=1)\n",
    "        return M[iu]\n",
    "\n",
    "    def fc_vector_from_npy(path):\n",
    "        X = np.load(path)  # (T,R)\n",
    "        C = np.corrcoef(X, rowvar=False)\n",
    "        # Replace NaNs arising from zero-variance ROI time series\n",
    "        C = np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        np.fill_diagonal(C, 1.0)\n",
    "        Cz = fisher_z(C)\n",
    "        return vec_uppertri(Cz)\n",
    "\n",
    "    def build_fc_matrix(df):\n",
    "        feats = [fc_vector_from_npy(p) for p in df['npy_path']]\n",
    "        X = np.vstack(feats)\n",
    "        # Safety: ensure no NaNs remain\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        y = df['label'].values.astype(int)\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = build_fc_matrix(train_df)\n",
    "    Xva, yva = build_fc_matrix(val_df)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xtr_s = scaler.fit_transform(Xtr)\n",
    "    Xva_s = scaler.transform(Xva)\n",
    "    # Extra safety before PCA\n",
    "    if np.isnan(Xtr_s).any() or np.isnan(Xva_s).any():\n",
    "        Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    if FC_PCA_COMPONENTS and FC_PCA_COMPONENTS > 0:\n",
    "        # PCA ограничение: n_components <= min(n_samples, n_features)\n",
    "        allowable = min(Xtr_s.shape[0], Xtr_s.shape[1])\n",
    "        n_comp = min(FC_PCA_COMPONENTS, allowable)\n",
    "        if n_comp < 1:\n",
    "            print(\"Пропуск PCA: недостаточно допустимых компонент.\")\n",
    "        else:\n",
    "            if n_comp != FC_PCA_COMPONENTS:\n",
    "                print(f\"Понижено число компонент PCA с {FC_PCA_COMPONENTS} до {n_comp} (min(n_samples={Xtr_s.shape[0]}, n_features={Xtr_s.shape[1]})).\")\n",
    "            pca = PCA(n_components=n_comp)\n",
    "            Xtr_s = pca.fit_transform(Xtr_s)\n",
    "            Xva_s = pca.transform(Xva_s)\n",
    "    clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    clf.fit(Xtr_s, ytr)\n",
    "    pr_tr = clf.predict_proba(Xtr_s); pr_va = clf.predict_proba(Xva_s)\n",
    "    yh_va = pr_va.argmax(1)\n",
    "    acc = accuracy_score(yva, yh_va)\n",
    "    f1  = f1_score(yva, yh_va, average='macro')\n",
    "    try:\n",
    "        auc = roc_auc_score(yva, pr_va, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    print(f\"[FC-LogReg] val_acc={acc:.3f} | val_auc={auc:.3f} | val_f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a593284",
   "metadata": {},
   "source": [
    "## 10) Baseline B — Динамический FC + HMM-фичи (или KMeans fallback)\n",
    "Идея: скользящим окном (`WIN_DYN`, шаг `STEP_DYN`) считаем FC по каждому окну → получаем последовательность векторов (\"кадров\") на субъекта. \n",
    "На **train** обучаем `GaussianHMM(n_states=HMM_N_STATES)` по этим кадрам. Для каждого субъекта считаем признаки:\n",
    "- доля времени в каждом состоянии,\n",
    "- частота переключений,\n",
    "- средняя длительность посещений.\n",
    "Если `hmmlearn` недоступен, используем **KMeans** как приближение скрытых состояний.\n",
    "Классификатор: `LogisticRegression` на агрегированных признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc55455",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def sliding_windows(X, win=30, step=5):\n",
    "    t, r = X.shape\n",
    "    for s in range(0, max(1, t - win + 1), step):\n",
    "        e = min(t, s + win)\n",
    "        if e - s >= max(5, win//2):\n",
    "            yield X[s:e]\n",
    "\n",
    "def fc_frames_from_npy(path, win=30, step=5):\n",
    "    X = np.load(path)\n",
    "    frames = []\n",
    "    for seg in sliding_windows(X, win, step):\n",
    "        C = np.corrcoef(seg, rowvar=False)\n",
    "        r = 0.5*np.log((1+np.clip(C, -0.999999, 0.999999))/(1-np.clip(C, -0.999999, 0.999999)))\n",
    "        iu = np.triu_indices_from(r, k=1)\n",
    "        frames.append(r[iu])\n",
    "    if not frames:\n",
    "        C = np.corrcoef(X, rowvar=False); iu = np.triu_indices_from(C, 1)\n",
    "        r = 0.5*np.log((1+np.clip(C, -0.999999, 0.999999))/(1-np.clip(C, -0.999999, 0.999999)))\n",
    "        frames = [r[iu]]\n",
    "    return np.vstack(frames)\n",
    "\n",
    "def summarize_states(states, n_states):\n",
    "    T = len(states)\n",
    "    if T == 0:\n",
    "        return np.zeros(n_states + 2)\n",
    "    frac = np.bincount(states, minlength=n_states) / max(1, T)\n",
    "    switches = (states[1:] != states[:-1]).mean() if T>1 else 0.0\n",
    "    lengths = []\n",
    "    cur = 1\n",
    "    for i in range(1, T):\n",
    "        if states[i]==states[i-1]: cur += 1\n",
    "        else: lengths.append(cur); cur = 1\n",
    "    lengths.append(cur)\n",
    "    dwell = float(np.mean(lengths))\n",
    "    return np.concatenate([frac, [switches, dwell]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a35de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DynFC] Removed 703 near-constant features before HMM/KMeans.\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    # HAS_HMM флаг (модуль уже импортирован выше, просто оставим структуру)\n",
    "    try:\n",
    "        HAS_HMM = True  # По-умолчанию используем Hidden Markov Model\n",
    "    except Exception:\n",
    "        HAS_HMM = False\n",
    "\n",
    "    # Получаем кадры динамического FC\n",
    "    tr_frames = [fc_frames_from_npy(p, WIN_DYN, STEP_DYN) for p in train_df['npy_path']]\n",
    "    va_frames = [fc_frames_from_npy(p, WIN_DYN, STEP_DYN) for p in val_df['npy_path']]\n",
    "\n",
    "    # Санитизация (NaN / inf -> 0) для устойчивости HMM / KMeans\n",
    "    def sanitize_frames(fr_list):\n",
    "        return [np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0) for f in fr_list]\n",
    "\n",
    "    tr_frames = sanitize_frames(tr_frames)\n",
    "    va_frames = sanitize_frames(va_frames)\n",
    "\n",
    "    # Объединяем обучающие кадры\n",
    "    Xtrain_seq = np.vstack(tr_frames)\n",
    "    Xtrain_seq = np.nan_to_num(Xtrain_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Удаляем/обрабатываем почти константные признаки (иначе ковариации нулевые -> ValueError)\n",
    "    var = Xtrain_seq.var(axis=0)\n",
    "    dyn_keep_cols = var > 1e-12\n",
    "    if dyn_keep_cols.sum() < Xtrain_seq.shape[1]:\n",
    "        removed = (~dyn_keep_cols).sum()\n",
    "        print(f\"[DynFC] Removed {removed} near-constant features before HMM/KMeans.\")\n",
    "        Xtrain_seq = Xtrain_seq[:, dyn_keep_cols]\n",
    "    else:\n",
    "        dyn_keep_cols = None  # ничего не удаляем\n",
    "\n",
    "    # Лёгкая стабилизация: добавим eps к абсолютно нулевым столбцам (если остались)\n",
    "    zero_var_cols = (Xtrain_seq.var(axis=0) <= 1e-12)\n",
    "    if zero_var_cols.any():\n",
    "        Xtrain_seq[:, zero_var_cols] += np.random.randn(Xtrain_seq.shape[0], zero_var_cols.sum()) * 1e-6\n",
    "        print(f\"[DynFC] Injected epsilon noise into {zero_var_cols.sum()} zero-variance columns.\")\n",
    "\n",
    "    n_states = int(HMM_N_STATES)\n",
    "\n",
    "    def _apply_keep(frames):\n",
    "        \"\"\"\n",
    "        Санитизация + приведение числа признаков к размеру dyn_keep_cols.\n",
    "        Исправление IndexError при несовпадении длины boolean mask и числа колонок:\n",
    "        - Если во входном кадре меньше признаков (из-за различного числа ROI после salvage),\n",
    "          дополняем нулями.\n",
    "        - Если больше — обрезаем.\n",
    "        После выравнивания применяем dyn_keep_cols.\n",
    "        \"\"\"\n",
    "        frames = np.nan_to_num(frames, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if dyn_keep_cols is not None:\n",
    "            target_len = dyn_keep_cols.shape[0]\n",
    "            cur_len = frames.shape[1]\n",
    "            if cur_len != target_len:\n",
    "                if cur_len < target_len:\n",
    "                    # pad zeros to the right\n",
    "                    pad = np.zeros((frames.shape[0], target_len - cur_len), dtype=frames.dtype)\n",
    "                    frames = np.hstack([frames, pad])\n",
    "                else:\n",
    "                    # truncate extra columns\n",
    "                    frames = frames[:, :target_len]\n",
    "            # now safe to index\n",
    "            frames = frames[:, dyn_keep_cols]\n",
    "        return frames\n",
    "\n",
    "    if HAS_HMM:\n",
    "        model_states = GaussianHMM(n_components=n_states, covariance_type='diag', n_iter=200, random_state=0)\n",
    "        try:\n",
    "            model_states.fit(Xtrain_seq)\n",
    "        except ValueError as e:\n",
    "            print(f\"[DynFC-HMM] HMM fit failed ({e}) -> fallback to KMeans.\")\n",
    "            HAS_HMM = False\n",
    "\n",
    "    if HAS_HMM:\n",
    "        def assign_states(frames):\n",
    "            frames = _apply_keep(frames)\n",
    "            return model_states.predict(frames)\n",
    "    else:\n",
    "        # Fallback: KMeans\n",
    "        kmeans = KMeans(n_clusters=n_states, random_state=0)\n",
    "        kmeans.fit(Xtrain_seq)\n",
    "\n",
    "        def assign_states(frames):\n",
    "            frames = _apply_keep(frames)\n",
    "            return kmeans.predict(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15995567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DynFC-HMM] val_acc=0.523 | val_auc=nan | val_f1=0.172 | HAS_HMM=False\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    def _apply_keep(frames):\n",
    "        \"\"\"\n",
    "        Санитизация + приведение числа признаков к размеру dyn_keep_cols.\n",
    "        Исправление IndexError при несовпадении длины boolean mask и числа колонок:\n",
    "        - Если во входном кадре меньше признаков (из-за различного числа ROI после salvage),\n",
    "          дополняем нулями.\n",
    "        - Если больше — обрезаем.\n",
    "        После выравнивания применяем dyn_keep_cols.\n",
    "        \"\"\"\n",
    "        frames = np.nan_to_num(frames, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if dyn_keep_cols is not None:\n",
    "            target_len = dyn_keep_cols.shape[0]\n",
    "            cur_len = frames.shape[1]\n",
    "            if cur_len != target_len:\n",
    "                if cur_len < target_len:\n",
    "                    # pad zeros to the right\n",
    "                    pad = np.zeros((frames.shape[0], target_len - cur_len), dtype=frames.dtype)\n",
    "                    frames = np.hstack([frames, pad])\n",
    "                else:\n",
    "                    # truncate extra columns\n",
    "                    frames = frames[:, :target_len]\n",
    "            # now safe to index\n",
    "            frames = frames[:, dyn_keep_cols]\n",
    "        return frames\n",
    "\n",
    "    def build_dyn_feats(frames_list):\n",
    "        feats = []\n",
    "        for fr in frames_list:\n",
    "            fr_san = _apply_keep(fr)\n",
    "            st = assign_states(fr_san)\n",
    "            feats.append(summarize_states(st, n_states))\n",
    "        return np.vstack(feats)\n",
    "\n",
    "    # Строим агрегированные признаки состояний\n",
    "    Xtr = build_dyn_feats(tr_frames)\n",
    "    ytr = train_df['label'].values.astype(int)\n",
    "    Xva = build_dyn_feats(va_frames)\n",
    "    yva = val_df['label'].values.astype(int)\n",
    "\n",
    "    # Финальная модель\n",
    "    clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    pr_va = clf.predict_proba(Xva)\n",
    "    yh_va = pr_va.argmax(1)\n",
    "    acc = accuracy_score(yva, yh_va)\n",
    "    f1 = f1_score(yva, yh_va, average='macro')\n",
    "    try:\n",
    "        auc = roc_auc_score(yva, pr_va, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    print(f\"[DynFC-HMM] val_acc={acc:.3f} | val_auc={auc:.3f} | val_f1={f1:.3f} | HAS_HMM={HAS_HMM}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae171d",
   "metadata": {},
   "source": [
    "## 11) Оценка переносимости: Leave-One-Site-Out (LOSO) для FC-baseline\n",
    "Для каждого сайта извлекаем его как **валидационную** выборку, обучаемся на остальных и считаем метрики. Это имитирует перенос на новый центр/сканер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee283ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_z(r):\n",
    "    r = np.clip(r, -0.999999, 0.999999)\n",
    "    return 0.5*np.log((1+r)/(1-r))\n",
    "\n",
    "def vec_uppertri(M):\n",
    "    iu = np.triu_indices_from(M, k=1)\n",
    "    return M[iu]\n",
    "\n",
    "def fc_vector_from_npy(path):\n",
    "    X = np.load(path)\n",
    "    C = np.corrcoef(X, rowvar=False)\n",
    "    Cz = fisher_z(C)\n",
    "    return vec_uppertri(Cz)\n",
    "\n",
    "def build_fc_matrix(df):\n",
    "    feats = [fc_vector_from_npy(p) for p in df['npy_path']]\n",
    "    X = np.vstack(feats)\n",
    "    y = df['label'].values.astype(int)\n",
    "    return X, y\n",
    "\n",
    "def pid2site(pid):\n",
    "    s = pid.replace('sub-','')\n",
    "    m = re.match(r'([a-z]+)', s)\n",
    "    return m.group(1) if m else 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45684fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOSO:kki] N=9 | acc=0.556 | auc=nan | f1=0.192\n",
      "[LOSO:neuroimage] N=56 | acc=0.554 | auc=0.684 | f1=0.317\n",
      "[LOSO:nyu] N=127 | acc=0.520 | auc=nan | f1=0.207\n",
      "[LOSO:peking] N=92 | acc=0.696 | auc=nan | f1=0.492\n",
      "[LOSO:pittsburgh] N=36 | acc=0.750 | auc=nan | f1=0.286\n",
      "[LOSO:washu] N=52 | acc=0.731 | auc=nan | f1=0.281\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "N_val",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "510686a6-13e5-45bd-8881-0be5d3619f72",
       "rows": [
        [
         "0",
         "kki",
         "9",
         "0.5555555555555556",
         null,
         "0.19230769230769232"
        ],
        [
         "1",
         "neuroimage",
         "56",
         "0.5535714285714286",
         "0.6838305461073318",
         "0.3174091966362498"
        ],
        [
         "2",
         "nyu",
         "127",
         "0.5196850393700787",
         null,
         "0.20690993788819878"
        ],
        [
         "3",
         "peking",
         "92",
         "0.6956521739130435",
         null,
         "0.4924924924924925"
        ],
        [
         "4",
         "pittsburgh",
         "36",
         "0.75",
         null,
         "0.2857142857142857"
        ],
        [
         "5",
         "washu",
         "52",
         "0.7307692307692307",
         null,
         "0.2814814814814815"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>N_val</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kki</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neuroimage</td>\n",
       "      <td>56</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.683831</td>\n",
       "      <td>0.317409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyu</td>\n",
       "      <td>127</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peking</td>\n",
       "      <td>92</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>36</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>washu</td>\n",
       "      <td>52</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         site  N_val       acc       auc        f1\n",
       "0         kki      9  0.555556       NaN  0.192308\n",
       "1  neuroimage     56  0.553571  0.683831  0.317409\n",
       "2         nyu    127  0.519685       NaN  0.206910\n",
       "3      peking     92  0.695652       NaN  0.492492\n",
       "4  pittsburgh     36  0.750000       NaN  0.285714\n",
       "5       washu     52  0.730769       NaN  0.281481"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние по сайтам: {'acc': 0.6342055713632229, 'auc': 0.6838305461073318, 'f1': 0.2960525144200667}\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES and DO_LOSO:\n",
    "    sites = sorted({pid2site(pid) for pid in data_df['participant_id']})\n",
    "    res = []\n",
    "    for site in sites:\n",
    "        tr_idx = data_df['participant_id'].map(pid2site) != site\n",
    "        va_idx = ~tr_idx\n",
    "        tr_df = data_df[tr_idx].reset_index(drop=True)\n",
    "        va_df = data_df[va_idx].reset_index(drop=True)\n",
    "        if len(va_df) < 5 or len(tr_df) < 10:\n",
    "            print(f\"[LOSO:{site}] слишком мало данных — пропуск\")\n",
    "            continue\n",
    "        # Формирование признаков (могут содержать NaN из-за нулевой дисперсии ROI)\n",
    "        Xtr, ytr = build_fc_matrix(tr_df)\n",
    "        Xva, yva = build_fc_matrix(va_df)\n",
    "        # Заменяем NaN / inf значениями 0 перед любыми трансформациями\n",
    "        Xtr = np.nan_to_num(Xtr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva = np.nan_to_num(Xva, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # Масштабирование\n",
    "        scaler = StandardScaler()\n",
    "        Xtr_s = scaler.fit_transform(Xtr)\n",
    "        Xva_s = scaler.transform(Xva)\n",
    "        # Повторная санитаризация (иногда стандартизация может породить inf при нулевом std)\n",
    "        Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # PCA (с проверкой допустимого числа компонент и отсутствия NaN)\n",
    "        if FC_PCA_COMPONENTS and FC_PCA_COMPONENTS > 0:\n",
    "            allowable = min(Xtr_s.shape[0], Xtr_s.shape[1])\n",
    "            n_comp = min(FC_PCA_COMPONENTS, allowable)\n",
    "            if n_comp < 1:\n",
    "                print(f\"[LOSO:{site}] Пропуск PCA (недостаточно компонент).\")\n",
    "            else:\n",
    "                if n_comp != FC_PCA_COMPONENTS:\n",
    "                    print(f\"[LOSO:{site}] PCA компонентов снижено до {n_comp} (allowable={allowable}).\")\n",
    "                # Санитизация перед PCA fit\n",
    "                Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                try:\n",
    "                    pca = PCA(n_components=n_comp)\n",
    "                    Xtr_s = pca.fit_transform(Xtr_s)\n",
    "                    Xva_s = pca.transform(Xva_s)\n",
    "                    # Финальная санитаризация\n",
    "                    Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                except ValueError as e:\n",
    "                    print(f\"[LOSO:{site}] Пропуск PCA из-за ошибки: {e}\")\n",
    "        # Обучение логистической регрессии\n",
    "        clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "        clf.fit(Xtr_s, ytr)\n",
    "        pr = clf.predict_proba(Xva_s); yh = pr.argmax(1)\n",
    "        acc = accuracy_score(yva, yh)\n",
    "        f1  = f1_score(yva, yh, average='macro')\n",
    "        try:\n",
    "            auc = roc_auc_score(yva, pr, multi_class='ovr', average='macro')\n",
    "        except Exception:\n",
    "            auc = float('nan')\n",
    "        res.append({\"site\": site, \"N_val\": len(va_df), \"acc\":acc, \"auc\":auc, \"f1\":f1})\n",
    "        print(f\"[LOSO:{site}] N={len(va_df)} | acc={acc:.3f} | auc={auc:.3f} | f1={f1:.3f}\")\n",
    "    if res:\n",
    "        df_res = pd.DataFrame(res)\n",
    "        display(df_res)\n",
    "        print(\"Средние по сайтам:\", df_res[['acc','auc','f1']].mean().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc59efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(87571) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlwt in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(87635) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Saved Excel to: /Users/alexey.stafeev/Documents/!Documents/Магистратура_МФТИ/Предметы/НИР/Материалы/ADHD200/Athena/methodology_ADHD200.xls\n",
      "Also CSV: /Users/alexey.stafeev/Documents/!Documents/Магистратура_МФТИ/Предметы/НИР/Материалы/ADHD200/Athena/methodology_ADHD200.csv\n"
     ]
    }
   ],
   "source": [
    "rows = [\n",
    "    [\"Отбор данных\",\"ADHD200; когорты 12–15 и 16–21; унификация ID; контроль утечки (splits по participant_id)\",\n",
    "     \"Фенотипы (CSV), фильтры по возрасту, групповые сплиты по participant_id\",\"Сделано\"],\n",
    "    [\"Подготовка сигналов\",\"ROI-тайм-серии Athena; окна фикс. длины T_FIX; mask паддинга; TR из BIDS\",\n",
    "     \".npy/.tsv.gz (T×R), *_mask.npy, *_bold.json\",\"Сделано\"],\n",
    "    [\"Базовые признаки\",\"Статическая FC из окна (Fisher-z верхний треугольник)\",\n",
    "     \"Внутренняя функция расчёта FC; baseline\",\"Сделано\"],\n",
    "    [\"Ковариаты\",\"Age / Gender / Site (предобработка и добавление в модель)\",\n",
    "     \"ColumnTransformer: StandardScaler + OneHotEncoder (fit на train)\",\"Сделано\"],\n",
    "    [\"Модели (последоват.)\",\"LSTM, GRU на (T, R) с поддержкой mask (зануление/pack)\",\n",
    "     \"PyTorch DataLoader (B, T, R)\",\"Сделано\"],\n",
    "    [\"Основная модель\",\"ROISequenceNet: Conv1d по времени per-ROI + Self-Attention по ROI + классификация\",\n",
    "     \"PyTorch; вход (T, R); mask учитывается\",\"Сделано\"],\n",
    "    [\"Бейзлайн (классика)\",\"LogisticRegression на статической FC\",\"scikit-learn\",\"Сделано\"],\n",
    "    [\"Валидация и метрики\",\"StratifiedGroupKFold / GroupShuffleSplit по participant_id; Accuracy/Precision/F1/AUC\",\n",
    "     \"sklearn.metrics; логирование результатов\",\"Сделано (нестабильность из-за объёма)\"],\n",
    "    [\"Гармонизация по сайту\",\"Коррекция межсайтовых сдвигов (ComBat)\",\"neuroComBat/аналог\",\"План\"],\n",
    "    [\"Motion-QC\",\"FD/DVARS как ковариаты/фильтр; скраббинг\",\"Конфаунды из fMRIPrep/Athena\",\"План\"],\n",
    "    [\"dFC-признаки\",\"Окна → FC-векторы → k-means состояния → occupancy/transition/dwell\",\n",
    "     \"DFC_CSV + MLP/ROISequenceNet\",\"План\"],\n",
    "    [\"Последовательность окон\",\"TCN/Transformer «по окнам» (моделирование переходов состояний)\",\n",
    "     \"PyTorch (вторая ось времени: окно→окно)\",\"План\"],\n",
    "    [\"Интерпретация\",\"Пермутационные важности, Integrated Gradients, карты внимания\",\n",
    "     \"Captum/собственные процедуры\",\"План\"],\n",
    "    [\"Воспроизводимость\",\"2 ноутбука: (1) подготовка/QC, (2) обучение/оценка; фиксация seed/версий\",\n",
    "     \"Версионирование манифеста/парцелляций/конфигов\",\"Сделано\"],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"Этап\",\"Метод / данные\",\"Инструменты и артефакты\",\"Статус\"])\n",
    "\n",
    "out_xls  = Path(\"methodology_ADHD200.xls\")\n",
    "out_xlsx = Path(\"methodology_ADHD200.xlsx\")\n",
    "out_csv  = Path(\"methodology_ADHD200.csv\")\n",
    "\n",
    "# Удаляем старые файлы, если есть\n",
    "for f in [out_xls, out_xlsx, out_csv]:\n",
    "    if f.exists():\n",
    "        f.unlink()\n",
    "\n",
    "saved = None\n",
    "try:\n",
    "    df.to_excel(out_xls, index=False)      # требует пакет xlwt для .xls\n",
    "    saved = out_xls\n",
    "except Exception:\n",
    "    df.to_excel(out_xlsx, index=False)     # универсальный .xlsx (требует openpyxl)\n",
    "    saved = out_xlsx\n",
    "\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Saved Excel to:\", saved.resolve())\n",
    "print(\"Also CSV:\", out_csv.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
