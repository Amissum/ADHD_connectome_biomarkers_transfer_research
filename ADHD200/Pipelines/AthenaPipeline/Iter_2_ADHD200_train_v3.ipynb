{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADHD200 — Обучение (Multiclass) на подготовленных таймсериях - Iter 2\n",
    "\n",
    "Этот ноутбук реализует три ступени:\n",
    "1) **Базлайны без нейросетей**:\n",
    "   - **Статический FC** (корреляции ROI×ROI) → Logistic Regression (+PCA по желанию);\n",
    "   - **Динамический FC + HMM** (или KMeans), признаки: доли состояний, переключаемость, длительность.\n",
    "   - **Переносимость**: Leave-One-Site-Out для статического FC.\n",
    "2) **Нейросети**: LSTM/GRU/TCN+BiGRU+Self-Attn с ковариатами (возраст/пол), веса классов, метрики `acc/auc/f1`.\n",
    "3) **Строгая валидация**: групповой сплит по участнику/сайту для предотвращения утечек.\n",
    "\n",
    "В данном ноутбуке используется подготовленный набор данных из ноутбука [ADHD200_prep.ipynb](ADHD200_prep.ipynb). Для обучения нейросети используются файлы `.npy` с таймсериями. Обучение ведётся только на данных подростков из соответствующего отфильтрованного манифеста `manifest.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dce36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(45668) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(45690) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: hmmlearn in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.7.2)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from hmmlearn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install hmmlearn\n",
    "\n",
    "import re, os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Увеличим ширину печати для pandas\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Отключим предупреждения для чистоты логирования\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f98cd4",
   "metadata": {},
   "source": [
    "## Конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение моделей будет произведено на cpu\n",
      "EarlyStopping: metric=val_loss, patience=15\n",
      "Sanitize=True, GradClip=5.0, ReinitOnNaN=True, StagnationReset=3\n",
      "Salvage: Impute=roi_mean, SampleMaxNanFrac=0.98, RowMinFiniteFrac=0.3, ROI_drop<0.2, Interp=True\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = './Athena_prepared_filtered/cohort_teen_participants'\n",
    "MANIFEST_CSV = f'{DATA_ROOT}/manifest_windows.csv'\n",
    "DFC_CSV      = f'{DATA_ROOT}/dfc_features.csv'   # если генерировались dFC-признаки\n",
    "\n",
    "PHENO_CSV = \"../SortedRawDataBIDS/cohort_teen_participants/participants.tsv\"    # participant_id + метка (0..N_CLASSES-1) + Age + sex + site\n",
    "DATA_MODE = 'SEQ_NPY'  # 'SEQ_NPY' | 'SEQ_TSV' | 'DFC'\n",
    "\n",
    "CHECKPOINT_DIR = str(Path(DATA_ROOT)/'iter_2_checkpoints')\n",
    "\n",
    "REUSE_MODELS = False\n",
    "N_CLASSES = 4                         # число классов для классификации (0 - TD, 1 - ADHD-C, 2 - ADHD-HI, 3 - ADHD-I)\n",
    "EPOCHS = 50\n",
    "BATCH_TRAIN = 32\n",
    "BATCH_VAL = 64\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# === Early Stopping ===\n",
    "EARLY_STOP_PATIENCE = 15\n",
    "EARLY_STOP_METRIC   = 'val_loss'\n",
    "MIN_DELTA_IMPROVE   = 1e-4\n",
    "\n",
    "# === Санитизация и стабильность ===\n",
    "SANITIZE_INPUTS = True\n",
    "ADD_EPS_NOISE_IF_ALL_ZERO = True\n",
    "MAX_GRAD_NORM = 5.0\n",
    "REINIT_ON_NAN = True\n",
    "STAGNATION_RESET_EPOCHS = 3\n",
    "HEAD_REINIT = True\n",
    "\n",
    "# === NaN / Imputation handling (salvage) ===\n",
    "IMPUTE_STRATEGY = 'roi_mean'          # 'roi_mean' | 'global_zero'\n",
    "SAMPLE_MAX_NAN_FRAC = 0.98            # итоговый порог после salvage\n",
    "ROW_MIN_FINITE_FRAC = 0.3             # ослаблен: строка валидна если >=30% конечных\n",
    "DROP_HIGH_NAN = True                  # удалять примеры только если нан_frac==1.0 (полностью испорчены)\n",
    "LOG_NAN_STATS = True\n",
    "ROI_DROP_THRESHOLD = 0.2              # удалить ROI (столбец), если доля конечных значений <20% в примере\n",
    "INTERPOLATE_NAN = True                # линейная интерполяция по времени до mean-импутации\n",
    "\n",
    "# === Балансировка классов ===\n",
    "ENABLE_AUTOBALANCE = True\n",
    "BALANCE_STRATEGY = 'sampler'          \n",
    "CLASS_WEIGHT_MODE = 'inv_freq'\n",
    "MAX_CLASS_WEIGHT_RATIO = 10.0         # ограничение максимального веса класса\n",
    "\n",
    "LABEL_COLUMN_CANDIDATES = ['label','Label','DX','dx','Diagnosis','diagnosis']\n",
    "BINARY_MAP = {0:0, 1:1, 2:2, 3:3, 'ADHD-Combined':1, 'ADHD-Hyperactive/Impulsive':2, 'ADHD-Inattentive':3, 'TD':0, 'HC':0, 'Control':0}\n",
    "MULTICLASS = True\n",
    "\n",
    "USE_COVARIATES = False\n",
    "COV_CONT = ['age']\n",
    "COV_CAT  = ['sex','site']\n",
    "\n",
    "RUN_BASELINES = True\n",
    "FC_PCA_COMPONENTS = 200\n",
    "HMM_N_STATES = 5\n",
    "WIN_DYN = 30\n",
    "STEP_DYN = 5\n",
    "DO_LOSO = True\n",
    "VAL_SIZE = 0.2                        # доля валидационного сета при GroupShuffleSplit - 20%\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Обучение моделей будет произведено на {DEVICE}\")\n",
    "print(f\"EarlyStopping: metric={EARLY_STOP_METRIC}, patience={EARLY_STOP_PATIENCE}\")\n",
    "print(f\"Sanitize={SANITIZE_INPUTS}, GradClip={MAX_GRAD_NORM}, ReinitOnNaN={REINIT_ON_NAN}, StagnationReset={STAGNATION_RESET_EPOCHS}\")\n",
    "print(f\"Salvage: Impute={IMPUTE_STRATEGY}, SampleMaxNanFrac={SAMPLE_MAX_NAN_FRAC}, RowMinFiniteFrac={ROW_MIN_FINITE_FRAC}, ROI_drop<{ROI_DROP_THRESHOLD}, Interp={INTERPOLATE_NAN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Загрузка манифеста и фенотипов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((660, 14), (274, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man = pd.read_csv(MANIFEST_CSV)\n",
    "ph  = pd.read_csv(PHENO_CSV, delimiter='\\t') # для .tsv\n",
    "\n",
    "if 'participant_id' not in ph.columns:\n",
    "    for c in ph.columns:\n",
    "        if c.lower() in ('participant_id','subject','sub','id'):\n",
    "            ph = ph.rename(columns={c:'participant_id'})\n",
    "            break\n",
    "\n",
    "label_col = next((c for c in LABEL_COLUMN_CANDIDATES if c in ph.columns), None)\n",
    "assert label_col is not None, f'Нет метки среди: {LABEL_COLUMN_CANDIDATES}'\n",
    "\n",
    "ph = ph[['participant_id', label_col] + [c for c in COV_CONT+COV_CAT if c in ph.columns]].copy()\n",
    "ph.rename(columns={label_col:'label'}, inplace=True)\n",
    "if not MULTICLASS:\n",
    "    ph['label'] = ph['label'].map(BINARY_MAP)\n",
    "\n",
    "man.shape, ph.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e8fa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "npy_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tsv_path",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atlas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nan_ratio_run",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "32b1eac1-1912-46b5-8a09-85a2af2451b4",
       "rows": [
        [
         "0",
         "sub-kki1018959",
         "1018959",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1018959/sub-kki1018959_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1018959/sub-kki1018959_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0"
        ],
        [
         "1",
         "sub-kki1019436",
         "1019436",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1019436/sub-kki1019436_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1019436/sub-kki1019436_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0"
        ],
        [
         "2",
         "sub-kki1594156",
         "1594156",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1594156/sub-kki1594156_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1594156/sub-kki1594156_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0"
        ],
        [
         "3",
         "sub-kki1623716",
         "1623716",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1623716/sub-kki1623716_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1623716/sub-kki1623716_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0"
        ],
        [
         "4",
         "sub-kki2026113",
         "2026113",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki2026113/sub-kki2026113_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki2026113/sub-kki2026113_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>tsv_path</th>\n",
       "      <th>atlas</th>\n",
       "      <th>TR</th>\n",
       "      <th>nan_ratio_run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-kki1018959</td>\n",
       "      <td>1018959</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-kki1019436</td>\n",
       "      <td>1019436</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-kki1594156</td>\n",
       "      <td>1594156</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-kki1623716</td>\n",
       "      <td>1623716</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-kki2026113</td>\n",
       "      <td>2026113</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  pid_raw site site_original      run_id  win_index  segment_start  segment_end                                           npy_path                                          mask_path  tsv_path  atlas  TR  nan_ratio_run\n",
       "0  sub-kki1018959  1018959  kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0\n",
       "1  sub-kki1019436  1019436  kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0\n",
       "2  sub-kki1594156  1594156  kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0\n",
       "3  sub-kki1623716  1623716  kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0\n",
       "4  sub-kki2026113  2026113  kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e2fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c13edc20-f80a-4ad7-adf7-44d7ce2e52df",
       "rows": [
        [
         "0",
         "sub-kki2026113",
         "1",
         "12.99",
         "F",
         "KKI"
        ],
        [
         "1",
         "sub-kki1623716",
         "1",
         "12.65",
         "F",
         "KKI"
        ],
        [
         "2",
         "sub-kki1594156",
         "0",
         "12.87",
         "M",
         "KKI"
        ],
        [
         "3",
         "sub-kki2917777",
         "0",
         "12.66",
         "M",
         "KKI"
        ],
        [
         "4",
         "sub-kki1018959",
         "0",
         "12.36",
         "F",
         "KKI"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-kki2026113</td>\n",
       "      <td>1</td>\n",
       "      <td>12.99</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-kki1623716</td>\n",
       "      <td>1</td>\n",
       "      <td>12.65</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-kki1594156</td>\n",
       "      <td>0</td>\n",
       "      <td>12.87</td>\n",
       "      <td>M</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-kki2917777</td>\n",
       "      <td>0</td>\n",
       "      <td>12.66</td>\n",
       "      <td>M</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-kki1018959</td>\n",
       "      <td>0</td>\n",
       "      <td>12.36</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  label    age sex site\n",
       "0  sub-kki2026113      1  12.99   F  KKI\n",
       "1  sub-kki1623716      1  12.65   F  KKI\n",
       "2  sub-kki1594156      0  12.87   M  KKI\n",
       "3  sub-kki2917777      0  12.66   M  KKI\n",
       "4  sub-kki1018959      0  12.36   F  KKI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Таблица примеров под режим\n",
    "\n",
    "Эта функция строит DataFrame с примерами для заданного режима работы модели (например, `SEQ_NPY` для таймсерий в формате `.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "participant_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pid_raw",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site_x",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_original",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "win_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "segment_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "npy_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tsv_path",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "atlas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nan_ratio_run",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "data_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_y",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7296b8dc-92c9-4d27-94b7-39ceb46fd1e8",
       "rows": [
        [
         "0",
         "sub-kki1018959",
         "1018959",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1018959/sub-kki1018959_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1018959/sub-kki1018959_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1018959/sub-kki1018959_ses1_rest1_w0_CC400.npy",
         "0",
         "12.36",
         "F",
         "KKI"
        ],
        [
         "1",
         "sub-kki1019436",
         "1019436",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1019436/sub-kki1019436_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1019436/sub-kki1019436_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1019436/sub-kki1019436_ses1_rest1_w0_CC400.npy",
         "3",
         "12.98",
         "M",
         "KKI"
        ],
        [
         "2",
         "sub-kki1594156",
         "1594156",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1594156/sub-kki1594156_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1594156/sub-kki1594156_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1594156/sub-kki1594156_ses1_rest1_w0_CC400.npy",
         "0",
         "12.87",
         "M",
         "KKI"
        ],
        [
         "3",
         "sub-kki1623716",
         "1623716",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1623716/sub-kki1623716_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1623716/sub-kki1623716_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki1623716/sub-kki1623716_ses1_rest1_w0_CC400.npy",
         "1",
         "12.65",
         "F",
         "KKI"
        ],
        [
         "4",
         "sub-kki2026113",
         "2026113",
         "kki",
         "KKI",
         "ses1_rest1",
         "0",
         "0",
         "200",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki2026113/sub-kki2026113_ses1_rest1_w0_CC400.npy",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki2026113/sub-kki2026113_ses1_rest1_w0_CC400_mask.npy",
         null,
         "CC400",
         null,
         "0.0",
         "Athena_prepared_filtered/cohort_teen_participants/sub-kki2026113/sub-kki2026113_ses1_rest1_w0_CC400.npy",
         "1",
         "12.99",
         "F",
         "KKI"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>pid_raw</th>\n",
       "      <th>site_x</th>\n",
       "      <th>site_original</th>\n",
       "      <th>run_id</th>\n",
       "      <th>win_index</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>tsv_path</th>\n",
       "      <th>atlas</th>\n",
       "      <th>TR</th>\n",
       "      <th>nan_ratio_run</th>\n",
       "      <th>data_path</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>site_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-kki1018959</td>\n",
       "      <td>1018959</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.36</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-kki1019436</td>\n",
       "      <td>1019436</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>3</td>\n",
       "      <td>12.98</td>\n",
       "      <td>M</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-kki1594156</td>\n",
       "      <td>1594156</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.87</td>\n",
       "      <td>M</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-kki1623716</td>\n",
       "      <td>1623716</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.65</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-kki2026113</td>\n",
       "      <td>2026113</td>\n",
       "      <td>kki</td>\n",
       "      <td>KKI</td>\n",
       "      <td>ses1_rest1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Athena_prepared_filtered/cohort_teen_participa...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.99</td>\n",
       "      <td>F</td>\n",
       "      <td>KKI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  pid_raw site_x site_original      run_id  win_index  segment_start  segment_end                                           npy_path                                          mask_path  tsv_path  atlas  TR  nan_ratio_run                                          data_path  label    age sex site_y\n",
       "0  sub-kki1018959  1018959    kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0  Athena_prepared_filtered/cohort_teen_participa...      0  12.36   F    KKI\n",
       "1  sub-kki1019436  1019436    kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0  Athena_prepared_filtered/cohort_teen_participa...      3  12.98   M    KKI\n",
       "2  sub-kki1594156  1594156    kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0  Athena_prepared_filtered/cohort_teen_participa...      0  12.87   M    KKI\n",
       "3  sub-kki1623716  1623716    kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0  Athena_prepared_filtered/cohort_teen_participa...      1  12.65   F    KKI\n",
       "4  sub-kki2026113  2026113    kki           KKI  ses1_rest1          0              0          200  Athena_prepared_filtered/cohort_teen_participa...  Athena_prepared_filtered/cohort_teen_participa...       NaN  CC400 NaN            0.0  Athena_prepared_filtered/cohort_teen_participa...      1  12.99   F    KKI"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_table_for_mode(manifest, phenotypes, mode):\n",
    "    df = manifest.copy()\n",
    "    if mode=='SEQ_NPY':\n",
    "        df = df[df['npy_path'].notna() & df['npy_path'].astype(str).str.len()>0]\n",
    "        df['data_path'] = df['npy_path']\n",
    "    elif mode=='SEQ_TSV':\n",
    "        if 'tsv_path' not in df.columns: raise ValueError(\"Нет 'tsv_path' в манифесте\")\n",
    "        df = df[df['tsv_path'].notna() & df['tsv_path'].astype(str).str.len()>0]\n",
    "        df['data_path'] = df['tsv_path']\n",
    "    elif mode=='DFC':\n",
    "        dfc = pd.read_csv(DFC_CSV)\n",
    "        agg = (manifest.groupby('participant_id').agg({'site':'first','atlas':'first','TR':'median'}).reset_index())\n",
    "        df = dfc.merge(agg, on='participant_id', how='left')\n",
    "    else:\n",
    "        raise ValueError('Unknown mode')\n",
    "    df = df.merge(phenotypes, on='participant_id', how='inner')\n",
    "    df = df[df['label'].notna()].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "data_df = build_table_for_mode(man, ph, DATA_MODE)\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c088bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Salvage] Raw nan_frac describe:\n",
      "count    372.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: nan_frac_raw, dtype: float64\n",
      "[Salvage] ROI drop count describe:\n",
      "count    372.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: roi_drop_cnt, dtype: float64\n",
      "[Salvage] Dropped 0 fully NaN samples\n",
      "[Salvage] nan_frac histogram (bins 0..1 step 0.1): [372   0   0   0   0   0   0   0   0   0]\n",
      "Размер после salvage: (372, 21)\n"
     ]
    }
   ],
   "source": [
    "# === Salvage & Filtering pass (replaces previous hard drop logic) ===\n",
    "if DATA_MODE in ('SEQ_NPY','SEQ_TSV'):\n",
    "    nan_fracs = []\n",
    "    roi_drop_counts = []\n",
    "    sample_paths = data_df['data_path'].tolist()\n",
    "    for p in sample_paths:\n",
    "        try:\n",
    "            arr = np.load(p) if DATA_MODE=='SEQ_NPY' else pd.read_csv(p, sep='\\t', header=None, compression='gzip').values\n",
    "            fin = np.isfinite(arr)\n",
    "            nan_frac = 1.0 - fin.mean()\n",
    "            # ROI salvage: drop columns (ROIs) with too few finite values\n",
    "            col_finite_ratio = fin.mean(axis=0)\n",
    "            bad_cols = np.where(col_finite_ratio < ROI_DROP_THRESHOLD)[0]\n",
    "            roi_drop_counts.append(len(bad_cols))\n",
    "            if len(bad_cols)>0 and len(bad_cols) < arr.shape[1]:\n",
    "                arr = np.delete(arr, bad_cols, axis=1)\n",
    "            # recompute nan_frac after column drop\n",
    "            fin2 = np.isfinite(arr)\n",
    "            nan_frac = 1.0 - fin2.mean()\n",
    "        except Exception:\n",
    "            nan_frac = 1.0\n",
    "            roi_drop_counts.append(np.nan)\n",
    "        nan_fracs.append(nan_frac)\n",
    "    data_df['nan_frac_raw'] = nan_fracs\n",
    "    data_df['roi_drop_cnt'] = roi_drop_counts\n",
    "    if LOG_NAN_STATS:\n",
    "        print('[Salvage] Raw nan_frac describe:')\n",
    "        print(data_df['nan_frac_raw'].describe())\n",
    "        print('[Salvage] ROI drop count describe:')\n",
    "        print(data_df['roi_drop_cnt'].describe())\n",
    "    # Drop only fully corrupted samples (nan_frac_raw == 1.0)\n",
    "    if DROP_HIGH_NAN:\n",
    "        before = len(data_df)\n",
    "        data_df = data_df[data_df['nan_frac_raw'] < 1.0].reset_index(drop=True)\n",
    "        print(f\"[Salvage] Dropped {before - len(data_df)} fully NaN samples\")\n",
    "    # Recompute simple histogram\n",
    "    if LOG_NAN_STATS:\n",
    "        import numpy as np\n",
    "        hist_vals = data_df['nan_frac_raw'].values\n",
    "        bins = np.linspace(0,1,11)\n",
    "        hist, _ = np.histogram(hist_vals, bins=bins)\n",
    "        print('[Salvage] nan_frac histogram (bins 0..1 step 0.1):', hist)\n",
    "else:\n",
    "    print('[Salvage] Skipped (DFC mode)')\n",
    "print('Размер после salvage:', data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2128fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NaN] Summary before filtering:\n",
      "count    372.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: nan_frac, dtype: float64\n",
      "[NaN] Count > SAMPLE_MAX_NAN_FRAC: 0\n",
      "[NaN] Dropped 0 / 372 samples (>98.0% NaN)\n",
      "Размер после NaN фильтрации: (372, 22)\n",
      "Top nan_frac head:\n",
      "                                           data_path  nan_frac\n",
      "0  Athena_prepared_filtered/cohort_teen_participa...       0.0\n",
      "1  Athena_prepared_filtered/cohort_teen_participa...       0.0\n",
      "2  Athena_prepared_filtered/cohort_teen_participa...       0.0\n",
      "3  Athena_prepared_filtered/cohort_teen_participa...       0.0\n",
      "4  Athena_prepared_filtered/cohort_teen_participa...       0.0\n"
     ]
    }
   ],
   "source": [
    "# === Фильтрация примеров по доле NaN до сплитов ===\n",
    "if DATA_MODE in ('SEQ_NPY','SEQ_TSV'):\n",
    "    nan_fracs = []\n",
    "    for p in data_df['data_path']:\n",
    "        try:\n",
    "            arr = np.load(p) if DATA_MODE=='SEQ_NPY' else pd.read_csv(p, sep='\\t', header=None, compression='gzip').values\n",
    "            total = arr.size\n",
    "            nan_count = np.isnan(arr).sum()\n",
    "            nan_frac = nan_count / total\n",
    "        except Exception as e:\n",
    "            nan_frac = 1.0\n",
    "        nan_fracs.append(nan_frac)\n",
    "    data_df['nan_frac'] = nan_fracs\n",
    "    if LOG_NAN_STATS:\n",
    "        print('[NaN] Summary before filtering:')\n",
    "        print(data_df['nan_frac'].describe())\n",
    "        print('[NaN] Count > SAMPLE_MAX_NAN_FRAC:', (data_df['nan_frac']>SAMPLE_MAX_NAN_FRAC).sum())\n",
    "    if DROP_HIGH_NAN:\n",
    "        kept_df = data_df[data_df['nan_frac']<=SAMPLE_MAX_NAN_FRAC].reset_index(drop=True)\n",
    "        dropped = len(data_df)-len(kept_df)\n",
    "        print(f\"[NaN] Dropped {dropped} / {len(data_df)} samples (>{SAMPLE_MAX_NAN_FRAC*100:.1f}% NaN)\")\n",
    "        data_df = kept_df\n",
    "else:\n",
    "    print('[NaN] Skipped filtering (DFC mode)')\n",
    "\n",
    "print('Размер после NaN фильтрации:', data_df.shape)\n",
    "print('Top nan_frac head:')\n",
    "print(data_df[['data_path','nan_frac']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6869323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athena_prepared_filtered/cohort_teen_participants/sub-nyu0010002/sub-nyu0010002_ses1_rest1_w0_CC400.npy nan% 0.0 std_mean 0.9247843\n"
     ]
    }
   ],
   "source": [
    "paths = data_df['data_path'].head(10).tolist()\n",
    "for p in paths:\n",
    "    x = np.load(p)\n",
    "print(p, 'nan%', np.isnan(x).mean()*100, 'std_mean', x.std(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Сплиты без утечки и ковариаты\n",
    "\n",
    "Эта функция создаёт сплиты по участникам/сайтам, чтобы избежать утечек между обучением и валидацией. Также она извлекает ковариаты (возраст, пол) для использования в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для текущего разбиения: длина 5\n",
      "Ковариаты не используются.\n"
     ]
    }
   ],
   "source": [
    "groups = data_df['participant_id'].astype(str).values\n",
    "y = data_df['label'].values\n",
    "if len(np.unique(y))>1:\n",
    "    splitter = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "else:\n",
    "    splitter = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=SEED)\n",
    "folds = list(splitter.split(X=np.zeros_like(y), y=y, groups=groups))\n",
    "\n",
    "cov_cols_cont = [c for c in COV_CONT if c in data_df.columns]\n",
    "cov_cols_cat  = [c for c in COV_CAT  if c in data_df.columns]\n",
    "if USE_COVARIATES and (cov_cols_cont or cov_cols_cat):\n",
    "    pre = ColumnTransformer([\n",
    "        ('cont', StandardScaler(), cov_cols_cont),\n",
    "        ('cat',  OneHotEncoder(handle_unknown='ignore'), cov_cols_cat)\n",
    "    ])\n",
    "else:\n",
    "    pre = None\n",
    "\n",
    "# Выведем информацию о разбиении и ковариатах\n",
    "print(f\"Для текущего разбиения: длина {len(folds)}\")\n",
    "if USE_COVARIATES:\n",
    "    print(f\"Числовые ковариаты - {cov_cols_cont}, категориальные ковариаты - {cov_cols_cat}\")\n",
    "else:\n",
    "    print(\"Ковариаты не используются.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Датасеты и DataLoader’ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, mode, cov_pre=None):\n",
    "        assert mode in ('SEQ_NPY','SEQ_TSV')\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.cov_pre = cov_pre\n",
    "        if cov_pre is not None:\n",
    "            cov_input = self.df[[c for c in (cov_cols_cont+cov_cols_cat) if c in self.df.columns]].copy()\n",
    "            self.cov = cov_pre.transform(cov_input)\n",
    "            self.cov = np.asarray(self.cov, dtype=np.float32)\n",
    "        else:\n",
    "            self.cov = None\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        if self.mode=='SEQ_NPY':\n",
    "            x = np.load(r['data_path']).astype('float32')\n",
    "        else:\n",
    "            x = pd.read_csv(r['data_path'], sep='\\t', header=None, compression='gzip').values.astype('float32')\n",
    "        # NaN stats per sample for debug (not persisted each call to avoid slowdown)\n",
    "        finite_mask = np.isfinite(x)\n",
    "        # Build time mask: row valid if fraction finite >= ROW_MIN_FINITE_FRAC\n",
    "        row_valid = (finite_mask.sum(axis=1) / finite_mask.shape[1]) >= ROW_MIN_FINITE_FRAC\n",
    "        # Impute NaNs\n",
    "        if IMPUTE_STRATEGY == 'roi_mean':\n",
    "            # Compute ROI means over valid rows (avoid NaNs)\n",
    "            roi_means = np.where(np.isfinite(x[row_valid]).sum(axis=0)>0, np.nanmean(x[row_valid], axis=0), 0.0)\n",
    "            # Replace NaNs with corresponding roi mean\n",
    "            nan_positions = ~finite_mask\n",
    "            x[nan_positions] = np.take(roi_means, np.where(nan_positions)[1])\n",
    "        else:  # global_zero\n",
    "            x[~finite_mask] = 0.0\n",
    "        if ADD_EPS_NOISE_IF_ALL_ZERO and not np.any(x):\n",
    "            x += (np.random.randn(*x.shape).astype('float32')) * 1e-3\n",
    "        # Final sanitize\n",
    "        x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        m = row_valid.astype('float32')  # mask of valid timepoints\n",
    "        # If external mask exists, AND it\n",
    "        mpath = r.get('mask_path', None)\n",
    "        if isinstance(mpath, str) and len(mpath)>0 and Path(mpath).exists():\n",
    "            ext_m = np.load(mpath).astype('float32')\n",
    "            if ext_m.shape[0] == m.shape[0]:\n",
    "                m = m * ext_m\n",
    "        if self.cov is not None:\n",
    "            cov_t = torch.from_numpy(self.cov[i])\n",
    "        else:\n",
    "            cov_t = torch.empty(0)\n",
    "        y = int(r['label'])\n",
    "        pid = str(r['participant_id'])\n",
    "        return torch.from_numpy(x), torch.from_numpy(m), cov_t, torch.tensor(y), pid\n",
    "\n",
    "class DFCDataset(Dataset):\n",
    "    def __init__(self, df, cov_pre=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cov_pre = cov_pre\n",
    "        drop_cols = {'participant_id','site','atlas','TR','label'}\n",
    "        self.feat_cols = [c for c in self.df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(self.df[c])]\n",
    "        if cov_pre is not None:\n",
    "            cov_input = self.df[[c for c in (cov_cols_cont+cov_cols_cat) if c in self.df.columns]].copy()\n",
    "            self.cov = cov_pre.transform(cov_input)\n",
    "            self.cov = np.asarray(self.cov, dtype=np.float32)\n",
    "        else:\n",
    "            self.cov = None\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        x = self.df.loc[i, self.feat_cols].values.astype('float32')\n",
    "        if IMPUTE_STRATEGY == 'roi_mean':  # treat each feature individually\n",
    "            if not np.isfinite(x).all():\n",
    "                bad = ~np.isfinite(x)\n",
    "                x[bad] = 0.0  # cannot compute per-feature mean without temporal axis\n",
    "        else:\n",
    "            x[~np.isfinite(x)] = 0.0\n",
    "        if ADD_EPS_NOISE_IF_ALL_ZERO and not np.any(x):\n",
    "            x += (np.random.randn(*x.shape).astype('float32')) * 1e-3\n",
    "        if self.cov is not None:\n",
    "            cov_t = torch.from_numpy(self.cov[i])\n",
    "        else:\n",
    "            cov_t = torch.empty(0)\n",
    "        y = int(r['label'])\n",
    "        pid = str(r['participant_id'])\n",
    "        return torch.from_numpy(x), torch.tensor(1.0), cov_t, torch.tensor(y), pid\n",
    "\n",
    "# Oversampling helper (replicate minority rows)\n",
    "def oversample_df(df, label_col='label'):\n",
    "    counts = df[label_col].value_counts()\n",
    "    max_n = counts.max()\n",
    "    parts = []\n",
    "    for lab, cnt in counts.items():\n",
    "        subset = df[df[label_col]==lab]\n",
    "        if cnt == max_n:\n",
    "            parts.append(subset)\n",
    "        else:\n",
    "            reps = int(np.ceil(max_n / cnt))\n",
    "            augmented = pd.concat([subset]*reps, ignore_index=True).iloc[:max_n]\n",
    "            parts.append(augmented)\n",
    "    out = pd.concat(parts, ignore_index=True).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def make_fold_dataloaders(df, fold_idx=0, mode='SEQ_NPY', cov_pipeline=None):\n",
    "    groups = df['participant_id'].astype(str).values\n",
    "    y = df['label'].values\n",
    "    class_counts = pd.Series(y).value_counts()\n",
    "    base_splits = 5\n",
    "    min_class = class_counts.min()\n",
    "    n_splits = base_splits if min_class >= base_splits else max(2, int(min_class))\n",
    "    if len(np.unique(y))>1 and n_splits >=2:\n",
    "        splitter = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    else:\n",
    "        splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    folds = list(splitter.split(X=np.zeros_like(y), y=y, groups=groups))\n",
    "    if fold_idx >= len(folds):\n",
    "        fold_idx = 0\n",
    "    tr_idx, va_idx = folds[fold_idx]\n",
    "\n",
    "    df_train = df.iloc[tr_idx].copy()\n",
    "    df_val = df.iloc[va_idx].copy()\n",
    "\n",
    "    if ENABLE_AUTOBALANCE and BALANCE_STRATEGY == 'oversample':\n",
    "        df_train = oversample_df(df_train, label_col='label')\n",
    "\n",
    "    if cov_pipeline is not None:\n",
    "        cov_fitted = Pipeline(steps=cov_pipeline.steps) if hasattr(cov_pipeline,'steps') else cov_pipeline\n",
    "        cov_fitted.fit(df_train[[c for c in (cov_cols_cont+cov_cols_cat) if c in df_train.columns]])\n",
    "    else:\n",
    "        cov_fitted = None\n",
    "\n",
    "    if mode in ('SEQ_NPY','SEQ_TSV'):\n",
    "        tr_ds = TimeSeriesDataset(df_train, mode, cov_pre=cov_fitted)\n",
    "        va_ds = TimeSeriesDataset(df_val, mode, cov_pre=cov_fitted)\n",
    "    else:\n",
    "        tr_ds = DFCDataset(df_train, cov_pre=cov_fitted)\n",
    "        va_ds = DFCDataset(df_val, cov_pre=cov_fitted)\n",
    "\n",
    "    if ENABLE_AUTOBALANCE and BALANCE_STRATEGY == 'sampler':\n",
    "        labels_train = df_train['label'].values\n",
    "        counts_train = pd.Series(labels_train).value_counts()\n",
    "        if CLASS_WEIGHT_MODE == 'inv_sqrt':\n",
    "            raw_w = {lab: 1.0/np.sqrt(cnt) for lab,cnt in counts_train.items()}\n",
    "        else:\n",
    "            raw_w = {lab: 1.0/cnt for lab,cnt in counts_train.items()}\n",
    "        w_vals = np.array(list(raw_w.values()))\n",
    "        w_vals /= w_vals.min()\n",
    "        ratio = w_vals.max()/w_vals.min()\n",
    "        if ratio > MAX_CLASS_WEIGHT_RATIO:\n",
    "            w_vals = w_vals / w_vals.max() * MAX_CLASS_WEIGHT_RATIO\n",
    "        for i,(lab,_) in enumerate(raw_w.items()):\n",
    "            raw_w[lab] = w_vals[i]\n",
    "        sample_weights = np.array([raw_w[lab] for lab in labels_train], dtype=np.float64)\n",
    "        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        train_loader = DataLoader(tr_ds, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "    else:\n",
    "        train_loader = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(va_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Модели: LSTM / GRU / MLP / TCN+BiGRU+Self-Attn (SE, FiLM) - ROISequenceNet\n",
    "- **LSTM/GRU**: компактные RNN-блоки. Ковариаты (если есть) конкатенируются к финальному скрытому состоянию.\n",
    "- **MLP**: полносвязная сеть по усреднённым по времени признакам (среднее/дисперсия по ROI).\n",
    "- **ROISequenceNet (TCN+BiGRU+Attn+SE+FiLM)**: темпоральные свёртки (локальные паттерны) → двунаправленный GRU (дальние зависимости) → self-attention и SE-внимание по ROI; ковариаты подаются через FiLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _final_timestep_from_packed(out_padded, lengths):\n",
    "    # out_padded: (B, T_max, H*) после pad_packed_sequence\n",
    "    # lengths: (B,) реальные длины (int64)\n",
    "    idx = (lengths - 1).to(out_padded.device)                 # (B,)\n",
    "    B = out_padded.size(0)\n",
    "    return out_padded[torch.arange(B, device=out_padded.device), idx]  # (B, H*)\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, n_rois, n_classes=2, cov_dim=0, hidden=128, num_layers=1,\n",
    "                 bidir=False, dropout=0.2, use_pack=False):\n",
    "        super().__init__()\n",
    "        self.use_pack = use_pack\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_rois, hidden_size=hidden, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=bidir,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        d = hidden * (2 if bidir else 1)\n",
    "        self.cov_proj = nn.Linear(cov_dim, d) if cov_dim > 0 else None\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        # x: (B,T,R), mask: (B,T) in {0,1}\n",
    "        if self.use_pack and mask is not None:\n",
    "            lengths = mask.sum(dim=1).to(torch.int64).cpu()\n",
    "            packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            out, _ = self.lstm(packed)\n",
    "            out_padded, _ = pad_packed_sequence(out, batch_first=True)  # (B,T_max,H*)\n",
    "            h = _final_timestep_from_packed(out_padded, lengths)        # (B,H*)\n",
    "        else:\n",
    "            if mask is not None:\n",
    "                x = x * mask.unsqueeze(-1)  # простой и быстрый вариант\n",
    "            out, _ = self.lstm(x)           # (B,T,H*)\n",
    "            h = out[:, -1]                  # берём последний таймстеп\n",
    "\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            h = h + self.cov_proj(cov)\n",
    "        return self.head(h)\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, n_rois, n_classes=2, cov_dim=0, hidden=128, num_layers=1,\n",
    "                 bidir=False, dropout=0.2, use_pack=False):\n",
    "        super().__init__()\n",
    "        self.use_pack = use_pack\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_rois, hidden_size=hidden, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=bidir,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        d = hidden * (2 if bidir else 1)\n",
    "        self.cov_proj = nn.Linear(cov_dim, d) if cov_dim > 0 else None\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        # x: (B,T,R), mask: (B,T) in {0,1}\n",
    "        if self.use_pack and mask is not None:\n",
    "            lengths = mask.sum(dim=1).to(torch.int64).cpu()\n",
    "            packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            out, _ = self.gru(packed)\n",
    "            out_padded, _ = pad_packed_sequence(out, batch_first=True)  # (B,T_max,H*)\n",
    "            h = _final_timestep_from_packed(out_padded, lengths)        # (B,H*)\n",
    "        else:\n",
    "            if mask is not None:\n",
    "                x = x * mask.unsqueeze(-1)\n",
    "            out, _ = self.gru(x)\n",
    "            h = out[:, -1]\n",
    "\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            h = h + self.cov_proj(cov)\n",
    "        return self.head(h)\n",
    "    \n",
    "class  SimpleMLP(nn.Module):  # для DFC\n",
    "    def __init__(self, in_dim, n_classes=2, cov_dim=0, hidden=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.cov_proj = nn.Linear(cov_dim, hidden) if cov_dim>0 else None\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, n_classes)\n",
    "        )\n",
    "    def forward(self, x, mask=None, cov=None):\n",
    "        out = self.net(x)\n",
    "        if cov is not None and self.cov_proj is not None:\n",
    "            out = out + self.cov_proj(cov)\n",
    "        return out\n",
    "\n",
    "\n",
    "# === Сложная многосоставная (целевая) модель TCN+BiGRU+Self-Attn (SE, FiLM) ===\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size): super().__init__(); self.chomp_size=chomp_size\n",
    "    def forward(self, x): return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout=0.1):\n",
    "        super().__init__()\n",
    "        pad = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=pad, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(pad)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=pad, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(pad)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.down = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        out = self.chomp1(self.conv1(x)); out = self.relu(out); out = self.dropout(out)\n",
    "        out = self.chomp2(self.conv2(out)); out = self.relu(out); out = self.dropout(out)\n",
    "        return self.relu(out + self.down(x))\n",
    "\n",
    "class SE1D(nn.Module):\n",
    "    def __init__(self, channels, r=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, max(1, channels // r))\n",
    "        self.fc2 = nn.Linear(max(1, channels // r), channels)\n",
    "    def forward(self, x):\n",
    "        s = x.mean(dim=2); w = torch.sigmoid(self.fc2(F.relu(self.fc1(s))))\n",
    "        return x * w.unsqueeze(-1)\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, cov_dim, feat_ch):\n",
    "        super().__init__(); self.gamma = nn.Linear(cov_dim, feat_ch); self.beta = nn.Linear(cov_dim, feat_ch)\n",
    "    def forward(self, x, z):\n",
    "        g = self.gamma(z).unsqueeze(-1); b = self.beta(z).unsqueeze(-1); return x * (1 + g) + b\n",
    "\n",
    "class MultiHeadTemporalAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=4):\n",
    "        super().__init__(); self.mha = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(d_model); self.ff = nn.Sequential(nn.Linear(d_model,2*d_model), nn.ReLU(), nn.Linear(2*d_model,d_model))\n",
    "    def forward(self, X, mask=None):\n",
    "        key_padding_mask = (~mask.bool()) if mask is not None else None\n",
    "        Y,_ = self.mha(X,X,X, key_padding_mask=key_padding_mask)\n",
    "        X = self.ln(X+Y); Z = self.ln(X + self.ff(X))\n",
    "        if mask is None: return Z.mean(dim=1)\n",
    "        w = mask.float().unsqueeze(-1); return (Z*w).sum(dim=1)/(w.sum(dim=1)+1e-8)\n",
    "\n",
    "class ROISequenceNet(nn.Module):\n",
    "    def __init__(self, n_roi, n_classes=4, cov_dim=0, tcn_dropout=0.1, gru_hidden=128, attn_heads=4):\n",
    "        super().__init__()\n",
    "        self.film = FiLM(cov_dim, 128) if cov_dim>0 else None\n",
    "        self.se1 = SE1D(n_roi)\n",
    "        self.tcn = nn.Sequential(\n",
    "            TemporalBlock(n_roi, 128, kernel_size=5, dilation=1, dropout=tcn_dropout),\n",
    "            TemporalBlock(128, 128, kernel_size=5, dilation=2, dropout=tcn_dropout),\n",
    "            TemporalBlock(128, 128, kernel_size=5, dilation=4, dropout=tcn_dropout),\n",
    "        )\n",
    "        self.se2 = SE1D(128)\n",
    "        self.bigru = nn.GRU(input_size=128, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "        self.attn = MultiHeadTemporalAttention(d_model=256, n_heads=4)\n",
    "        self.head = nn.Sequential(nn.Linear(256,128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, n_classes))\n",
    "    def forward(self, x, mask=None, z=None):\n",
    "        x = x.transpose(1,2); x = self.se1(x)\n",
    "        if self.film is not None and z is not None: x = self.film(x, z)\n",
    "        x = self.tcn(x); x = self.se2(x); x = x.transpose(1,2)\n",
    "        y,_ = self.bigru(x); emb = self.attn(y, mask=mask); return self.head(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Обучение и метрики\n",
    "\n",
    "### Организация обучения\n",
    "- Используется стандартный цикл обучения PyTorch с оптимизатором Adam и планировщиком lr.ReduceLROnPlateau.\n",
    "- Метрики: accuracy, precision, AUC, F1-score (макро).\n",
    "- Веса классов учитываются в функции потерь (CrossEntropyLoss).\n",
    "- Последовательно обучаем модели LSTM, GRU и ROISequenceNet, сравнивая их производительность на валидационном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2044b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Универсальный класс тренировки модели\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dl, val_dl, class_counts: pd.Series, device, lr=1e-3, weight_decay=1e-4):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.device = device\n",
    "        self.class_labels = sorted(class_counts.index.tolist())\n",
    "        self.class_count = len(self.class_labels)\n",
    "        weights = (1.0 / (class_counts + 1e-9))\n",
    "        weights = (weights / weights.sum()) * len(class_counts)\n",
    "        class_weights = torch.tensor(weights.values, dtype=torch.float32).to(device)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def _forward_model(self, X, M, C):\n",
    "        if C is not None and C.nelement() > 0:\n",
    "            # Пытаемся вызвать с аргументом cov, fallback на z\n",
    "            try:\n",
    "                return self.model(X, mask=M, cov=C)\n",
    "            except TypeError:\n",
    "                return self.model(X, mask=M, z=C)\n",
    "        else:\n",
    "            return self.model(X, mask=M)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch in self.train_dl:\n",
    "            # Поддержка различных форматов батча\n",
    "            if len(batch) == 5:\n",
    "                X, M, C, y, _ = batch\n",
    "            elif len(batch) == 4:\n",
    "                X, M, C, y = batch\n",
    "            elif len(batch) == 3:\n",
    "                X, C, y = batch\n",
    "                M = None\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            M = M.to(self.device) if M is not None else None\n",
    "            C = C.to(self.device) if (C is not None and C.nelement() > 0) else None\n",
    "            outputs = self._forward_model(X, M, C)\n",
    "            loss = self.criterion(outputs, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "        return total_loss / len(self.train_dl.dataset)\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dl:\n",
    "                if len(batch) == 5:\n",
    "                    X, M, C, y, _ = batch\n",
    "                elif len(batch) == 4:\n",
    "                    X, M, C, y = batch\n",
    "                elif len(batch) == 3:\n",
    "                    X, C, y = batch\n",
    "                    M = None\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                M = M.to(self.device) if M is not None else None\n",
    "                C = C.to(self.device) if (C is not None and C.nelement() > 0) else None\n",
    "                outputs = self._forward_model(X, M, C)\n",
    "                loss = self.criterion(outputs, y)\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "        all_probs = np.vstack(all_probs) if all_probs else np.zeros((0, self.class_count))\n",
    "        accuracy = accuracy_score(all_labels, all_preds) if all_labels else float('nan')\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0) if all_labels else float('nan')\n",
    "        try:\n",
    "            auc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr', labels=self.class_labels) if all_labels else float('nan')\n",
    "        except ValueError:\n",
    "            auc = float('nan')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0) if all_labels else float('nan')\n",
    "        return total_loss / len(self.val_dl.dataset), accuracy, precision, auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, opt, dl, device='cuda'):\n",
    "    model.train(); losses=[]; ce=nn.CrossEntropyLoss()\n",
    "    for xb, mb, cb, yb, _ in dl:\n",
    "        xb=xb.to(device).float(); yb=yb.to(device).long(); cb=cb.to(device).float() if cb is not None else None\n",
    "        if SANITIZE_INPUTS:\n",
    "            xb = torch.nan_to_num(xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        logits = model(xb, mask=mb, cov=cb)\n",
    "        if torch.isnan(logits).any():\n",
    "            print('[WARN] NaN logits detected, skipping batch')\n",
    "            continue\n",
    "        loss = ce(logits, yb)\n",
    "        if torch.isnan(loss):\n",
    "            print('[WARN] NaN loss detected, skipping batch')\n",
    "            continue\n",
    "        opt.zero_grad(); loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    return float(np.mean(losses)) if losses else float('nan')\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_metrics(model, dl, device='cuda'):\n",
    "    model.eval(); ys=[]; yh=[]; yp=[]\n",
    "    for xb, mb, cb, yb, _ in dl:\n",
    "        xb=xb.to(device).float(); yb=yb.to(device).long(); cb=cb.to(device).float() if cb is not None else None\n",
    "        if SANITIZE_INPUTS:\n",
    "            xb = torch.nan_to_num(xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        logits = model(xb, mask=mb, cov=cb)\n",
    "        if torch.isnan(logits).any():\n",
    "            continue\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        pred  = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        ys += yb.cpu().numpy().tolist(); yh += pred; yp += probs\n",
    "    if not ys:\n",
    "        return float('nan'), float('nan'), float('nan')\n",
    "    acc = accuracy_score(ys, yh)\n",
    "    try:\n",
    "        if probs.shape[1] > 2:\n",
    "            auc = roc_auc_score(ys, yp, multi_class='ovr')\n",
    "        else:\n",
    "            auc = roc_auc_score(ys, np.vstack(yp)[:,1])\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    f1  = f1_score(ys, yh, average='weighted')\n",
    "    return acc, auc, f1\n",
    "\n",
    "# Weight init helper\n",
    "def init_weights_if_requested(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.uniform_(m.bias, -0.05, 0.05)\n",
    "        elif isinstance(m, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name and param.ndimension() >= 2:\n",
    "                    # use .data to avoid in-place ops on leaf views\n",
    "                    nn.init.orthogonal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    # safe zero init\n",
    "                    param.data.zero_()\n",
    "                    # forget gate bias boost (only LSTM: bias_hh and bias_ih concatenated gates)\n",
    "                    if isinstance(m, nn.LSTM):\n",
    "                        hidden_size = m.hidden_size\n",
    "                        # bias structure: [i, f, g, o]; set forget gate (f) to 1\n",
    "                        param.data[hidden_size:2*hidden_size].fill_(1.0)\n",
    "\n",
    "# Head reinit helper\n",
    "def reinit_head(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if name.endswith('head') and isinstance(module, nn.Sequential):\n",
    "            for sub in module:\n",
    "                if isinstance(sub, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(sub.weight)\n",
    "                    if sub.bias is not None:\n",
    "                        nn.init.uniform_(sub.bias, -0.05, 0.05)\n",
    "            print('[INFO] Reinitialized classification head for stagnation recovery.')\n",
    "            break\n",
    "\n",
    "# Функция для обучения модели с поддержкой: history, early stopping, debug, санитизация, клиппинг, стагнация.\n",
    "\n",
    "def train_model(model, train_dl, val_dl, class_counts, device, epochs=10, checkpoint_dir=None, lr=1e-3, weight_decay=1e-4, debug=False,\n",
    "                early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE):\n",
    "    if checkpoint_dir and not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    trainer = Trainer(model, train_dl, val_dl, class_counts, device, lr, weight_decay)\n",
    "    best_acc = 0.0\n",
    "    history = []\n",
    "    if early_metric not in ('val_loss','val_acc','val_f1'):\n",
    "        early_metric = 'val_loss'\n",
    "    early_best = None\n",
    "    early_counter = 0\n",
    "\n",
    "    init_weights_if_requested(model)\n",
    "    stagnation_epochs = 0\n",
    "\n",
    "    def param_vector(m):\n",
    "        return torch.cat([p.detach().flatten() for p in m.parameters() if p.requires_grad])\n",
    "    prev_params = param_vector(model)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train(); total_loss=0.0; batch_losses=[]; grad_norms=[]; skipped_batches=0\n",
    "        for batch in train_dl:\n",
    "            if len(batch)==5: X,M,C,y,_ = batch\n",
    "            elif len(batch)==4: X,M,C,y = batch\n",
    "            elif len(batch)==3: X,C,y = batch; M=None\n",
    "            else: raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            M = M.to(device) if M is not None else None\n",
    "            C = C.to(device) if (C is not None and C.nelement()>0) else None\n",
    "            if SANITIZE_INPUTS:\n",
    "                X = torch.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            outputs = trainer._forward_model(X, M, C)\n",
    "            if torch.isnan(outputs).any():\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            loss = trainer.criterion(outputs, y)\n",
    "            if torch.isnan(loss):\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            trainer.optimizer.zero_grad(); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "            gnorm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    gnorm += p.grad.detach().data.norm(2).item()\n",
    "            trainer.optimizer.step()\n",
    "            total_loss += loss.item()*X.size(0)\n",
    "            batch_losses.append(loss.item())\n",
    "            grad_norms.append(gnorm)\n",
    "        train_loss = total_loss / len(train_dl.dataset) if batch_losses else float('nan')\n",
    "        val_loss, val_acc, val_prec, val_auc, val_f1 = trainer.evaluate()\n",
    "        cur_params = param_vector(model)\n",
    "        delta = (cur_params - prev_params).abs().mean().item()\n",
    "        prev_params = cur_params\n",
    "        if torch.isnan(cur_params).any() and REINIT_ON_NAN:\n",
    "            print('[WARN] NaN detected in parameters -> reinitializing linear + recurrent layers')\n",
    "            init_weights_if_requested(model)\n",
    "\n",
    "        print(f\"Эпоха {epoch+1}/{epochs} | TrainLoss {train_loss:.4f} | ValLoss {val_loss:.4f} | Acc {val_acc:.4f} | Prec {val_prec:.4f} | AUC {val_auc:.4f} | F1 {val_f1:.4f} | Δparam {delta:.6e} | skipped {skipped_batches}\")\n",
    "        if debug and batch_losses:\n",
    "            print(f\"  BatchLoss[min/median/max]: {np.min(batch_losses):.4f}/{np.median(batch_losses):.4f}/{np.max(batch_losses):.4f}; GradNorm[mean]: {np.mean(grad_norms):.4f}\")\n",
    "\n",
    "        if val_acc > best_acc and not torch.isnan(torch.tensor(val_acc)):\n",
    "            best_acc = val_acc\n",
    "            if checkpoint_dir:\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pth'))\n",
    "                if debug: print('  ↳ saved best checkpoint')\n",
    "\n",
    "        # stagnation logic\n",
    "        if val_acc == 0.0:\n",
    "            stagnation_epochs += 1\n",
    "            if HEAD_REINIT and stagnation_epochs >= STAGNATION_RESET_EPOCHS:\n",
    "                print(f\"[STAGNATION] val_acc remained 0 for {stagnation_epochs} epochs -> reinit head\")\n",
    "                reinit_head(model)\n",
    "                stagnation_epochs = 0\n",
    "        else:\n",
    "            stagnation_epochs = 0\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_prec': val_prec,\n",
    "            'val_auc': val_auc,\n",
    "            'val_f1': val_f1,\n",
    "            'param_delta_mean_abs': delta,\n",
    "            'skipped_batches': skipped_batches,\n",
    "            'grad_norm_mean': float(np.mean(grad_norms)) if grad_norms else float('nan'),\n",
    "            'stagnation_epochs': stagnation_epochs\n",
    "        })\n",
    "\n",
    "        metric_value = {'val_loss': val_loss, 'val_acc': val_acc, 'val_f1': val_f1}[early_metric]\n",
    "        improve = False\n",
    "        if early_best is None:\n",
    "            early_best = metric_value\n",
    "            improve = True\n",
    "        else:\n",
    "            if early_metric == 'val_loss':\n",
    "                if early_best - metric_value > min_delta:\n",
    "                    improve = True\n",
    "            else:\n",
    "                if metric_value - early_best > min_delta:\n",
    "                    improve = True\n",
    "        if improve:\n",
    "            early_best = metric_value\n",
    "            early_counter = 0\n",
    "        else:\n",
    "            early_counter += 1\n",
    "            if early_counter >= patience:\n",
    "                print(f\"[EARLY STOP] metric={early_metric} no improve {patience} epochs (best={early_best:.4f}).\")\n",
    "                break\n",
    "\n",
    "    print(\"Лучший валид. Accuracy:\", best_acc)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Создание тренировочной и валидационной выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: режим SEQ_NPY, число ROI 353, размер ковариат 0, число классов 4\n",
      "Train классы: (array([0, 1, 2, 3]), array([2, 3, 4, 7]))\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = make_fold_dataloaders(data_df, fold_idx=0, mode=DATA_MODE, cov_pipeline=pre)\n",
    "xb, mb, cb, yb, pid = next(iter(train_dl))\n",
    "\n",
    "# cb теперь всегда тензор (пустой если нет ковариат)\n",
    "cov_dim = (cb.shape[-1] if (cb is not None and cb.numel() > 0) else 0)\n",
    "\n",
    "class_counts = data_df['label'].value_counts().sort_index()\n",
    "cls_counts = class_counts  # совместимость с нижними ячейками\n",
    "\n",
    "if DATA_MODE in ('SEQ_NPY','SEQ_TSV'):\n",
    "    R = xb.shape[-1]      # число ROI\n",
    "    in_dim = R\n",
    "else:\n",
    "    in_dim = xb.shape[-1]\n",
    "    R = in_dim\n",
    "\n",
    "print(f\"Входные данные: режим {DATA_MODE}, число ROI {R}, размер ковариат {cov_dim}, число классов {N_CLASSES}\")\n",
    "\n",
    "# Разбивка по классам:\n",
    "print(\"Train классы:\", np.unique(yb.numpy(), return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e60ad2",
   "metadata": {},
   "source": [
    "### Обучение Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21abc55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DIAG] class counts (full df): {0: 249, 1: 64, 2: 8, 3: 51}\n",
      "[DIAG] unique labels: [0, 1, 2, 3]\n",
      "\n",
      "=== SimpleLSTM: балансировка sampler (взвешенный семплинг) ===\n",
      "Эпоха 1/30 | TrainLoss 0.5654 | ValLoss 2.0080 | Acc 0.1500 | Prec 0.6393 | AUC 0.5185 | F1 0.1179 | Δparam 4.869583e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1167/0.3805/1.9969; GradNorm[mean]: 7.1440\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/30 | TrainLoss 0.2441 | ValLoss 2.0387 | Acc 0.1375 | Prec 0.8484 | AUC 0.5681 | F1 0.0973 | Δparam 2.525484e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0563/0.2333/0.5279; GradNorm[mean]: 4.1229\n",
      "Эпоха 3/30 | TrainLoss 0.1502 | ValLoss 1.7726 | Acc 0.1625 | Prec 0.8505 | AUC 0.5947 | F1 0.1449 | Δparam 2.119693e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0344/0.1223/0.3294; GradNorm[mean]: 3.2534\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 4/30 | TrainLoss 0.0954 | ValLoss 1.5982 | Acc 0.2500 | Prec 0.6897 | AUC 0.5397 | F1 0.2951 | Δparam 1.444459e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0247/0.0949/0.1764; GradNorm[mean]: 1.8991\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 5/30 | TrainLoss 0.0627 | ValLoss 1.6016 | Acc 0.2875 | Prec 0.7522 | AUC 0.5701 | F1 0.3371 | Δparam 1.221430e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0262/0.0615/0.1222; GradNorm[mean]: 1.3291\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 6/30 | TrainLoss 0.0621 | ValLoss 1.6247 | Acc 0.3875 | Prec 0.7113 | AUC 0.5332 | F1 0.4727 | Δparam 1.115022e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0252/0.0492/0.1855; GradNorm[mean]: 1.2809\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 7/30 | TrainLoss 0.0465 | ValLoss 1.7144 | Acc 0.4125 | Prec 0.6627 | AUC 0.4820 | F1 0.4931 | Δparam 1.057124e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0136/0.0384/0.1233; GradNorm[mean]: 1.7935\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 8/30 | TrainLoss 0.0602 | ValLoss 2.0351 | Acc 0.1875 | Prec 0.6704 | AUC 0.6038 | F1 0.2030 | Δparam 1.718200e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0166/0.0276/1.2486; GradNorm[mean]: 2.3766\n",
      "Эпоха 9/30 | TrainLoss 0.0608 | ValLoss 2.3619 | Acc 0.2125 | Prec 0.8500 | AUC 0.6199 | F1 0.2431 | Δparam 1.060626e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0147/0.0525/0.1995; GradNorm[mean]: 0.8174\n",
      "Эпоха 10/30 | TrainLoss 0.0619 | ValLoss 1.7018 | Acc 0.2875 | Prec 0.8028 | AUC 0.5803 | F1 0.3491 | Δparam 1.027685e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0169/0.0511/0.2131; GradNorm[mean]: 1.1106\n",
      "Эпоха 11/30 | TrainLoss 0.0515 | ValLoss 1.6467 | Acc 0.4875 | Prec 0.7276 | AUC 0.5055 | F1 0.5695 | Δparam 1.136124e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0197/0.0419/0.3712; GradNorm[mean]: 1.4391\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 12/30 | TrainLoss 0.0393 | ValLoss 1.5356 | Acc 0.4875 | Prec 0.7271 | AUC 0.5966 | F1 0.5656 | Δparam 1.881173e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0069/0.0306/0.1020; GradNorm[mean]: 1.7599\n",
      "Эпоха 13/30 | TrainLoss 0.0218 | ValLoss 1.7296 | Acc 0.4750 | Prec 0.7070 | AUC 0.5232 | F1 0.5537 | Δparam 1.066297e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0023/0.0192/0.0524; GradNorm[mean]: 0.5916\n",
      "Эпоха 14/30 | TrainLoss 0.0184 | ValLoss 1.8145 | Acc 0.5000 | Prec 0.6932 | AUC 0.5040 | F1 0.5698 | Δparam 9.201571e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0050/0.0175/0.0366; GradNorm[mean]: 0.6638\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 15/30 | TrainLoss 0.0145 | ValLoss 1.7237 | Acc 0.5625 | Prec 0.6647 | AUC 0.4562 | F1 0.6070 | Δparam 8.260586e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0040/0.0127/0.0344; GradNorm[mean]: 0.4779\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 16/30 | TrainLoss 0.0120 | ValLoss 1.8884 | Acc 0.5375 | Prec 0.6576 | AUC 0.4405 | F1 0.5885 | Δparam 5.351626e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0044/0.0092/0.0329; GradNorm[mean]: 0.2897\n",
      "Эпоха 17/30 | TrainLoss 0.0086 | ValLoss 2.0563 | Acc 0.4875 | Prec 0.6546 | AUC 0.4568 | F1 0.5495 | Δparam 4.686129e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0019/0.0072/0.0251; GradNorm[mean]: 0.2328\n",
      "Эпоха 18/30 | TrainLoss 0.0081 | ValLoss 1.9866 | Acc 0.5375 | Prec 0.6703 | AUC 0.4523 | F1 0.5896 | Δparam 3.983311e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0017/0.0045/0.0212; GradNorm[mean]: 0.2322\n",
      "Эпоха 19/30 | TrainLoss 0.0072 | ValLoss 1.9667 | Acc 0.5375 | Prec 0.6703 | AUC 0.4601 | F1 0.5896 | Δparam 3.461841e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0028/0.0063/0.0209; GradNorm[mean]: 0.1458\n",
      "Эпоха 20/30 | TrainLoss 0.0067 | ValLoss 1.9842 | Acc 0.5500 | Prec 0.6740 | AUC 0.4643 | F1 0.5994 | Δparam 2.452721e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0005/0.0050/0.0236; GradNorm[mean]: 0.1156\n",
      "Эпоха 21/30 | TrainLoss 0.0062 | ValLoss 1.9984 | Acc 0.5500 | Prec 0.6740 | AUC 0.4663 | F1 0.5994 | Δparam 2.577276e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0014/0.0047/0.0185; GradNorm[mean]: 0.1230\n",
      "Эпоха 22/30 | TrainLoss 0.0062 | ValLoss 1.9942 | Acc 0.5625 | Prec 0.6777 | AUC 0.4720 | F1 0.6090 | Δparam 2.684863e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0047/0.0180; GradNorm[mean]: 0.1201\n",
      "Эпоха 23/30 | TrainLoss 0.0043 | ValLoss 1.9991 | Acc 0.5750 | Prec 0.6699 | AUC 0.4683 | F1 0.6144 | Δparam 2.436504e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0016/0.0044/0.0081; GradNorm[mean]: 0.0841\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 24/30 | TrainLoss 0.0175 | ValLoss 2.1353 | Acc 0.4375 | Prec 0.7038 | AUC 0.4699 | F1 0.5233 | Δparam 2.437652e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0021/0.0073/0.0732; GradNorm[mean]: 1.8755\n",
      "Эпоха 25/30 | TrainLoss 0.0128 | ValLoss 1.8709 | Acc 0.4875 | Prec 0.6961 | AUC 0.5090 | F1 0.5625 | Δparam 1.585079e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0014/0.0091/0.0467; GradNorm[mean]: 1.0792\n",
      "Эпоха 26/30 | TrainLoss 0.0295 | ValLoss 2.1961 | Acc 0.4375 | Prec 0.6759 | AUC 0.4773 | F1 0.5248 | Δparam 3.257766e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0040/0.0110/0.1616; GradNorm[mean]: 2.1697\n",
      "Эпоха 27/30 | TrainLoss 0.0298 | ValLoss 1.8500 | Acc 0.5375 | Prec 0.6932 | AUC 0.4928 | F1 0.5997 | Δparam 3.050391e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0046/0.0101/0.1324; GradNorm[mean]: 1.6927\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.5356).\n",
      "Лучший валид. Accuracy: 0.575\n",
      "\n",
      "[HISTORY - sampler] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "24515fa7-26bf-4a96-ad98-ba8b6e1915e8",
       "rows": [
        [
         "22",
         "23",
         "0.0042848168961601716",
         "1.9990646243095398",
         "0.575",
         "0.6699074074074074",
         "0.468297619047619",
         "0.614390756302521",
         "0.0002436503564240411",
         "0",
         "0.08407269892785207",
         "0"
        ],
        [
         "23",
         "24",
         "0.01747148966557053",
         "2.1353036642074583",
         "0.4375",
         "0.7038087194337195",
         "0.4698571428571429",
         "0.5233265720081135",
         "0.002437652088701725",
         "0",
         "1.875485745316837",
         "0"
        ],
        [
         "24",
         "25",
         "0.012805775477716776",
         "1.87088440656662",
         "0.4875",
         "0.6960979427549195",
         "0.5089642857142856",
         "0.5625362318840579",
         "0.0015850792406126857",
         "0",
         "1.0791684021272598",
         "0"
        ],
        [
         "25",
         "26",
         "0.02947882052562008",
         "2.196054494380951",
         "0.4375",
         "0.6758638211382113",
         "0.4772619047619047",
         "0.5247978436657681",
         "0.003257765667513013",
         "0",
         "2.169706384216337",
         "0"
        ],
        [
         "26",
         "27",
         "0.029799009666918484",
         "1.8499530673027038",
         "0.5375",
         "0.6931690705128205",
         "0.49280952380952386",
         "0.5996994036167757",
         "0.003050390863791108",
         "0",
         "1.6927141139014183",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>1.999065</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.669907</td>\n",
       "      <td>0.468298</td>\n",
       "      <td>0.614391</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>2.135304</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.703809</td>\n",
       "      <td>0.469857</td>\n",
       "      <td>0.523327</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0</td>\n",
       "      <td>1.875486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>1.870884</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.696098</td>\n",
       "      <td>0.508964</td>\n",
       "      <td>0.562536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0</td>\n",
       "      <td>1.079168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>2.196054</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.675864</td>\n",
       "      <td>0.477262</td>\n",
       "      <td>0.524798</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0</td>\n",
       "      <td>2.169706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.029799</td>\n",
       "      <td>1.849953</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.693169</td>\n",
       "      <td>0.492810</td>\n",
       "      <td>0.599699</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0</td>\n",
       "      <td>1.692714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "22     23    0.004285  1.999065   0.5750  0.669907  0.468298  0.614391              0.000244                0        0.084073                  0\n",
       "23     24    0.017471  2.135304   0.4375  0.703809  0.469857  0.523327              0.002438                0        1.875486                  0\n",
       "24     25    0.012806  1.870884   0.4875  0.696098  0.508964  0.562536              0.001585                0        1.079168                  0\n",
       "25     26    0.029479  2.196054   0.4375  0.675864  0.477262  0.524798              0.003258                0        2.169706                  0\n",
       "26     27    0.029799  1.849953   0.5375  0.693169  0.492810  0.599699              0.003050                0        1.692714                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] SimpleLSTM - Val Acc: 0.5750 | Val F1: 0.6144 | Val AUC: 0.4683\n"
     ]
    }
   ],
   "source": [
    "model_lstm = SimpleLSTM(n_rois=R, n_classes=N_CLASSES, cov_dim=cov_dim, hidden=64, num_layers=1).to(DEVICE)\n",
    "checkpoint_dir_path_lstm = f\"{CHECKPOINT_DIR}/SimpleLSTM_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_lstm, exist_ok=True)\n",
    "\n",
    "print('[DIAG] class counts (full df):', cls_counts.to_dict())\n",
    "print('[DIAG] unique labels:', sorted(data_df['label'].unique().tolist()))\n",
    "\n",
    "# Прогон со стратегией sampler (WeightedRandomSampler)\n",
    "print('\\n=== SimpleLSTM: балансировка sampler (взвешенный семплинг) ===')\n",
    "history_lstm_sampler = train_model(\n",
    "    model_lstm, train_dl, val_dl, cls_counts, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_lstm,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "\n",
    "hist_lstm_sampler_df = pd.DataFrame(history_lstm_sampler)\n",
    "print('\\n[HISTORY - sampler] Последние строки:')\n",
    "display(hist_lstm_sampler_df.tail())\n",
    "\n",
    "# Оценка итоговой и лучшей модели\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_lstm, 'best_model.pth')):\n",
    "    model_lstm.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_lstm, 'best_model.pth')))\n",
    "model_lstm.eval()\n",
    "val_loss_lstm, val_acc_lstm, val_prec_lstm, val_auc_lstm, val_f1_lstm = Trainer(model_lstm, train_dl, val_dl, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] SimpleLSTM - Val Acc: {val_acc_lstm:.4f} | Val F1: {val_f1_lstm:.4f} | Val AUC: {val_auc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2186767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DIAG] Начало диагностики батча\n",
      "  Train batch shape: torch.Size([16, 200, 353]) labels shape: torch.Size([16])\n",
      "  Unique labels in batch: (array([0, 1, 2, 3]), array([2, 5, 4, 5]))\n",
      "  Any NaN in Xd: False\n",
      "  Any Inf in Xd: False\n",
      "  Train batch shape: torch.Size([16, 200, 353]) labels shape: torch.Size([16])\n",
      "  Unique labels in batch: (array([0, 1, 2, 3]), array([2, 5, 4, 5]))\n",
      "  Any NaN in Xd: False\n",
      "  Any Inf in Xd: False\n",
      "  Preds before training step: (array([1, 2, 3]), array([ 4,  1, 11]))\n",
      "  Preds after one step: (array([1, 2, 3]), array([4, 4, 8]))\n",
      "[DIAG] Завершено. Если preds не меняются и всегда один класс, возможно входы вырожденные или head не обновляется.\n",
      "  Preds before training step: (array([1, 2, 3]), array([ 4,  1, 11]))\n",
      "  Preds after one step: (array([1, 2, 3]), array([4, 4, 8]))\n",
      "[DIAG] Завершено. Если preds не меняются и всегда один класс, возможно входы вырожденные или head не обновляется.\n"
     ]
    }
   ],
   "source": [
    "# === Диагностика батчей: распределение меток и предсказаний до и после одной итерации ===\n",
    "print('\\n[DIAG] Начало диагностики батча')\n",
    "first_batch = next(iter(train_dl))\n",
    "if len(first_batch)==5:\n",
    "    Xd, Md, Cd, yd, _ = first_batch\n",
    "elif len(first_batch)==4:\n",
    "    Xd, Md, Cd, yd = first_batch\n",
    "else:\n",
    "    Xd, Cd, yd = first_batch; Md=None\n",
    "print('  Train batch shape:', Xd.shape, 'labels shape:', yd.shape)\n",
    "print('  Unique labels in batch:', np.unique(yd.numpy(), return_counts=True))\n",
    "print('  Any NaN in Xd:', np.isnan(Xd.numpy()).any())\n",
    "print('  Any Inf in Xd:', np.isinf(Xd.numpy()).any())\n",
    "\n",
    "# Создаём временную модель для теста (LSTM)\n",
    "_diag_model = SimpleLSTM(n_rois=Xd.shape[-1], n_classes=N_CLASSES, cov_dim=(Cd.shape[-1] if Cd is not None and Cd.numel()>0 else 0), hidden=32)\n",
    "init_weights_if_requested(_diag_model)\n",
    "_diag_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits0 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "    probs0 = torch.softmax(logits0, dim=1)\n",
    "    preds0 = probs0.argmax(1)\n",
    "print('  Preds before training step:', np.unique(preds0.numpy(), return_counts=True))\n",
    "\n",
    "# Один шаг обучения для проверки обновления\n",
    "opt_tmp = torch.optim.Adam(_diag_model.parameters(), lr=1e-3)\n",
    "_diag_model.train()\n",
    "logits1 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "loss1 = nn.CrossEntropyLoss()(logits1, yd)\n",
    "loss1.backward(); torch.nn.utils.clip_grad_norm_(_diag_model.parameters(), MAX_GRAD_NORM); opt_tmp.step()\n",
    "\n",
    "_diag_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits2 = _diag_model(Xd.float(), mask=Md, cov=(Cd if Cd is not None and Cd.numel()>0 else None))\n",
    "    preds2 = logits2.argmax(1)\n",
    "print('  Preds after one step:', np.unique(preds2.numpy(), return_counts=True))\n",
    "print('[DIAG] Завершено. Если preds не меняются и всегда один класс, возможно входы вырожденные или head не обновляется.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89bebf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SimpleLSTM: альтернативный прогон с oversample =====\n",
      "Эпоха 1/30 | TrainLoss 0.3892 | ValLoss 1.4944 | Acc 0.3000 | Prec 0.7985 | AUC 0.6842 | F1 0.3440 | Δparam 6.758468e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0876/0.3036/1.4170; GradNorm[mean]: 5.4328\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 2/30 | TrainLoss 0.1232 | ValLoss 1.5822 | Acc 0.3000 | Prec 0.7198 | AUC 0.5388 | F1 0.3885 | Δparam 2.908253e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0369/0.1009/0.5014; GradNorm[mean]: 2.2200\n",
      "Эпоха 3/30 | TrainLoss 0.0623 | ValLoss 1.4209 | Acc 0.4375 | Prec 0.6862 | AUC 0.5437 | F1 0.5131 | Δparam 1.950261e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0123/0.0512/0.1585; GradNorm[mean]: 1.3561\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 4/30 | TrainLoss 0.0336 | ValLoss 1.7327 | Acc 0.4750 | Prec 0.6791 | AUC 0.5235 | F1 0.5420 | Δparam 1.563722e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0094/0.0339/0.0689; GradNorm[mean]: 0.7757\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 5/30 | TrainLoss 0.0193 | ValLoss 1.6365 | Acc 0.5500 | Prec 0.6868 | AUC 0.5356 | F1 0.5997 | Δparam 1.302370e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0071/0.0168/0.0429; GradNorm[mean]: 0.4867\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 6/30 | TrainLoss 0.0121 | ValLoss 1.7898 | Acc 0.5625 | Prec 0.6912 | AUC 0.5341 | F1 0.6096 | Δparam 8.721979e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0039/0.0110/0.0252; GradNorm[mean]: 0.2532\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 7/30 | TrainLoss 0.0095 | ValLoss 1.8552 | Acc 0.5625 | Prec 0.6905 | AUC 0.5259 | F1 0.6097 | Δparam 6.853418e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0029/0.0079/0.0231; GradNorm[mean]: 0.1764\n",
      "Эпоха 8/30 | TrainLoss 0.0089 | ValLoss 1.9542 | Acc 0.5750 | Prec 0.6955 | AUC 0.5241 | F1 0.6203 | Δparam 6.896792e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0014/0.0074/0.0279; GradNorm[mean]: 0.1697\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 9/30 | TrainLoss 0.0067 | ValLoss 2.0161 | Acc 0.5875 | Prec 0.6855 | AUC 0.5072 | F1 0.6279 | Δparam 6.840359e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0047/0.0642; GradNorm[mean]: 0.1429\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 10/30 | TrainLoss 0.0048 | ValLoss 2.0652 | Acc 0.6250 | Prec 0.6974 | AUC 0.5085 | F1 0.6546 | Δparam 6.235975e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0013/0.0038/0.0165; GradNorm[mean]: 0.0849\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 11/30 | TrainLoss 0.0048 | ValLoss 2.1132 | Acc 0.6125 | Prec 0.6935 | AUC 0.5010 | F1 0.6464 | Δparam 5.386422e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0013/0.0042/0.0190; GradNorm[mean]: 0.0936\n",
      "Эпоха 12/30 | TrainLoss 0.0042 | ValLoss 2.1537 | Acc 0.6125 | Prec 0.6797 | AUC 0.4925 | F1 0.6426 | Δparam 5.659210e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0012/0.0032/0.0138; GradNorm[mean]: 0.0808\n",
      "Эпоха 13/30 | TrainLoss 0.0030 | ValLoss 2.2041 | Acc 0.6250 | Prec 0.6846 | AUC 0.4875 | F1 0.6516 | Δparam 4.873957e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0010/0.0026/0.0076; GradNorm[mean]: 0.0591\n",
      "Эпоха 14/30 | TrainLoss 0.0030 | ValLoss 2.2455 | Acc 0.6375 | Prec 0.6901 | AUC 0.4845 | F1 0.6604 | Δparam 4.225700e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0005/0.0024/0.0091; GradNorm[mean]: 0.0618\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 15/30 | TrainLoss 0.0023 | ValLoss 2.3037 | Acc 0.6500 | Prec 0.6931 | AUC 0.4799 | F1 0.6688 | Δparam 4.510968e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0007/0.0021/0.0063; GradNorm[mean]: 0.0483\n",
      "  ↳ saved best checkpoint\n",
      "Эпоха 16/30 | TrainLoss 0.0025 | ValLoss 2.3381 | Acc 0.6500 | Prec 0.6962 | AUC 0.4822 | F1 0.6689 | Δparam 4.352818e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0003/0.0018/0.0131; GradNorm[mean]: 0.0513\n",
      "Эпоха 17/30 | TrainLoss 0.0023 | ValLoss 2.3988 | Acc 0.6250 | Prec 0.6823 | AUC 0.4733 | F1 0.6507 | Δparam 4.414085e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0007/0.0017/0.0145; GradNorm[mean]: 0.0476\n",
      "Эпоха 18/30 | TrainLoss 0.0022 | ValLoss 2.4216 | Acc 0.6375 | Prec 0.6871 | AUC 0.4802 | F1 0.6595 | Δparam 4.795286e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0003/0.0016/0.0087; GradNorm[mean]: 0.0481\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.4209).\n",
      "Лучший валид. Accuracy: 0.65\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3fbdcdbe-88d9-415d-9f03-a8f4d8e81b88",
       "rows": [
        [
         "13",
         "14",
         "0.00297735018260858",
         "2.2454680621623995",
         "0.6375",
         "0.6900568181818182",
         "0.48445238095238097",
         "0.6604375",
         "0.0004225700395181775",
         "0",
         "0.06175590195356483",
         "0"
        ],
        [
         "14",
         "15",
         "0.002307512293792451",
         "2.303684688732028",
         "0.65",
         "0.6930669398907103",
         "0.47994047619047614",
         "0.6687996031746031",
         "0.00045109677012078464",
         "0",
         "0.048336803852219855",
         "0"
        ],
        [
         "15",
         "16",
         "0.002464744395262602",
         "2.338100019097328",
         "0.65",
         "0.6961919398907104",
         "0.48221428571428576",
         "0.668860877684407",
         "0.0004352818359620869",
         "0",
         "0.051274262477185716",
         "0"
        ],
        [
         "16",
         "17",
         "0.0022663262649945427",
         "2.3987825885415077",
         "0.625",
         "0.6823237673343605",
         "0.47325000000000006",
         "0.6507336469534051",
         "0.00044140854151919484",
         "0",
         "0.04757384570510349",
         "0"
        ],
        [
         "17",
         "18",
         "0.0021627770392629113",
         "2.4216275207698343",
         "0.6375",
         "0.6870806277056277",
         "0.48023809523809524",
         "0.6595183823529412",
         "0.00047952859313227236",
         "0",
         "0.04807543905158325",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>2.245468</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.690057</td>\n",
       "      <td>0.484452</td>\n",
       "      <td>0.660438</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>2.303685</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.693067</td>\n",
       "      <td>0.479940</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>2.338100</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.696192</td>\n",
       "      <td>0.482214</td>\n",
       "      <td>0.668861</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>2.398783</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.682324</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>0.650734</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>2.421628</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.687081</td>\n",
       "      <td>0.480238</td>\n",
       "      <td>0.659518</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "13     14    0.002977  2.245468   0.6375  0.690057  0.484452  0.660438              0.000423                0        0.061756                  0\n",
       "14     15    0.002308  2.303685   0.6500  0.693067  0.479940  0.668800              0.000451                0        0.048337                  0\n",
       "15     16    0.002465  2.338100   0.6500  0.696192  0.482214  0.668861              0.000435                0        0.051274                  0\n",
       "16     17    0.002266  2.398783   0.6250  0.682324  0.473250  0.650734              0.000441                0        0.047574                  0\n",
       "17     18    0.002163  2.421628   0.6375  0.687081  0.480238  0.659518              0.000480                0        0.048075                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Oversample] SimpleLSTM - Val Acc: 0.6500 | Val F1: 0.6688 | Val AUC: 0.4799\n"
     ]
    }
   ],
   "source": [
    "# === Альтернативный прогон SimpleLSTM с oversample стратегией ===\n",
    "# Отличие: oversample физически реплицирует строки меньшинства до размера большинства,\n",
    "# тогда как sampler (WeightedRandomSampler) просто повышает вероятность выборки редких примеров,\n",
    "# не увеличивая абсолютное число уникальных примеров. Oversample увеличивает риск переобучения на редких\n",
    "# классах (дубликаты), sampler более стохастичен.\n",
    "\n",
    "BALANCE_STRATEGY = 'oversample'\n",
    "print('\\n===== SimpleLSTM: альтернативный прогон с oversample =====')\n",
    "train_dl_over, val_dl_over = make_fold_dataloaders(data_df, fold_idx=0, mode=DATA_MODE, cov_pipeline=pre)\n",
    "model_lstm_over = SimpleLSTM(n_rois=R, n_classes=N_CLASSES, cov_dim=cov_dim, hidden=64, num_layers=1).to(DEVICE)\n",
    "checkpoint_dir_path_lstm_over = f\"{CHECKPOINT_DIR}/SimpleLSTM_oversample\"\n",
    "os.makedirs(checkpoint_dir_path_lstm_over, exist_ok=True)\n",
    "\n",
    "history_lstm_oversample = train_model(\n",
    "    model_lstm_over, train_dl_over, val_dl_over, cls_counts, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_lstm_over,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "\n",
    "hist_lstm_oversample_df = pd.DataFrame(history_lstm_oversample)\n",
    "print('\\n[HISTORY - oversample] Последние строки:')\n",
    "display(hist_lstm_oversample_df.tail())\n",
    "\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_lstm_over, 'best_model.pth')):\n",
    "    model_lstm_over.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_lstm_over, 'best_model.pth')))\n",
    "model_lstm_over.eval()\n",
    "val_loss_lstm_o, val_acc_lstm_o, val_prec_lstm_o, val_auc_lstm_o, val_f1_lstm_o = Trainer(model_lstm_over, train_dl_over, val_dl_over, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@Oversample] SimpleLSTM - Val Acc: {val_acc_lstm_o:.4f} | Val F1: {val_f1_lstm_o:.4f} | Val AUC: {val_auc_lstm_o:.4f}\")\n",
    "\n",
    "# Вернём глобальную стратегию в sampler для последующих ячеек\n",
    "BALANCE_STRATEGY = 'sampler'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d509e0",
   "metadata": {},
   "source": [
    "### Обучение Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9496f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SimpleGRU: балансировка sampler ===\n",
      "Эпоха 1/30 | TrainLoss 0.6758 | ValLoss 2.0404 | Acc 0.1000 | Prec 0.8360 | AUC 0.3812 | F1 0.0569 | Δparam 5.702900e-03 | skipped 0\n",
      "Эпоха 2/30 | TrainLoss 0.2823 | ValLoss 2.1011 | Acc 0.1000 | Prec 0.0175 | AUC 0.3456 | F1 0.0299 | Δparam 2.844713e-03 | skipped 0\n",
      "Эпоха 3/30 | TrainLoss 0.2532 | ValLoss 1.8687 | Acc 0.0875 | Prec 0.0162 | AUC 0.3988 | F1 0.0273 | Δparam 2.354905e-03 | skipped 0\n",
      "Эпоха 4/30 | TrainLoss 0.2034 | ValLoss 1.9925 | Acc 0.0750 | Prec 0.0155 | AUC 0.3675 | F1 0.0216 | Δparam 1.840412e-03 | skipped 0\n",
      "Эпоха 5/30 | TrainLoss 0.1430 | ValLoss 1.9325 | Acc 0.0875 | Prec 0.0159 | AUC 0.3727 | F1 0.0269 | Δparam 1.292751e-03 | skipped 0\n",
      "Эпоха 6/30 | TrainLoss 0.2283 | ValLoss 1.9700 | Acc 0.0750 | Prec 0.0155 | AUC 0.4420 | F1 0.0216 | Δparam 1.413375e-03 | skipped 0\n",
      "Эпоха 7/30 | TrainLoss 0.2092 | ValLoss 1.7730 | Acc 0.1125 | Prec 0.8284 | AUC 0.4346 | F1 0.0754 | Δparam 1.546709e-03 | skipped 0\n",
      "Эпоха 8/30 | TrainLoss 0.1737 | ValLoss 1.7835 | Acc 0.1000 | Prec 0.8277 | AUC 0.4675 | F1 0.0703 | Δparam 1.140978e-03 | skipped 0\n",
      "Эпоха 9/30 | TrainLoss 0.1301 | ValLoss 1.7439 | Acc 0.1125 | Prec 0.8293 | AUC 0.4892 | F1 0.0767 | Δparam 1.170927e-03 | skipped 0\n",
      "Эпоха 10/30 | TrainLoss 0.1570 | ValLoss 1.7634 | Acc 0.1250 | Prec 0.8290 | AUC 0.4976 | F1 0.0995 | Δparam 7.366835e-04 | skipped 0\n",
      "Эпоха 11/30 | TrainLoss 0.1644 | ValLoss 1.6993 | Acc 0.1375 | Prec 0.8287 | AUC 0.4984 | F1 0.1215 | Δparam 8.507717e-04 | skipped 0\n",
      "Эпоха 12/30 | TrainLoss 0.1531 | ValLoss 1.6383 | Acc 0.1500 | Prec 0.8279 | AUC 0.4994 | F1 0.1595 | Δparam 1.247617e-03 | skipped 0\n",
      "Эпоха 13/30 | TrainLoss 0.1591 | ValLoss 1.7111 | Acc 0.1375 | Prec 0.8281 | AUC 0.4988 | F1 0.1207 | Δparam 9.647234e-04 | skipped 0\n",
      "Эпоха 14/30 | TrainLoss 0.1402 | ValLoss 1.8061 | Acc 0.1250 | Prec 0.8277 | AUC 0.5463 | F1 0.1160 | Δparam 9.387194e-04 | skipped 0\n",
      "Эпоха 15/30 | TrainLoss 0.1558 | ValLoss 1.6617 | Acc 0.1500 | Prec 0.8293 | AUC 0.5187 | F1 0.1443 | Δparam 1.070572e-03 | skipped 0\n",
      "Эпоха 16/30 | TrainLoss 0.1680 | ValLoss 1.6457 | Acc 0.1750 | Prec 0.8293 | AUC 0.5261 | F1 0.1862 | Δparam 1.075683e-03 | skipped 0\n",
      "Эпоха 17/30 | TrainLoss 0.1653 | ValLoss 1.6222 | Acc 0.1875 | Prec 0.8297 | AUC 0.5983 | F1 0.2068 | Δparam 1.075317e-03 | skipped 0\n",
      "Эпоха 18/30 | TrainLoss 0.1836 | ValLoss 1.5671 | Acc 0.1875 | Prec 0.8287 | AUC 0.5736 | F1 0.2054 | Δparam 8.384927e-04 | skipped 0\n",
      "Эпоха 19/30 | TrainLoss 0.1844 | ValLoss 1.5568 | Acc 0.1750 | Prec 0.8290 | AUC 0.5426 | F1 0.1858 | Δparam 7.984926e-04 | skipped 0\n",
      "Эпоха 20/30 | TrainLoss 0.1790 | ValLoss 1.5463 | Acc 0.1875 | Prec 0.8287 | AUC 0.5207 | F1 0.2054 | Δparam 9.147812e-04 | skipped 0\n",
      "Эпоха 21/30 | TrainLoss 0.1229 | ValLoss 1.5784 | Acc 0.1875 | Prec 0.8290 | AUC 0.5281 | F1 0.2059 | Δparam 6.070399e-04 | skipped 0\n",
      "Эпоха 22/30 | TrainLoss 0.1387 | ValLoss 1.6368 | Acc 0.1875 | Prec 0.8287 | AUC 0.5622 | F1 0.2054 | Δparam 6.802182e-04 | skipped 0\n",
      "Эпоха 23/30 | TrainLoss 0.1328 | ValLoss 1.7046 | Acc 0.1875 | Prec 0.8281 | AUC 0.5951 | F1 0.2201 | Δparam 5.942014e-04 | skipped 0\n",
      "Эпоха 24/30 | TrainLoss 0.1402 | ValLoss 1.5690 | Acc 0.2250 | Prec 0.8284 | AUC 0.6180 | F1 0.2755 | Δparam 9.484959e-04 | skipped 0\n",
      "Эпоха 25/30 | TrainLoss 0.1532 | ValLoss 1.5835 | Acc 0.2375 | Prec 0.8300 | AUC 0.6099 | F1 0.2939 | Δparam 7.655580e-04 | skipped 0\n",
      "Эпоха 26/30 | TrainLoss 0.1311 | ValLoss 1.4335 | Acc 0.2625 | Prec 0.8297 | AUC 0.5879 | F1 0.3167 | Δparam 8.603780e-04 | skipped 0\n",
      "Эпоха 27/30 | TrainLoss 0.1757 | ValLoss 1.5168 | Acc 0.2625 | Prec 0.8304 | AUC 0.5577 | F1 0.3176 | Δparam 6.013251e-04 | skipped 0\n",
      "Эпоха 28/30 | TrainLoss 0.1658 | ValLoss 1.5020 | Acc 0.2625 | Prec 0.8300 | AUC 0.5989 | F1 0.3171 | Δparam 6.080848e-04 | skipped 0\n",
      "Эпоха 29/30 | TrainLoss 0.1488 | ValLoss 1.6005 | Acc 0.2625 | Prec 0.8300 | AUC 0.6022 | F1 0.3171 | Δparam 5.814480e-04 | skipped 0\n",
      "Эпоха 30/30 | TrainLoss 0.1452 | ValLoss 1.6112 | Acc 0.2375 | Prec 0.8297 | AUC 0.5825 | F1 0.2819 | Δparam 5.724034e-04 | skipped 0\n",
      "Лучший валид. Accuracy: 0.2625\n",
      "[HISTORY GRU - sampler] Последние строки:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9c216e58-6b33-47d5-a110-f43f5adbe7af",
       "rows": [
        [
         "25",
         "26",
         "0.13109083045018863",
         "1.4335286140441894",
         "0.2625",
         "0.8296568627450981",
         "0.5878869047619047",
         "0.3166632081344677",
         "0.0008603779715485871",
         "0",
         "1.8648508261938237",
         "0"
        ],
        [
         "26",
         "27",
         "0.17565212511036493",
         "1.5168048858642578",
         "0.2625",
         "0.8303571428571429",
         "0.5577023809523809",
         "0.31763570049345635",
         "0.0006013251258991659",
         "0",
         "2.2387235074941265",
         "0"
        ],
        [
         "27",
         "28",
         "0.16579599760166586",
         "1.5019959688186646",
         "0.2625",
         "0.8300000000000001",
         "0.5989404761904762",
         "0.31714135021097045",
         "0.0006080848397687078",
         "0",
         "1.7383151562198211",
         "0"
        ],
        [
         "28",
         "29",
         "0.14877663304621022",
         "1.6005038022994995",
         "0.2625",
         "0.8300000000000001",
         "0.6021904761904763",
         "0.31714135021097045",
         "0.0005814479663968086",
         "0",
         "1.599913822609539",
         "0"
        ],
        [
         "29",
         "30",
         "0.1452398181778111",
         "1.6111833810806275",
         "0.2375",
         "0.8296568627450981",
         "0.5824999999999999",
         "0.2819352778369172",
         "0.0005724034272134304",
         "0",
         "1.078682407369151",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.131091</td>\n",
       "      <td>1.433529</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.829657</td>\n",
       "      <td>0.587887</td>\n",
       "      <td>0.316663</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0</td>\n",
       "      <td>1.864851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.175652</td>\n",
       "      <td>1.516805</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.557702</td>\n",
       "      <td>0.317636</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0</td>\n",
       "      <td>2.238724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.165796</td>\n",
       "      <td>1.501996</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0</td>\n",
       "      <td>1.738315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.148777</td>\n",
       "      <td>1.600504</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.602190</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0</td>\n",
       "      <td>1.599914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.145240</td>\n",
       "      <td>1.611183</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.829657</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.281935</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0</td>\n",
       "      <td>1.078682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "25     26    0.131091  1.433529   0.2625  0.829657  0.587887  0.316663              0.000860                0        1.864851                  0\n",
       "26     27    0.175652  1.516805   0.2625  0.830357  0.557702  0.317636              0.000601                0        2.238724                  0\n",
       "27     28    0.165796  1.501996   0.2625  0.830000  0.598940  0.317141              0.000608                0        1.738315                  0\n",
       "28     29    0.148777  1.600504   0.2625  0.830000  0.602190  0.317141              0.000581                0        1.599914                  0\n",
       "29     30    0.145240  1.611183   0.2375  0.829657  0.582500  0.281935              0.000572                0        1.078682                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] SimpleGRU - Val Acc: 0.2625 | Val F1: 0.3167 | Val AUC: 0.5879\n"
     ]
    }
   ],
   "source": [
    "model_gru = SimpleGRU(n_rois=R, hidden=64, num_layers=1, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_gru = f\"{CHECKPOINT_DIR}/SimpleGRU_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_gru, exist_ok=True)\n",
    "\n",
    "print('\\n=== SimpleGRU: балансировка sampler ===')\n",
    "if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_gru, 'best_model.pth')):\n",
    "    history_gru = train_model(\n",
    "        model_gru, train_dl, val_dl, cls_counts, DEVICE,\n",
    "        epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_gru,\n",
    "        lr=LR, weight_decay=WEIGHT_DECAY, debug=False,\n",
    "        early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    "    )\n",
    "    hist_gru_df = pd.DataFrame(history_gru)\n",
    "    print('[HISTORY GRU - sampler] Последние строки:')\n",
    "    display(hist_gru_df.tail())\n",
    "else:\n",
    "    model_gru.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_gru, 'best_model.pth')))\n",
    "    print(\"Загружен существующий чекпоинт SimpleGRU.\")\n",
    "\n",
    "model_gru.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_gru, 'best_model.pth')))\n",
    "model_gru.eval()\n",
    "val_loss_gru, val_acc_gru, val_prec_gru, val_auc_gru, val_f1_gru = Trainer(model_gru, train_dl, val_dl, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] SimpleGRU - Val Acc: {val_acc_gru:.4f} | Val F1: {val_f1_gru:.4f} | Val AUC: {val_auc_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002cb25e",
   "metadata": {},
   "source": [
    "### Обучение Simple MLP (по усреднённым признакам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920fedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported DATA_MODE for model training.\n"
     ]
    }
   ],
   "source": [
    "if DATA_MODE not in ('SEQ_NPY','SEQ_TSV'):\n",
    "    mlp_model = SimpleMLP(in_dim=in_dim, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "    # Создадим директорию для чекпоинтов\n",
    "    checkpoint_dir_path_mlp = f\"{CHECKPOINT_DIR}/SimpleMLP\"\n",
    "    os.makedirs(checkpoint_dir_path_mlp, exist_ok=True)\n",
    "    # Запустим обучение модели, если не нужно переиспользовать существующую\n",
    "    if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')):\n",
    "        train_model(mlp_model, train_dl, val_dl, cls_counts, DEVICE, epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_mlp, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    else:\n",
    "        mlp_model.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')))\n",
    "        print(\"Загружен существующий чекпоинт SimpleMLP.\")\n",
    "    # Статистика обучения SimpleMLP\n",
    "    val_loss_mlp, val_acc_mlp, val_prec_mlp, val_auc_mlp, val_f1_mlp = Trainer(mlp_model, train_dl, val_dl, cls_counts, DEVICE).evaluate()\n",
    "    print(f\"SimpleMLP - Val Acc: {val_acc_mlp:.4f} | Val F1: {val_f1_mlp:.4f} | Val AUC: {val_auc_mlp:.4f}\")\n",
    "    # Лучшая модель SimpleMLP:\n",
    "    print(\"Лучшая модель SimpleMLP:\")\n",
    "    mlp_model.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_mlp, 'best_model.pth')))\n",
    "    mlp_model.eval()\n",
    "    val_loss_mlp, val_acc_mlp, val_prec_mlp, val_auc_mlp, val_f1_mlp = Trainer(mlp_model, train_dl, val_dl, cls_counts, DEVICE).evaluate()\n",
    "    print(f\"Лучшая модель SimpleMLP - Val Acc: {val_acc_mlp:.4f} | Val F1: {val_f1_mlp:.4f} | Val AUC: {val_auc_mlp:.4f}\")\n",
    "else:\n",
    "    print(\"Unsupported DATA_MODE for model training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3832d",
   "metadata": {},
   "source": [
    "### Обучение модели ROISequenceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eed1f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ROISequenceNet: балансировка sampler ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/30 | TrainLoss 1.1461 | ValLoss 2.8516 | Acc 0.0000 | Prec 0.0000 | AUC 0.3934 | F1 0.0000 | Δparam 5.468754e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2/30 | TrainLoss 0.6155 | ValLoss 1.7138 | Acc 0.0625 | Prec 0.0042 | AUC 0.4057 | F1 0.0078 | Δparam 3.463998e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3/30 | TrainLoss 0.2996 | ValLoss 1.9652 | Acc 0.1250 | Prec 0.0164 | AUC 0.4280 | F1 0.0291 | Δparam 2.090411e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4/30 | TrainLoss 0.2624 | ValLoss 1.4904 | Acc 0.1250 | Prec 0.0164 | AUC 0.4931 | F1 0.0291 | Δparam 1.727767e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5/30 | TrainLoss 0.2027 | ValLoss 1.3498 | Acc 0.1000 | Prec 0.0188 | AUC 0.5608 | F1 0.0316 | Δparam 1.616570e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6/30 | TrainLoss 0.2040 | ValLoss 1.8010 | Acc 0.1250 | Prec 0.0164 | AUC 0.5268 | F1 0.0291 | Δparam 2.204247e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7/30 | TrainLoss 0.1680 | ValLoss 1.6172 | Acc 0.1250 | Prec 0.0164 | AUC 0.4800 | F1 0.0291 | Δparam 1.597142e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8/30 | TrainLoss 0.1513 | ValLoss 1.9062 | Acc 0.0625 | Prec 0.0154 | AUC 0.5129 | F1 0.0237 | Δparam 1.329584e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9/30 | TrainLoss 0.1067 | ValLoss 2.1610 | Acc 0.2625 | Prec 0.7364 | AUC 0.5900 | F1 0.3251 | Δparam 1.252675e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10/30 | TrainLoss 0.2357 | ValLoss 1.7500 | Acc 0.0875 | Prec 0.0156 | AUC 0.4774 | F1 0.0262 | Δparam 1.846032e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11/30 | TrainLoss 0.1074 | ValLoss 1.5836 | Acc 0.1125 | Prec 0.8314 | AUC 0.3353 | F1 0.0563 | Δparam 9.625214e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12/30 | TrainLoss 0.0725 | ValLoss 1.5230 | Acc 0.2000 | Prec 0.5872 | AUC 0.3800 | F1 0.1834 | Δparam 7.488637e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13/30 | TrainLoss 0.1108 | ValLoss 1.1987 | Acc 0.2250 | Prec 0.6101 | AUC 0.4514 | F1 0.2044 | Δparam 1.225887e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14/30 | TrainLoss 0.1100 | ValLoss 2.2292 | Acc 0.1125 | Prec 0.6665 | AUC 0.5544 | F1 0.1162 | Δparam 1.412973e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15/30 | TrainLoss 0.0830 | ValLoss 2.7774 | Acc 0.2125 | Prec 0.7121 | AUC 0.5753 | F1 0.2646 | Δparam 1.134789e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16/30 | TrainLoss 0.1055 | ValLoss 1.6534 | Acc 0.3125 | Prec 0.6328 | AUC 0.4760 | F1 0.3685 | Δparam 1.312969e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 17/30 | TrainLoss 0.1331 | ValLoss 1.7967 | Acc 0.2125 | Prec 0.7691 | AUC 0.5669 | F1 0.2433 | Δparam 1.327409e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 18/30 | TrainLoss 0.0776 | ValLoss 2.1251 | Acc 0.2625 | Prec 0.6787 | AUC 0.5573 | F1 0.3377 | Δparam 8.508945e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 19/30 | TrainLoss 0.0423 | ValLoss 1.5869 | Acc 0.6125 | Prec 0.7320 | AUC 0.5566 | F1 0.6587 | Δparam 6.566853e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 20/30 | TrainLoss 0.0242 | ValLoss 1.9316 | Acc 0.6125 | Prec 0.7163 | AUC 0.5991 | F1 0.6541 | Δparam 5.880420e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 21/30 | TrainLoss 0.0287 | ValLoss 1.9676 | Acc 0.6375 | Prec 0.6814 | AUC 0.5393 | F1 0.6578 | Δparam 7.491923e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 22/30 | TrainLoss 0.0214 | ValLoss 1.9285 | Acc 0.6375 | Prec 0.6487 | AUC 0.5823 | F1 0.6430 | Δparam 7.940471e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 23/30 | TrainLoss 0.0264 | ValLoss 1.5554 | Acc 0.6500 | Prec 0.6666 | AUC 0.4005 | F1 0.6580 | Δparam 1.083799e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 24/30 | TrainLoss 0.1178 | ValLoss 1.7551 | Acc 0.5875 | Prec 0.6650 | AUC 0.5098 | F1 0.6173 | Δparam 2.066013e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 25/30 | TrainLoss 0.0545 | ValLoss 1.9562 | Acc 0.5875 | Prec 0.6830 | AUC 0.4933 | F1 0.6317 | Δparam 1.418925e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 26/30 | TrainLoss 0.0993 | ValLoss 3.0182 | Acc 0.4625 | Prec 0.7521 | AUC 0.5584 | F1 0.5484 | Δparam 1.635822e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 27/30 | TrainLoss 0.0214 | ValLoss 2.7528 | Acc 0.5625 | Prec 0.6887 | AUC 0.5608 | F1 0.6042 | Δparam 1.145018e-03 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 28/30 | TrainLoss 0.0480 | ValLoss 1.1235 | Acc 0.7750 | Prec 0.6921 | AUC 0.4678 | F1 0.7259 | Δparam 8.836609e-04 | skipped 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 29/30 | TrainLoss 0.0145 | ValLoss 1.6380 | Acc 0.6750 | Prec 0.6869 | AUC 0.5083 | F1 0.6757 | Δparam 6.208404e-04 | skipped 0\n",
      "Эпоха 30/30 | TrainLoss 0.0204 | ValLoss 1.5260 | Acc 0.6625 | Prec 0.6802 | AUC 0.5149 | F1 0.6698 | Δparam 6.988682e-04 | skipped 0\n",
      "Лучший валид. Accuracy: 0.775\n",
      "[HISTORY ROISequenceNet - sampler] Последние строки:\n",
      "Эпоха 30/30 | TrainLoss 0.0204 | ValLoss 1.5260 | Acc 0.6625 | Prec 0.6802 | AUC 0.5149 | F1 0.6698 | Δparam 6.988682e-04 | skipped 0\n",
      "Лучший валид. Accuracy: 0.775\n",
      "[HISTORY ROISequenceNet - sampler] Последние строки:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "20f30aa3-71a9-4eee-be79-f095fbcc68e0",
       "rows": [
        [
         "25",
         "26",
         "0.09934275811665678",
         "3.018150734901428",
         "0.4625",
         "0.752066464237517",
         "0.5583809523809523",
         "0.5483845644646616",
         "0.001635821769014001",
         "0",
         "4.800781402849105",
         "0"
        ],
        [
         "26",
         "27",
         "0.021441950160955806",
         "2.7527586698532103",
         "0.5625",
         "0.68875",
         "0.5608214285714286",
         "0.6041925465838509",
         "0.0011450183810666203",
         "0",
         "1.965877740038584",
         "0"
        ],
        [
         "27",
         "28",
         "0.04801597391982397",
         "1.1235284775495529",
         "0.775",
         "0.6920833333333334",
         "0.46782142857142867",
         "0.7258928571428572",
         "0.0008836608612909913",
         "0",
         "2.8938542730015313",
         "0"
        ],
        [
         "28",
         "29",
         "0.014548906149049226",
         "1.6380085468292236",
         "0.675",
         "0.6869318181818181",
         "0.5082857142857143",
         "0.6756696428571429",
         "0.0006208403501659632",
         "0",
         "1.1641234074137237",
         "0"
        ],
        [
         "29",
         "30",
         "0.020376682902242964",
         "1.5259578943252563",
         "0.6625",
         "0.6802419354838709",
         "0.5148571428571428",
         "0.6697637795275591",
         "0.0006988682434894145",
         "0",
         "1.6966782680732486",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.099343</td>\n",
       "      <td>3.018151</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.558381</td>\n",
       "      <td>0.548385</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0</td>\n",
       "      <td>4.800781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>2.752759</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.688750</td>\n",
       "      <td>0.560821</td>\n",
       "      <td>0.604193</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0</td>\n",
       "      <td>1.965878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.048016</td>\n",
       "      <td>1.123528</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.692083</td>\n",
       "      <td>0.467821</td>\n",
       "      <td>0.725893</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0</td>\n",
       "      <td>2.893854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>1.638009</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.686932</td>\n",
       "      <td>0.508286</td>\n",
       "      <td>0.675670</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0</td>\n",
       "      <td>1.164123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.525958</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.680242</td>\n",
       "      <td>0.514857</td>\n",
       "      <td>0.669764</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0</td>\n",
       "      <td>1.696678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "25     26    0.099343  3.018151   0.4625  0.752066  0.558381  0.548385              0.001636                0        4.800781                  0\n",
       "26     27    0.021442  2.752759   0.5625  0.688750  0.560821  0.604193              0.001145                0        1.965878                  0\n",
       "27     28    0.048016  1.123528   0.7750  0.692083  0.467821  0.725893              0.000884                0        2.893854                  0\n",
       "28     29    0.014549  1.638009   0.6750  0.686932  0.508286  0.675670              0.000621                0        1.164123                  0\n",
       "29     30    0.020377  1.525958   0.6625  0.680242  0.514857  0.669764              0.000699                0        1.696678                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Sampler] ROISequenceNet - Val Acc: 0.7750 | Val F1: 0.7259 | Val AUC: 0.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_roi_seq_net = ROISequenceNet(n_roi=R, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net = f\"{CHECKPOINT_DIR}/ROISequenceNet_sampler\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net, exist_ok=True)\n",
    "\n",
    "print('\\n=== ROISequenceNet: балансировка sampler ===')\n",
    "if not REUSE_MODELS or not os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net, 'best_model.pth')):\n",
    "    history_roi_seq = train_model(\n",
    "        model_roi_seq_net, train_dl, val_dl, cls_counts, DEVICE,\n",
    "        epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net,\n",
    "        lr=LR, weight_decay=WEIGHT_DECAY, debug=False,\n",
    "        early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    "    )\n",
    "    hist_roi_seq_df = pd.DataFrame(history_roi_seq)\n",
    "    print('[HISTORY ROISequenceNet - sampler] Последние строки:')\n",
    "    display(hist_roi_seq_df.tail())\n",
    "else:\n",
    "    model_roi_seq_net.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net, 'best_model.pth')))\n",
    "    print(\"Загружен существующий чекпоинт ROISequenceNet.\")\n",
    "\n",
    "model_roi_seq_net.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net, 'best_model.pth')))\n",
    "model_roi_seq_net.eval()\n",
    "val_loss_roi_seq_net, val_acc_roi_seq_net, val_prec_roi_seq_net, val_auc_roi_seq_net, val_f1_roi_seq_net = Trainer(model_roi_seq_net, train_dl, val_dl, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@Sampler] ROISequenceNet - Val Acc: {val_acc_roi_seq_net:.4f} | Val F1: {val_f1_roi_seq_net:.4f} | Val AUC: {val_auc_roi_seq_net:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36f5b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ROISequenceNet: альтернативный прогон с oversample =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/30 | TrainLoss 1.0388 | ValLoss 1.9473 | Acc 0.0000 | Prec 0.0000 | AUC 0.4473 | F1 0.0000 | Δparam 8.044878e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.4640/0.8891/3.0268; GradNorm[mean]: 9.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2/30 | TrainLoss 0.3285 | ValLoss 1.3587 | Acc 0.1250 | Prec 0.0158 | AUC 0.5733 | F1 0.0281 | Δparam 4.754629e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1058/0.3136/0.6692; GradNorm[mean]: 4.1872\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3/30 | TrainLoss 0.3024 | ValLoss 1.4076 | Acc 0.0625 | Prec 0.0042 | AUC 0.5420 | F1 0.0079 | Δparam 2.742442e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0871/0.2917/0.7063; GradNorm[mean]: 2.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4/30 | TrainLoss 0.2920 | ValLoss 1.9403 | Acc 0.0625 | Prec 0.0039 | AUC 0.5512 | F1 0.0074 | Δparam 1.346560e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0828/0.2591/0.6982; GradNorm[mean]: 1.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5/30 | TrainLoss 0.2715 | ValLoss 1.6919 | Acc 0.1250 | Prec 0.0156 | AUC 0.5231 | F1 0.0278 | Δparam 1.101067e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1105/0.2281/0.9622; GradNorm[mean]: 1.4260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6/30 | TrainLoss 0.2650 | ValLoss 1.5458 | Acc 0.1250 | Prec 0.0156 | AUC 0.5169 | F1 0.0278 | Δparam 1.000979e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0845/0.2454/0.6802; GradNorm[mean]: 1.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7/30 | TrainLoss 0.2653 | ValLoss 1.6420 | Acc 0.1375 | Prec 0.0240 | AUC 0.5271 | F1 0.0407 | Δparam 8.910536e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0746/0.2498/0.9224; GradNorm[mean]: 1.3992\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8/30 | TrainLoss 0.2679 | ValLoss 1.8788 | Acc 0.1250 | Prec 0.0156 | AUC 0.5167 | F1 0.0278 | Δparam 1.159282e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1042/0.2305/0.6382; GradNorm[mean]: 1.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9/30 | TrainLoss 0.1868 | ValLoss 1.7250 | Acc 0.0875 | Prec 0.0204 | AUC 0.3962 | F1 0.0318 | Δparam 2.981419e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0451/0.1737/0.3485; GradNorm[mean]: 2.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10/30 | TrainLoss 0.1106 | ValLoss 2.3125 | Acc 0.1000 | Prec 0.0220 | AUC 0.4980 | F1 0.0360 | Δparam 3.502653e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0217/0.0880/0.5082; GradNorm[mean]: 3.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11/30 | TrainLoss 0.1799 | ValLoss 1.8606 | Acc 0.4875 | Prec 0.6418 | AUC 0.4578 | F1 0.5494 | Δparam 3.426792e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0137/0.0662/3.7984; GradNorm[mean]: 4.2353\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12/30 | TrainLoss 0.1271 | ValLoss 2.9724 | Acc 0.0875 | Prec 0.4259 | AUC 0.3986 | F1 0.0509 | Δparam 4.934181e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0190/0.0954/0.7395; GradNorm[mean]: 4.3799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13/30 | TrainLoss 0.0727 | ValLoss 2.0427 | Acc 0.3250 | Prec 0.6288 | AUC 0.3911 | F1 0.4195 | Δparam 1.670412e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0114/0.0593/0.3200; GradNorm[mean]: 1.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14/30 | TrainLoss 0.0457 | ValLoss 2.1125 | Acc 0.5000 | Prec 0.6451 | AUC 0.3840 | F1 0.5630 | Δparam 1.306890e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0051/0.0381/0.1689; GradNorm[mean]: 1.4289\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15/30 | TrainLoss 0.0209 | ValLoss 2.1325 | Acc 0.6625 | Prec 0.6527 | AUC 0.4777 | F1 0.6575 | Δparam 1.366111e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0027/0.0147/0.0767; GradNorm[mean]: 1.2493\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16/30 | TrainLoss 0.0535 | ValLoss 1.9804 | Acc 0.5750 | Prec 0.6727 | AUC 0.4400 | F1 0.6172 | Δparam 2.497195e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0005/0.0420/0.2220; GradNorm[mean]: 3.5627\n",
      "Эпоха 17/30 | TrainLoss 0.0235 | ValLoss 2.0257 | Acc 0.6500 | Prec 0.6583 | AUC 0.4730 | F1 0.6531 | Δparam 1.347335e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0134/0.1160; GradNorm[mean]: 1.2067\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.3587).\n",
      "Лучший валид. Accuracy: 0.6625\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n",
      "Эпоха 17/30 | TrainLoss 0.0235 | ValLoss 2.0257 | Acc 0.6500 | Prec 0.6583 | AUC 0.4730 | F1 0.6531 | Δparam 1.347335e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0022/0.0134/0.1160; GradNorm[mean]: 1.2067\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.3587).\n",
      "Лучший валид. Accuracy: 0.6625\n",
      "\n",
      "[HISTORY - oversample] Последние строки:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "de98a644-b2d2-456b-8dc7-cca29040ced9",
       "rows": [
        [
         "12",
         "13",
         "0.07270205026978384",
         "2.0426602125167848",
         "0.325",
         "0.6287565331010454",
         "0.39107142857142857",
         "0.4194851293273921",
         "0.001670412253588438",
         "0",
         "1.7604241913034595",
         "0"
        ],
        [
         "13",
         "14",
         "0.04566897969166546",
         "2.1124818563461303",
         "0.5",
         "0.6451136363636364",
         "0.3840238095238096",
         "0.562991718426501",
         "0.0013068903936073184",
         "0",
         "1.428937201882231",
         "0"
        ],
        [
         "14",
         "15",
         "0.020900150725577514",
         "2.1324867963790894",
         "0.6625",
         "0.6526515151515151",
         "0.4776904761904762",
         "0.6575381679389313",
         "0.0013661106349900365",
         "0",
         "1.2492665616716452",
         "0"
        ],
        [
         "15",
         "16",
         "0.053540049381452896",
         "1.9804163068532943",
         "0.575",
         "0.6726973684210527",
         "0.4400476190476191",
         "0.6172423887587823",
         "0.0024971954990178347",
         "0",
         "3.5626960296333734",
         "0"
        ],
        [
         "16",
         "17",
         "0.02349163399523367",
         "2.0256691828370093",
         "0.65",
         "0.6583333333333333",
         "0.47297619047619044",
         "0.653125",
         "0.0013473345898091793",
         "0",
         "1.2067349442088446",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.072702</td>\n",
       "      <td>2.042660</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.628757</td>\n",
       "      <td>0.391071</td>\n",
       "      <td>0.419485</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.760424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>2.112482</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.645114</td>\n",
       "      <td>0.384024</td>\n",
       "      <td>0.562992</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>2.132487</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.652652</td>\n",
       "      <td>0.477690</td>\n",
       "      <td>0.657538</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0</td>\n",
       "      <td>1.249267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.053540</td>\n",
       "      <td>1.980416</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.672697</td>\n",
       "      <td>0.440048</td>\n",
       "      <td>0.617242</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0</td>\n",
       "      <td>3.562696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>2.025669</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.472976</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "12     13    0.072702  2.042660   0.3250  0.628757  0.391071  0.419485              0.001670                0        1.760424                  0\n",
       "13     14    0.045669  2.112482   0.5000  0.645114  0.384024  0.562992              0.001307                0        1.428937                  0\n",
       "14     15    0.020900  2.132487   0.6625  0.652652  0.477690  0.657538              0.001366                0        1.249267                  0\n",
       "15     16    0.053540  1.980416   0.5750  0.672697  0.440048  0.617242              0.002497                0        3.562696                  0\n",
       "16     17    0.023492  2.025669   0.6500  0.658333  0.472976  0.653125              0.001347                0        1.206735                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@Oversample] ROISequenceNet - Val Acc: 0.6625 | Val F1: 0.6575 | Val AUC: 0.4777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Альтернативный прогон ROISequenceNet с oversample стратегией\n",
    "BALANCE_STRATEGY = 'oversample'\n",
    "print('\\n===== ROISequenceNet: альтернативный прогон с oversample =====')\n",
    "train_dl_over, val_dl_over = make_fold_dataloaders(data_df, fold_idx=0, mode=DATA_MODE, cov_pipeline=pre)\n",
    "model_roi_seq_net_over = ROISequenceNet(n_roi=R, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net_over = f\"{CHECKPOINT_DIR}/ROISequenceNet_oversample\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net_over, exist_ok=True)\n",
    "history_roi_seq_oversample = train_model(\n",
    "    model_roi_seq_net_over, train_dl_over, val_dl_over, cls_counts, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net_over,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "hist_roi_seq_oversample_df = pd.DataFrame(history_roi_seq_oversample)\n",
    "print('\\n[HISTORY - oversample] Последние строки:')\n",
    "display(hist_roi_seq_oversample_df.tail())\n",
    "\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'best_model.pth')):\n",
    "    model_roi_seq_net_over.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'best_model.pth')))\n",
    "model_roi_seq_net_over.eval()\n",
    "val_loss_roi_seq_o, val_acc_roi_seq_o, val_prec_roi_seq_o, val_auc_roi_seq_o, val_f1_roi_seq_o = Trainer(model_roi_seq_net_over, train_dl_over, val_dl_over, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@Oversample] ROISequenceNet - Val Acc: {val_acc_roi_seq_o:.4f} | Val F1: {val_f1_roi_seq_o:.4f} | Val AUC: {val_auc_roi_seq_o:.4f}\")\n",
    "\n",
    "BALANCE_STRATEGY = 'sampler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9d27cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ROISequenceNet: альтернативный прогон без балансировки классов =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/30 | TrainLoss 0.9357 | ValLoss 2.9785 | Acc 0.0000 | Prec 0.0000 | AUC 0.4160 | F1 0.0000 | Δparam 5.599746e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.4279/0.8359/1.9797; GradNorm[mean]: 11.4881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2/30 | TrainLoss 0.9432 | ValLoss 3.2083 | Acc 0.0000 | Prec 0.0000 | AUC 0.4239 | F1 0.0000 | Δparam 3.263781e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.4487/0.8098/1.6737; GradNorm[mean]: 9.4479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3/30 | TrainLoss 0.4134 | ValLoss 2.0837 | Acc 0.1250 | Prec 0.0156 | AUC 0.6210 | F1 0.0278 | Δparam 3.226618e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0724/0.3270/1.2255; GradNorm[mean]: 4.6043\n",
      "  ↳ saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4/30 | TrainLoss 0.3441 | ValLoss 1.3374 | Acc 0.1250 | Prec 0.0160 | AUC 0.5337 | F1 0.0284 | Δparam 1.695089e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0506/0.3805/0.6504; GradNorm[mean]: 3.3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5/30 | TrainLoss 0.2475 | ValLoss 2.3130 | Acc 0.1250 | Prec 0.0156 | AUC 0.5787 | F1 0.0278 | Δparam 1.635481e-03 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1081/0.2154/1.2314; GradNorm[mean]: 1.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6/30 | TrainLoss 0.2395 | ValLoss 1.8359 | Acc 0.1250 | Prec 0.0156 | AUC 0.5752 | F1 0.0278 | Δparam 9.424402e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1091/0.1986/0.6109; GradNorm[mean]: 1.4178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7/30 | TrainLoss 0.2546 | ValLoss 1.6660 | Acc 0.1250 | Prec 0.0156 | AUC 0.5817 | F1 0.0278 | Δparam 7.752898e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0942/0.2552/0.4511; GradNorm[mean]: 1.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8/30 | TrainLoss 0.2715 | ValLoss 1.7970 | Acc 0.1250 | Prec 0.0156 | AUC 0.5746 | F1 0.0278 | Δparam 7.048933e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0916/0.2286/0.9068; GradNorm[mean]: 1.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9/30 | TrainLoss 0.3133 | ValLoss 1.8392 | Acc 0.1250 | Prec 0.0156 | AUC 0.5707 | F1 0.0278 | Δparam 6.397657e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0916/0.2807/0.6526; GradNorm[mean]: 1.7684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10/30 | TrainLoss 0.2586 | ValLoss 1.7141 | Acc 0.0625 | Prec 0.0039 | AUC 0.5610 | F1 0.0074 | Δparam 5.699871e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0500/0.2531/0.9355; GradNorm[mean]: 1.8836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11/30 | TrainLoss 0.3381 | ValLoss 1.8199 | Acc 0.0625 | Prec 0.0039 | AUC 0.5542 | F1 0.0074 | Δparam 5.578675e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0913/0.2586/0.6991; GradNorm[mean]: 1.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12/30 | TrainLoss 0.2885 | ValLoss 1.4278 | Acc 0.1250 | Prec 0.0156 | AUC 0.5520 | F1 0.0278 | Δparam 5.274520e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1077/0.2336/1.5138; GradNorm[mean]: 1.8017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13/30 | TrainLoss 0.3160 | ValLoss 1.6095 | Acc 0.0625 | Prec 0.0039 | AUC 0.5362 | F1 0.0074 | Δparam 5.397318e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1120/0.2499/1.0415; GradNorm[mean]: 1.2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14/30 | TrainLoss 0.2604 | ValLoss 1.6450 | Acc 0.1250 | Prec 0.0156 | AUC 0.5479 | F1 0.0278 | Δparam 4.439368e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0547/0.1965/0.9423; GradNorm[mean]: 0.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15/30 | TrainLoss 0.2404 | ValLoss 1.6651 | Acc 0.1250 | Prec 0.0156 | AUC 0.5392 | F1 0.0278 | Δparam 4.202629e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1075/0.1980/0.9491; GradNorm[mean]: 1.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16/30 | TrainLoss 0.2692 | ValLoss 1.7127 | Acc 0.1250 | Prec 0.0156 | AUC 0.5339 | F1 0.0278 | Δparam 4.188913e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0999/0.2322/0.6451; GradNorm[mean]: 1.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 17/30 | TrainLoss 0.2422 | ValLoss 1.7893 | Acc 0.0625 | Prec 0.0039 | AUC 0.5456 | F1 0.0074 | Δparam 3.823441e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.0259/0.2275/0.4503; GradNorm[mean]: 1.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 18/30 | TrainLoss 0.2258 | ValLoss 1.5433 | Acc 0.1250 | Prec 0.0156 | AUC 0.5354 | F1 0.0278 | Δparam 3.817051e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1487/0.2087/0.4111; GradNorm[mean]: 1.1054\n",
      "Эпоха 19/30 | TrainLoss 0.2371 | ValLoss 1.9614 | Acc 0.1250 | Prec 0.0156 | AUC 0.5375 | F1 0.0278 | Δparam 4.070838e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1375/0.2241/0.7561; GradNorm[mean]: 1.1424\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.3374).\n",
      "Лучший валид. Accuracy: 0.125\n",
      "\n",
      "[HISTORY - no balance] Последние строки:\n",
      "Эпоха 19/30 | TrainLoss 0.2371 | ValLoss 1.9614 | Acc 0.1250 | Prec 0.0156 | AUC 0.5375 | F1 0.0278 | Δparam 4.070838e-04 | skipped 0\n",
      "  BatchLoss[min/median/max]: 0.1375/0.2241/0.7561; GradNorm[mean]: 1.1424\n",
      "[EARLY STOP] metric=val_loss no improve 15 epochs (best=1.3374).\n",
      "Лучший валид. Accuracy: 0.125\n",
      "\n",
      "[HISTORY - no balance] Последние строки:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_prec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "param_delta_mean_abs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skipped_batches",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_norm_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stagnation_epochs",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b589b3e7-6001-4932-981c-eae309ffe576",
       "rows": [
        [
         "14",
         "15",
         "0.24035006475775209",
         "1.6650607585906982",
         "0.125",
         "0.015625",
         "0.5391785714285715",
         "0.02777777777777778",
         "0.00042026289156638086",
         "0",
         "1.2966623024162132",
         "0"
        ],
        [
         "15",
         "16",
         "0.26921174236356393",
         "1.7127048015594482",
         "0.125",
         "0.015625",
         "0.5338690476190476",
         "0.02777777777777778",
         "0.0004188912862446159",
         "0",
         "1.2960804438781768",
         "0"
        ],
        [
         "16",
         "17",
         "0.2422097286286011",
         "1.7893173217773437",
         "0.0625",
         "0.00390625",
         "0.5456309523809525",
         "0.007352941176470588",
         "0.0003823440638370812",
         "0",
         "1.0189461566562006",
         "0"
        ],
        [
         "17",
         "18",
         "0.22581673872797456",
         "1.5433220624923707",
         "0.125",
         "0.015625",
         "0.5353690476190476",
         "0.02777777777777778",
         "0.0003817051474470645",
         "0",
         "1.105374024474954",
         "0"
        ],
        [
         "18",
         "19",
         "0.2370800302453237",
         "1.961397361755371",
         "0.125",
         "0.015625",
         "0.5375119047619048",
         "0.02777777777777778",
         "0.00040708380402065814",
         "0",
         "1.142361538536539",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>param_delta_mean_abs</th>\n",
       "      <th>skipped_batches</th>\n",
       "      <th>grad_norm_mean</th>\n",
       "      <th>stagnation_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.240350</td>\n",
       "      <td>1.665061</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.539179</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.296662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.269212</td>\n",
       "      <td>1.712705</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.533869</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0</td>\n",
       "      <td>1.296080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.242210</td>\n",
       "      <td>1.789317</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.545631</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.225817</td>\n",
       "      <td>1.543322</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.535369</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.237080</td>\n",
       "      <td>1.961397</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.537512</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_acc  val_prec   val_auc    val_f1  param_delta_mean_abs  skipped_batches  grad_norm_mean  stagnation_epochs\n",
       "14     15    0.240350  1.665061   0.1250  0.015625  0.539179  0.027778              0.000420                0        1.296662                  0\n",
       "15     16    0.269212  1.712705   0.1250  0.015625  0.533869  0.027778              0.000419                0        1.296080                  0\n",
       "16     17    0.242210  1.789317   0.0625  0.003906  0.545631  0.007353              0.000382                0        1.018946                  0\n",
       "17     18    0.225817  1.543322   0.1250  0.015625  0.535369  0.027778              0.000382                0        1.105374                  0\n",
       "18     19    0.237080  1.961397   0.1250  0.015625  0.537512  0.027778              0.000407                0        1.142362                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST@NoBalance] ROISequenceNet - Val Acc: 0.1250 | Val F1: 0.0278 | Val AUC: 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Альтернативный прогон ROISequenceNet без балансировки классов\n",
    "print('\\n===== ROISequenceNet: альтернативный прогон без балансировки классов =====')\n",
    "\n",
    "ENABLE_CLASS_BALANCE = False\n",
    "\n",
    "train_dl_nb, val_dl_nb = make_fold_dataloaders(data_df, fold_idx=0, mode=DATA_MODE, cov_pipeline=pre)\n",
    "model_roi_seq_net_nb = ROISequenceNet(n_roi=R, n_classes=N_CLASSES, cov_dim=cov_dim).to(DEVICE)\n",
    "checkpoint_dir_path_roi_seq_net_nb = f\"{CHECKPOINT_DIR}/ROISequenceNet_nobalance\"\n",
    "os.makedirs(checkpoint_dir_path_roi_seq_net_nb, exist_ok=True)\n",
    "history_roi_seq_nobalance = train_model(\n",
    "    model_roi_seq_net_nb, train_dl_nb, val_dl_nb, cls_counts, DEVICE,\n",
    "    epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_roi_seq_net_nb,\n",
    "    lr=LR, weight_decay=WEIGHT_DECAY, debug=True,\n",
    "    early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    ")\n",
    "hist_roi_seq_nobalance_df = pd.DataFrame(history_roi_seq_nobalance)\n",
    "print('\\n[HISTORY - no balance] Последние строки:')\n",
    "display(hist_roi_seq_nobalance_df.tail())\n",
    "\n",
    "if os.path.exists(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'best_model.pth')):\n",
    "    model_roi_seq_net_nb.load_state_dict(torch.load(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'best_model.pth')))\n",
    "model_roi_seq_net_nb.eval()\n",
    "val_loss_roi_seq_nb, val_acc_roi_seq_nb, val_prec_roi_seq_nb, val_auc_roi_seq_nb, val_f1_roi_seq_nb = Trainer(model_roi_seq_net_nb, train_dl_nb, val_dl_nb, cls_counts, DEVICE).evaluate()\n",
    "print(f\"[BEST@NoBalance] ROISequenceNet - Val Acc: {val_acc_roi_seq_nb:.4f} | Val F1: {val_f1_roi_seq_nb:.4f} | Val AUC: {val_auc_roi_seq_nb:.4f}\")\n",
    "\n",
    "ENABLE_CLASS_BALANCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c297aa",
   "metadata": {},
   "source": [
    "## 8) Оценка моделей на валидационном наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c449b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0, 1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1201: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3600x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сводная таблица финальных метрик:\n",
      "                       model  val_acc  val_auc    val_f1\n",
      "0         SimpleLSTM_sampler   0.4875      NaN  0.573594\n",
      "1      SimpleLSTM_oversample   0.5625      NaN  0.610539\n",
      "2          SimpleGRU_sampler   0.2500      NaN  0.292751\n",
      "3     ROISequenceNet_sampler   0.7750      NaN  0.725893\n",
      "4  ROISequenceNet_oversample   0.6625      NaN  0.657538\n",
      "5   ROISequenceNet_nobalance   0.1250      NaN  0.027778\n",
      "\n",
      "[INFO] Завершено: построение ROC (если было возможно), метрики, сохранение историй.\n"
     ]
    }
   ],
   "source": [
    "# === ROC Curves и сводные метрики (устойчиво к отсутствию oversample / других моделей) ===\n",
    "from sklearn.preprocessing import label_binarize\n",
    "try:\n",
    "    roc_curve\n",
    "except NameError:\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "try:\n",
    "    F\n",
    "except NameError:\n",
    "    import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_probs_and_labels(model, val_loader, device):\n",
    "    model.eval(); all_probs=[]; all_labels=[]\n",
    "    for batch in val_loader:\n",
    "        if len(batch)==5: X,M,C,y,_ = batch\n",
    "        elif len(batch)==4: X,M,C,y = batch\n",
    "        elif len(batch)==3: X,C,y = batch; M=None\n",
    "        else: raise ValueError(\"Unexpected batch format\")\n",
    "        X=X.to(device)\n",
    "        M = M.to(device) if M is not None else None\n",
    "        C = C.to(device) if (C is not None and C.nelement()>0) else None\n",
    "        # Унификация вызова\n",
    "        if M is None and C is None:\n",
    "            out = model(X)\n",
    "        else:\n",
    "            # поддержка аргумента z vs cov\n",
    "            try:\n",
    "                out = model(X, mask=M, cov=C)\n",
    "            except TypeError:\n",
    "                out = model(X, mask=M, z=C)\n",
    "        probs = F.softmax(out, dim=1).cpu().numpy()\n",
    "        all_probs.append(probs); all_labels.extend(y.numpy())\n",
    "    if not all_probs:\n",
    "        return np.zeros((0, N_CLASSES)), np.zeros((0,), dtype=int)\n",
    "    return np.vstack(all_probs), np.array(all_labels)\n",
    "\n",
    "classes_sorted = sorted(cls_counts.index.tolist())\n",
    "print('Classes:', classes_sorted)\n",
    "\n",
    "# --- Подготовка oversample версии LSTM при отсутствии ---\n",
    "if 'model_lstm_over' not in globals():\n",
    "    orig_strategy = BALANCE_STRATEGY\n",
    "    try:\n",
    "        BALANCE_STRATEGY = 'oversample'\n",
    "        train_dl_over, val_dl_over = make_fold_dataloaders(data_df, fold_idx=0, mode=DATA_MODE, cov_pipeline=pre)\n",
    "        model_lstm_over = SimpleLSTM(n_rois=R, n_classes=N_CLASSES, cov_dim=cov_dim, hidden=64, num_layers=1).to(DEVICE)\n",
    "        checkpoint_dir_path_lstm_over = f\"{CHECKPOINT_DIR}/SimpleLSTM_oversample\"\n",
    "        os.makedirs(checkpoint_dir_path_lstm_over, exist_ok=True)\n",
    "        history_lstm_oversample = train_model(\n",
    "            model_lstm_over, train_dl_over, val_dl_over, cls_counts, DEVICE,\n",
    "            epochs=EPOCHS, checkpoint_dir=checkpoint_dir_path_lstm_over,\n",
    "            lr=LR, weight_decay=WEIGHT_DECAY, debug=False,\n",
    "            early_metric=EARLY_STOP_METRIC, patience=EARLY_STOP_PATIENCE, min_delta=MIN_DELTA_IMPROVE\n",
    "        )\n",
    "        hist_lstm_oversample_df = pd.DataFrame(history_lstm_oversample)\n",
    "        best_path = os.path.join(checkpoint_dir_path_lstm_over, 'best_model.pth')\n",
    "        if os.path.exists(best_path):\n",
    "            model_lstm_over.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Oversample LSTM preparation failed: {e}\")\n",
    "        model_lstm_over = None\n",
    "        val_dl_over = None\n",
    "        hist_lstm_oversample_df = None\n",
    "    finally:\n",
    "        BALANCE_STRATEGY = orig_strategy\n",
    "\n",
    "# --- Сбор вероятностей (только для существующих моделей) ---\n",
    "lstm_sampler_probs, lstm_sampler_labels = collect_probs_and_labels(model_lstm, val_dl, DEVICE)\n",
    "\n",
    "lstm_over_probs, lstm_over_labels = (None, None)\n",
    "if 'model_lstm_over' in globals() and model_lstm_over is not None and 'val_dl_over' in globals() and val_dl_over is not None:\n",
    "    lstm_over_probs, lstm_over_labels = collect_probs_and_labels(model_lstm_over, val_dl_over, DEVICE)\n",
    "\n",
    "gru_probs, gru_labels = (None, None)\n",
    "if 'model_gru' in globals():\n",
    "    gru_probs, gru_labels = collect_probs_and_labels(model_gru, val_dl, DEVICE)\n",
    "\n",
    "roi_probs, roi_labels = (None, None)\n",
    "if 'model_roi_seq_net' in globals():\n",
    "    roi_probs, roi_labels = collect_probs_and_labels(model_roi_seq_net, val_dl, DEVICE)\n",
    "\n",
    "roi_over_probs, roi_over_labels = (None, None)\n",
    "if 'model_roi_seq_net_over' in globals() and model_roi_seq_net_over is not None and 'val_dl_over' in globals() and val_dl_over is not None:\n",
    "    roi_over_probs, roi_over_labels = collect_probs_and_labels(model_roi_seq_net_over, val_dl_over, DEVICE)\n",
    "\n",
    "roi_nb_probs, roi_nb_labels = (None, None)\n",
    "if 'model_roi_seq_net_nb' in globals():\n",
    "    roi_nb_probs, roi_nb_labels = collect_probs_and_labels(model_roi_seq_net_nb, val_dl_nb, DEVICE)\n",
    "\n",
    "# --- Binarization helper (skip if probs is None) ---\n",
    "def binarize(labels):\n",
    "    if labels is None: return None\n",
    "    return label_binarize(labels, classes=classes_sorted)\n",
    "\n",
    "lstm_sampler_bin = binarize(lstm_sampler_labels)\n",
    "lstm_over_bin    = binarize(lstm_over_labels)\n",
    "gru_bin          = binarize(gru_labels)\n",
    "roi_bin          = binarize(roi_labels)\n",
    "roi_over_bin     = binarize(roi_over_labels)\n",
    "roi_nb_bin       = binarize(roi_nb_labels)\n",
    "\n",
    "# --- Подготовка списка для построения ROC ---\n",
    "plot_items = []\n",
    "if lstm_sampler_bin is not None:\n",
    "    plot_items.append(('SimpleLSTM (sampler)', lstm_sampler_bin, lstm_sampler_probs))\n",
    "if lstm_over_bin is not None:\n",
    "    plot_items.append(('SimpleLSTM (oversample)', lstm_over_bin, lstm_over_probs))\n",
    "if gru_bin is not None:\n",
    "    plot_items.append(('SimpleGRU (sampler)', gru_bin, gru_probs))\n",
    "if roi_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (sampler)', roi_bin, roi_probs))\n",
    "if roi_over_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (oversample)', roi_over_bin, roi_over_probs))\n",
    "if roi_nb_bin is not None:\n",
    "    plot_items.append(('ROISequenceNet (no balance)', roi_nb_bin, roi_nb_probs))\n",
    "\n",
    "if plot_items:\n",
    "    fig, axes = plt.subplots(1, len(plot_items), figsize=(6*len(plot_items), 5))\n",
    "    if len(plot_items) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (title, y_bin, probs) in zip(axes, plot_items):\n",
    "        for c_idx, c_lab in enumerate(classes_sorted):\n",
    "            try:\n",
    "                fpr, tpr, _ = roc_curve(y_bin[:, c_idx], probs[:, c_idx])\n",
    "                ax.plot(fpr, tpr, label=f'class {c_lab}')\n",
    "            except Exception:\n",
    "                pass\n",
    "        ax.set_title(f'{title} ROC')\n",
    "        ax.set_xlabel('FPR'); ax.set_ylabel('TPR'); ax.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"[INFO] Нет моделей для построения ROC.\")\n",
    "\n",
    "# --- Сводная таблица метрик ---\n",
    "summary_rows = []\n",
    "\n",
    "def add_summary(name, probs, labels):\n",
    "    if probs is None or labels is None:\n",
    "        return\n",
    "    try:\n",
    "        preds = probs.argmax(1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        try:\n",
    "            auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "        except Exception:\n",
    "            auc = float('nan')\n",
    "        f1 = f1_score(labels, preds, average='weighted')\n",
    "        summary_rows.append({'model': name, 'val_acc': acc, 'val_auc': auc, 'val_f1': f1})\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Summary failed for {name}: {e}\")\n",
    "\n",
    "add_summary('SimpleLSTM_sampler', lstm_sampler_probs, lstm_sampler_labels)\n",
    "add_summary('SimpleLSTM_oversample', lstm_over_probs, lstm_over_labels)\n",
    "add_summary('SimpleGRU_sampler', gru_probs, gru_labels)\n",
    "add_summary('ROISequenceNet_sampler', roi_probs, roi_labels)\n",
    "add_summary('ROISequenceNet_oversample', roi_over_probs, roi_over_labels)\n",
    "add_summary('ROISequenceNet_nobalance', roi_nb_probs, roi_nb_labels)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print('\\nСводная таблица финальных метрик:')\n",
    "print(summary_df if not summary_df.empty else '[EMPTY]')\n",
    "\n",
    "# --- Сохранение историй (проверка наличия) ---\n",
    "if 'hist_lstm_sampler_df' in globals():\n",
    "    hist_lstm_sampler_df.to_csv(os.path.join(checkpoint_dir_path_lstm, 'history_sampler.csv'), index=False)\n",
    "if 'hist_lstm_oversample_df' in globals() and hist_lstm_oversample_df is not None:\n",
    "    hist_lstm_oversample_df.to_csv(os.path.join(checkpoint_dir_path_lstm_over, 'history_oversample.csv'), index=False)\n",
    "if 'hist_gru_df' in globals():\n",
    "    hist_gru_df.to_csv(os.path.join(checkpoint_dir_path_gru, 'history_sampler.csv'), index=False)\n",
    "if 'hist_roi_seq_df' in globals():\n",
    "    hist_roi_seq_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net, 'history_sampler.csv'), index=False)\n",
    "if 'hist_roi_seq_oversample_df' in globals():\n",
    "    hist_roi_seq_oversample_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net_over, 'history_oversample.csv'), index=False)\n",
    "if 'hist_roi_seq_nobalance_df' in globals():\n",
    "    hist_roi_seq_nobalance_df.to_csv(os.path.join(checkpoint_dir_path_roi_seq_net_nb, 'history_nobalance.csv'), index=False)\n",
    "\n",
    "print('\\n[INFO] Завершено: построение ROC (если было возможно), метрики, сохранение историй.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Baseline A — Статический функциональный коннектом (FC) + логистическая регрессия\n",
    "Идея: из каждого временного ряда NPY `(T,R)` считаем корреляционную матрицу `R×R` (Пирсон), применяем **Фишера z** и векторизуем верхний треугольник → получаем признак фиксированной длины. \n",
    "Затем обучаем **LogisticRegression (multinomial)**, опционально предваряя **PCA** до `FC_PCA_COMPONENTS`.\n",
    "Разбиение — то же групповое (без утечек)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3480b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train N=307, val N=65; groups → train:4, val:2\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(len(data_df))\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=VAL_SIZE, random_state=SEED)\n",
    "train_idx, val_idx = next(gss.split(idx, groups=data_df['site_x'].values))\n",
    "train_df, val_df = data_df.iloc[train_idx].reset_index(drop=True), data_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"train N={len(train_df)}, val N={len(val_df)}; groups → train:{train_df['site_x'].nunique()}, val:{val_df['site_x'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FC-LogReg] val_acc=0.585 | val_auc=nan | val_f1=0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    def fisher_z(r):\n",
    "        r = np.clip(r, -0.999999, 0.999999)\n",
    "        return 0.5*np.log((1+r)/(1-r))\n",
    "\n",
    "    def vec_uppertri(M):\n",
    "        iu = np.triu_indices_from(M, k=1)\n",
    "        return M[iu]\n",
    "\n",
    "    def fc_vector_from_npy(path):\n",
    "        X = np.load(path)  # (T,R)\n",
    "        C = np.corrcoef(X, rowvar=False)\n",
    "        # Replace NaNs arising from zero-variance ROI time series\n",
    "        C = np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        np.fill_diagonal(C, 1.0)\n",
    "        Cz = fisher_z(C)\n",
    "        return vec_uppertri(Cz)\n",
    "\n",
    "    def build_fc_matrix(df):\n",
    "        feats = [fc_vector_from_npy(p) for p in df['npy_path']]\n",
    "        X = np.vstack(feats)\n",
    "        # Safety: ensure no NaNs remain\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        y = df['label'].values.astype(int)\n",
    "        return X, y\n",
    "\n",
    "    Xtr, ytr = build_fc_matrix(train_df)\n",
    "    Xva, yva = build_fc_matrix(val_df)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xtr_s = scaler.fit_transform(Xtr)\n",
    "    Xva_s = scaler.transform(Xva)\n",
    "    # Extra safety before PCA\n",
    "    if np.isnan(Xtr_s).any() or np.isnan(Xva_s).any():\n",
    "        Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    if FC_PCA_COMPONENTS and FC_PCA_COMPONENTS > 0:\n",
    "        # PCA ограничение: n_components <= min(n_samples, n_features)\n",
    "        allowable = min(Xtr_s.shape[0], Xtr_s.shape[1])\n",
    "        n_comp = min(FC_PCA_COMPONENTS, allowable)\n",
    "        if n_comp < 1:\n",
    "            print(\"Пропуск PCA: недостаточно допустимых компонент.\")\n",
    "        else:\n",
    "            if n_comp != FC_PCA_COMPONENTS:\n",
    "                print(f\"Понижено число компонент PCA с {FC_PCA_COMPONENTS} до {n_comp} (min(n_samples={Xtr_s.shape[0]}, n_features={Xtr_s.shape[1]})).\")\n",
    "            pca = PCA(n_components=n_comp)\n",
    "            Xtr_s = pca.fit_transform(Xtr_s)\n",
    "            Xva_s = pca.transform(Xva_s)\n",
    "    clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    clf.fit(Xtr_s, ytr)\n",
    "    pr_tr = clf.predict_proba(Xtr_s); pr_va = clf.predict_proba(Xva_s)\n",
    "    yh_va = pr_va.argmax(1)\n",
    "    acc = accuracy_score(yva, yh_va)\n",
    "    f1  = f1_score(yva, yh_va, average='macro')\n",
    "    try:\n",
    "        auc = roc_auc_score(yva, pr_va, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    print(f\"[FC-LogReg] val_acc={acc:.3f} | val_auc={auc:.3f} | val_f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a593284",
   "metadata": {},
   "source": [
    "## 10) Baseline B — Динамический FC + HMM-фичи (или KMeans fallback)\n",
    "Идея: скользящим окном (`WIN_DYN`, шаг `STEP_DYN`) считаем FC по каждому окну → получаем последовательность векторов (\"кадров\") на субъекта. \n",
    "На **train** обучаем `GaussianHMM(n_states=HMM_N_STATES)` по этим кадрам. Для каждого субъекта считаем признаки:\n",
    "- доля времени в каждом состоянии,\n",
    "- частота переключений,\n",
    "- средняя длительность посещений.\n",
    "Если `hmmlearn` недоступен, используем **KMeans** как приближение скрытых состояний.\n",
    "Классификатор: `LogisticRegression` на агрегированных признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffc55455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(X, win=30, step=5):\n",
    "    t, r = X.shape\n",
    "    for s in range(0, max(1, t - win + 1), step):\n",
    "        e = min(t, s + win)\n",
    "        if e - s >= max(5, win//2):\n",
    "            yield X[s:e]\n",
    "\n",
    "def fc_frames_from_npy(path, win=30, step=5):\n",
    "    X = np.load(path)\n",
    "    frames = []\n",
    "    for seg in sliding_windows(X, win, step):\n",
    "        C = np.corrcoef(seg, rowvar=False)\n",
    "        r = 0.5*np.log((1+np.clip(C, -0.999999, 0.999999))/(1-np.clip(C, -0.999999, 0.999999)))\n",
    "        iu = np.triu_indices_from(r, k=1)\n",
    "        frames.append(r[iu])\n",
    "    if not frames:\n",
    "        C = np.corrcoef(X, rowvar=False); iu = np.triu_indices_from(C, 1)\n",
    "        r = 0.5*np.log((1+np.clip(C, -0.999999, 0.999999))/(1-np.clip(C, -0.999999, 0.999999)))\n",
    "        frames = [r[iu]]\n",
    "    return np.vstack(frames)\n",
    "\n",
    "def summarize_states(states, n_states):\n",
    "    T = len(states)\n",
    "    if T == 0:\n",
    "        return np.zeros(n_states + 2)\n",
    "    frac = np.bincount(states, minlength=n_states) / max(1, T)\n",
    "    switches = (states[1:] != states[:-1]).mean() if T>1 else 0.0\n",
    "    lengths = []\n",
    "    cur = 1\n",
    "    for i in range(1, T):\n",
    "        if states[i]==states[i-1]: cur += 1\n",
    "        else: lengths.append(cur); cur = 1\n",
    "    lengths.append(cur)\n",
    "    dwell = float(np.mean(lengths))\n",
    "    return np.concatenate([frac, [switches, dwell]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a35de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DynFC] Removed 703 near-constant features before HMM/KMeans.\n",
      "[DynFC-HMM] HMM fit failed ('diag' covars must be positive) -> fallback to KMeans.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 61425 but corresponding boolean dimension is 62128",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.vstack(feats)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Строим агрегированные признаки состояний\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m Xtr = \u001b[43mbuild_dyn_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m ytr = train_df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].values.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     79\u001b[39m Xva = build_dyn_feats(va_frames)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mbuild_dyn_feats\u001b[39m\u001b[34m(frames_list)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fr \u001b[38;5;129;01min\u001b[39;00m frames_list:\n\u001b[32m     71\u001b[39m     fr_san = _apply_keep(fr)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     st = \u001b[43massign_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfr_san\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     feats.append(summarize_states(st, n_states))\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.vstack(feats)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36massign_states\u001b[39m\u001b[34m(frames)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massign_states\u001b[39m(frames):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     frames = \u001b[43m_apply_keep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m kmeans.predict(frames)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36m_apply_keep\u001b[39m\u001b[34m(frames)\u001b[39m\n\u001b[32m     42\u001b[39m frames = np.nan_to_num(frames, nan=\u001b[32m0.0\u001b[39m, posinf=\u001b[32m0.0\u001b[39m, neginf=\u001b[32m0.0\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dyn_keep_cols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     frames = \u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdyn_keep_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frames\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along dimension 1; dimension is 61425 but corresponding boolean dimension is 62128"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    # HAS_HMM флаг (модуль уже импортирован выше, просто оставим структуру)\n",
    "    try:\n",
    "        HAS_HMM = True  # По-умолчанию используем Hidden Markov Model\n",
    "    except Exception:\n",
    "        HAS_HMM = False\n",
    "\n",
    "    # Получаем кадры динамического FC\n",
    "    tr_frames = [fc_frames_from_npy(p, WIN_DYN, STEP_DYN) for p in train_df['npy_path']]\n",
    "    va_frames = [fc_frames_from_npy(p, WIN_DYN, STEP_DYN) for p in val_df['npy_path']]\n",
    "\n",
    "    # Санитизация (NaN / inf -> 0) для устойчивости HMM / KMeans\n",
    "    def sanitize_frames(fr_list):\n",
    "        return [np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0) for f in fr_list]\n",
    "\n",
    "    tr_frames = sanitize_frames(tr_frames)\n",
    "    va_frames = sanitize_frames(va_frames)\n",
    "\n",
    "    # Объединяем обучающие кадры\n",
    "    Xtrain_seq = np.vstack(tr_frames)\n",
    "    Xtrain_seq = np.nan_to_num(Xtrain_seq, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Удаляем/обрабатываем почти константные признаки (иначе ковариации нулевые -> ValueError)\n",
    "    var = Xtrain_seq.var(axis=0)\n",
    "    dyn_keep_cols = var > 1e-12\n",
    "    if dyn_keep_cols.sum() < Xtrain_seq.shape[1]:\n",
    "        removed = (~dyn_keep_cols).sum()\n",
    "        print(f\"[DynFC] Removed {removed} near-constant features before HMM/KMeans.\")\n",
    "        Xtrain_seq = Xtrain_seq[:, dyn_keep_cols]\n",
    "    else:\n",
    "        dyn_keep_cols = None  # ничего не удаляем\n",
    "\n",
    "    # Лёгкая стабилизация: добавим eps к абсолютно нулевым столбцам (если остались)\n",
    "    zero_var_cols = (Xtrain_seq.var(axis=0) <= 1e-12)\n",
    "    if zero_var_cols.any():\n",
    "        Xtrain_seq[:, zero_var_cols] += np.random.randn(Xtrain_seq.shape[0], zero_var_cols.sum()) * 1e-6\n",
    "        print(f\"[DynFC] Injected epsilon noise into {zero_var_cols.sum()} zero-variance columns.\")\n",
    "\n",
    "    n_states = int(HMM_N_STATES)\n",
    "\n",
    "    def _apply_keep(frames):\n",
    "        \"\"\"\n",
    "        Санитизация + приведение числа признаков к размеру dyn_keep_cols.\n",
    "        Исправление IndexError при несовпадении длины boolean mask и числа колонок:\n",
    "        - Если во входном кадре меньше признаков (из-за различного числа ROI после salvage),\n",
    "          дополняем нулями.\n",
    "        - Если больше — обрезаем.\n",
    "        После выравнивания применяем dyn_keep_cols.\n",
    "        \"\"\"\n",
    "        frames = np.nan_to_num(frames, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if dyn_keep_cols is not None:\n",
    "            target_len = dyn_keep_cols.shape[0]\n",
    "            cur_len = frames.shape[1]\n",
    "            if cur_len != target_len:\n",
    "                if cur_len < target_len:\n",
    "                    # pad zeros to the right\n",
    "                    pad = np.zeros((frames.shape[0], target_len - cur_len), dtype=frames.dtype)\n",
    "                    frames = np.hstack([frames, pad])\n",
    "                else:\n",
    "                    # truncate extra columns\n",
    "                    frames = frames[:, :target_len]\n",
    "            # now safe to index\n",
    "            frames = frames[:, dyn_keep_cols]\n",
    "        return frames\n",
    "\n",
    "    if HAS_HMM:\n",
    "        model_states = GaussianHMM(n_components=n_states, covariance_type='diag', n_iter=200, random_state=0)\n",
    "        try:\n",
    "            model_states.fit(Xtrain_seq)\n",
    "        except ValueError as e:\n",
    "            print(f\"[DynFC-HMM] HMM fit failed ({e}) -> fallback to KMeans.\")\n",
    "            HAS_HMM = False\n",
    "\n",
    "    if HAS_HMM:\n",
    "        def assign_states(frames):\n",
    "            frames = _apply_keep(frames)\n",
    "            return model_states.predict(frames)\n",
    "    else:\n",
    "        # Fallback: KMeans\n",
    "        kmeans = KMeans(n_clusters=n_states, random_state=0)\n",
    "        kmeans.fit(Xtrain_seq)\n",
    "\n",
    "        def assign_states(frames):\n",
    "            frames = _apply_keep(frames)\n",
    "            return kmeans.predict(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15995567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DynFC-HMM] val_acc=0.523 | val_auc=nan | val_f1=0.172 | HAS_HMM=False\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES:\n",
    "    def _apply_keep(frames):\n",
    "        \"\"\"\n",
    "        Санитизация + приведение числа признаков к размеру dyn_keep_cols.\n",
    "        Исправление IndexError при несовпадении длины boolean mask и числа колонок:\n",
    "        - Если во входном кадре меньше признаков (из-за различного числа ROI после salvage),\n",
    "          дополняем нулями.\n",
    "        - Если больше — обрезаем.\n",
    "        После выравнивания применяем dyn_keep_cols.\n",
    "        \"\"\"\n",
    "        frames = np.nan_to_num(frames, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if dyn_keep_cols is not None:\n",
    "            target_len = dyn_keep_cols.shape[0]\n",
    "            cur_len = frames.shape[1]\n",
    "            if cur_len != target_len:\n",
    "                if cur_len < target_len:\n",
    "                    # pad zeros to the right\n",
    "                    pad = np.zeros((frames.shape[0], target_len - cur_len), dtype=frames.dtype)\n",
    "                    frames = np.hstack([frames, pad])\n",
    "                else:\n",
    "                    # truncate extra columns\n",
    "                    frames = frames[:, :target_len]\n",
    "            # now safe to index\n",
    "            frames = frames[:, dyn_keep_cols]\n",
    "        return frames\n",
    "\n",
    "    def build_dyn_feats(frames_list):\n",
    "        feats = []\n",
    "        for fr in frames_list:\n",
    "            fr_san = _apply_keep(fr)\n",
    "            st = assign_states(fr_san)\n",
    "            feats.append(summarize_states(st, n_states))\n",
    "        return np.vstack(feats)\n",
    "\n",
    "    # Строим агрегированные признаки состояний\n",
    "    Xtr = build_dyn_feats(tr_frames)\n",
    "    ytr = train_df['label'].values.astype(int)\n",
    "    Xva = build_dyn_feats(va_frames)\n",
    "    yva = val_df['label'].values.astype(int)\n",
    "\n",
    "    # Финальная модель\n",
    "    clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    pr_va = clf.predict_proba(Xva)\n",
    "    yh_va = pr_va.argmax(1)\n",
    "    acc = accuracy_score(yva, yh_va)\n",
    "    f1 = f1_score(yva, yh_va, average='macro')\n",
    "    try:\n",
    "        auc = roc_auc_score(yva, pr_va, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "    print(f\"[DynFC-HMM] val_acc={acc:.3f} | val_auc={auc:.3f} | val_f1={f1:.3f} | HAS_HMM={HAS_HMM}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae171d",
   "metadata": {},
   "source": [
    "## 11) Оценка переносимости: Leave-One-Site-Out (LOSO) для FC-baseline\n",
    "Для каждого сайта извлекаем его как **валидационную** выборку, обучаемся на остальных и считаем метрики. Это имитирует перенос на новый центр/сканер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dee283ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_z(r):\n",
    "    r = np.clip(r, -0.999999, 0.999999)\n",
    "    return 0.5*np.log((1+r)/(1-r))\n",
    "\n",
    "def vec_uppertri(M):\n",
    "    iu = np.triu_indices_from(M, k=1)\n",
    "    return M[iu]\n",
    "\n",
    "def fc_vector_from_npy(path):\n",
    "    X = np.load(path)\n",
    "    C = np.corrcoef(X, rowvar=False)\n",
    "    Cz = fisher_z(C)\n",
    "    return vec_uppertri(Cz)\n",
    "\n",
    "def build_fc_matrix(df):\n",
    "    feats = [fc_vector_from_npy(p) for p in df['npy_path']]\n",
    "    X = np.vstack(feats)\n",
    "    y = df['label'].values.astype(int)\n",
    "    return X, y\n",
    "\n",
    "def pid2site(pid):\n",
    "    s = pid.replace('sub-','')\n",
    "    m = re.match(r'([a-z]+)', s)\n",
    "    return m.group(1) if m else 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b45684fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOSO:kki] N=9 | acc=0.556 | auc=nan | f1=0.192\n",
      "[LOSO:neuroimage] N=56 | acc=0.554 | auc=0.684 | f1=0.317\n",
      "[LOSO:nyu] N=127 | acc=0.520 | auc=nan | f1=0.207\n",
      "[LOSO:peking] N=92 | acc=0.696 | auc=nan | f1=0.492\n",
      "[LOSO:pittsburgh] N=36 | acc=0.750 | auc=nan | f1=0.286\n",
      "[LOSO:washu] N=52 | acc=0.731 | auc=nan | f1=0.281\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "N_val",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "510686a6-13e5-45bd-8881-0be5d3619f72",
       "rows": [
        [
         "0",
         "kki",
         "9",
         "0.5555555555555556",
         null,
         "0.19230769230769232"
        ],
        [
         "1",
         "neuroimage",
         "56",
         "0.5535714285714286",
         "0.6838305461073318",
         "0.3174091966362498"
        ],
        [
         "2",
         "nyu",
         "127",
         "0.5196850393700787",
         null,
         "0.20690993788819878"
        ],
        [
         "3",
         "peking",
         "92",
         "0.6956521739130435",
         null,
         "0.4924924924924925"
        ],
        [
         "4",
         "pittsburgh",
         "36",
         "0.75",
         null,
         "0.2857142857142857"
        ],
        [
         "5",
         "washu",
         "52",
         "0.7307692307692307",
         null,
         "0.2814814814814815"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>N_val</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kki</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neuroimage</td>\n",
       "      <td>56</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.683831</td>\n",
       "      <td>0.317409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyu</td>\n",
       "      <td>127</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.206910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peking</td>\n",
       "      <td>92</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>36</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>washu</td>\n",
       "      <td>52</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         site  N_val       acc       auc        f1\n",
       "0         kki      9  0.555556       NaN  0.192308\n",
       "1  neuroimage     56  0.553571  0.683831  0.317409\n",
       "2         nyu    127  0.519685       NaN  0.206910\n",
       "3      peking     92  0.695652       NaN  0.492492\n",
       "4  pittsburgh     36  0.750000       NaN  0.285714\n",
       "5       washu     52  0.730769       NaN  0.281481"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние по сайтам: {'acc': 0.6342055713632229, 'auc': 0.6838305461073318, 'f1': 0.2960525144200667}\n"
     ]
    }
   ],
   "source": [
    "if RUN_BASELINES and DO_LOSO:\n",
    "    sites = sorted({pid2site(pid) for pid in data_df['participant_id']})\n",
    "    res = []\n",
    "    for site in sites:\n",
    "        tr_idx = data_df['participant_id'].map(pid2site) != site\n",
    "        va_idx = ~tr_idx\n",
    "        tr_df = data_df[tr_idx].reset_index(drop=True)\n",
    "        va_df = data_df[va_idx].reset_index(drop=True)\n",
    "        if len(va_df) < 5 or len(tr_df) < 10:\n",
    "            print(f\"[LOSO:{site}] слишком мало данных — пропуск\")\n",
    "            continue\n",
    "        # Формирование признаков (могут содержать NaN из-за нулевой дисперсии ROI)\n",
    "        Xtr, ytr = build_fc_matrix(tr_df)\n",
    "        Xva, yva = build_fc_matrix(va_df)\n",
    "        # Заменяем NaN / inf значениями 0 перед любыми трансформациями\n",
    "        Xtr = np.nan_to_num(Xtr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva = np.nan_to_num(Xva, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # Масштабирование\n",
    "        scaler = StandardScaler()\n",
    "        Xtr_s = scaler.fit_transform(Xtr)\n",
    "        Xva_s = scaler.transform(Xva)\n",
    "        # Повторная санитаризация (иногда стандартизация может породить inf при нулевом std)\n",
    "        Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # PCA (с проверкой допустимого числа компонент и отсутствия NaN)\n",
    "        if FC_PCA_COMPONENTS and FC_PCA_COMPONENTS > 0:\n",
    "            allowable = min(Xtr_s.shape[0], Xtr_s.shape[1])\n",
    "            n_comp = min(FC_PCA_COMPONENTS, allowable)\n",
    "            if n_comp < 1:\n",
    "                print(f\"[LOSO:{site}] Пропуск PCA (недостаточно компонент).\")\n",
    "            else:\n",
    "                if n_comp != FC_PCA_COMPONENTS:\n",
    "                    print(f\"[LOSO:{site}] PCA компонентов снижено до {n_comp} (allowable={allowable}).\")\n",
    "                # Санитизация перед PCA fit\n",
    "                Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                try:\n",
    "                    pca = PCA(n_components=n_comp)\n",
    "                    Xtr_s = pca.fit_transform(Xtr_s)\n",
    "                    Xva_s = pca.transform(Xva_s)\n",
    "                    # Финальная санитаризация\n",
    "                    Xtr_s = np.nan_to_num(Xtr_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    Xva_s = np.nan_to_num(Xva_s, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                except ValueError as e:\n",
    "                    print(f\"[LOSO:{site}] Пропуск PCA из-за ошибки: {e}\")\n",
    "        # Обучение логистической регрессии\n",
    "        clf = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
    "        clf.fit(Xtr_s, ytr)\n",
    "        pr = clf.predict_proba(Xva_s); yh = pr.argmax(1)\n",
    "        acc = accuracy_score(yva, yh)\n",
    "        f1  = f1_score(yva, yh, average='macro')\n",
    "        try:\n",
    "            auc = roc_auc_score(yva, pr, multi_class='ovr', average='macro')\n",
    "        except Exception:\n",
    "            auc = float('nan')\n",
    "        res.append({\"site\": site, \"N_val\": len(va_df), \"acc\":acc, \"auc\":auc, \"f1\":f1})\n",
    "        print(f\"[LOSO:{site}] N={len(va_df)} | acc={acc:.3f} | auc={auc:.3f} | f1={f1:.3f}\")\n",
    "    if res:\n",
    "        df_res = pd.DataFrame(res)\n",
    "        display(df_res)\n",
    "        print(\"Средние по сайтам:\", df_res[['acc','auc','f1']].mean().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bc59efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(87571) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlwt in /usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(87635) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution ~andas (/usr/local/Caskroom/miniconda/base/envs/nlp312/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Saved Excel to: /Users/alexey.stafeev/Documents/!Documents/Магистратура_МФТИ/Предметы/НИР/Материалы/ADHD200/Athena/methodology_ADHD200.xls\n",
      "Also CSV: /Users/alexey.stafeev/Documents/!Documents/Магистратура_МФТИ/Предметы/НИР/Материалы/ADHD200/Athena/methodology_ADHD200.csv\n"
     ]
    }
   ],
   "source": [
    "%pip install xlwt\n",
    "%pip install openpyxl\n",
    "\n",
    "import xlwt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "rows = [\n",
    "    [\"Отбор данных\",\"ADHD200; когорты 12–15 и 16–21; унификация ID; контроль утечки (splits по participant_id)\",\n",
    "     \"Фенотипы (CSV), фильтры по возрасту, групповые сплиты по participant_id\",\"Сделано\"],\n",
    "    [\"Подготовка сигналов\",\"ROI-тайм-серии Athena; окна фикс. длины T_FIX; mask паддинга; TR из BIDS\",\n",
    "     \".npy/.tsv.gz (T×R), *_mask.npy, *_bold.json\",\"Сделано\"],\n",
    "    [\"Базовые признаки\",\"Статическая FC из окна (Fisher-z верхний треугольник)\",\n",
    "     \"Внутренняя функция расчёта FC; baseline\",\"Сделано\"],\n",
    "    [\"Ковариаты\",\"Age / Gender / Site (предобработка и добавление в модель)\",\n",
    "     \"ColumnTransformer: StandardScaler + OneHotEncoder (fit на train)\",\"Сделано\"],\n",
    "    [\"Модели (последоват.)\",\"LSTM, GRU на (T, R) с поддержкой mask (зануление/pack)\",\n",
    "     \"PyTorch DataLoader (B, T, R)\",\"Сделано\"],\n",
    "    [\"Основная модель\",\"ROISequenceNet: Conv1d по времени per-ROI + Self-Attention по ROI + классификация\",\n",
    "     \"PyTorch; вход (T, R); mask учитывается\",\"Сделано\"],\n",
    "    [\"Бейзлайн (классика)\",\"LogisticRegression на статической FC\",\"scikit-learn\",\"Сделано\"],\n",
    "    [\"Валидация и метрики\",\"StratifiedGroupKFold / GroupShuffleSplit по participant_id; Accuracy/Precision/F1/AUC\",\n",
    "     \"sklearn.metrics; логирование результатов\",\"Сделано (нестабильность из-за объёма)\"],\n",
    "    [\"Гармонизация по сайту\",\"Коррекция межсайтовых сдвигов (ComBat)\",\"neuroComBat/аналог\",\"План\"],\n",
    "    [\"Motion-QC\",\"FD/DVARS как ковариаты/фильтр; скраббинг\",\"Конфаунды из fMRIPrep/Athena\",\"План\"],\n",
    "    [\"dFC-признаки\",\"Окна → FC-векторы → k-means состояния → occupancy/transition/dwell\",\n",
    "     \"DFC_CSV + MLP/ROISequenceNet\",\"План\"],\n",
    "    [\"Последовательность окон\",\"TCN/Transformer «по окнам» (моделирование переходов состояний)\",\n",
    "     \"PyTorch (вторая ось времени: окно→окно)\",\"План\"],\n",
    "    [\"Интерпретация\",\"Пермутационные важности, Integrated Gradients, карты внимания\",\n",
    "     \"Captum/собственные процедуры\",\"План\"],\n",
    "    [\"Воспроизводимость\",\"2 ноутбука: (1) подготовка/QC, (2) обучение/оценка; фиксация seed/версий\",\n",
    "     \"Версионирование манифеста/парцелляций/конфигов\",\"Сделано\"],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"Этап\",\"Метод / данные\",\"Инструменты и артефакты\",\"Статус\"])\n",
    "\n",
    "out_xls  = Path(\"methodology_ADHD200.xls\")\n",
    "out_xlsx = Path(\"methodology_ADHD200.xlsx\")\n",
    "out_csv  = Path(\"methodology_ADHD200.csv\")\n",
    "\n",
    "saved = None\n",
    "try:\n",
    "    df.to_excel(out_xls, index=False)      # требует пакет xlwt для .xls\n",
    "    saved = out_xls\n",
    "except Exception:\n",
    "    df.to_excel(out_xlsx, index=False)     # универсальный .xlsx (требует openpyxl)\n",
    "    saved = out_xlsx\n",
    "\n",
    "df.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Saved Excel to:\", saved.resolve())\n",
    "print(\"Also CSV:\", out_csv.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda (nlp312)",
   "language": "python",
   "name": "nlp312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
